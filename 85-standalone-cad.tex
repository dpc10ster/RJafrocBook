% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{lmodern}
\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{longtable,booktabs}
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{5}

\author{}
\date{\vspace{-2.5em}}

\begin{document}

{
\setcounter{tocdepth}{2}
\tableofcontents
}
\hypertarget{standalone-cad-radiologists}{%
\section{Standalone CAD vs.~Radiologists}\label{standalone-cad-radiologists}}

\hypertarget{standalone-cad-radiologists-abstract}{%
\subsection{Abstract}\label{standalone-cad-radiologists-abstract}}

Computer aided detection (CAD) research for screening mammography has so far focused on measuring performance of radiologists with and without CAD. Standalone performance of CAD algorithms is rarely measured. One reason is the lack of clear methodology for comparing CAD to radiologists interpreting the same cases. This work extends the method used in a recent study of standalone performance. The method is termed random-reader fixed case (\(\text{1T-RRFC}\)), since it only accounts for reader variability. The extension includes the effect of case-sampling variability. Since CAD is treated as an additional reader, the method is termed one-treatment random-reader random-case (\(\text{1T-RRRC}\)) analysis. The new method is based on existing methodology that allows comparing the average performance of readers in a single treatment to a constant value. The key modification is to regard the difference in performance between radiologists and CAD as a figure of merit, to which the existing work is directly applicable. The \(\text{1T-RRRC}\) method was compared to \(\text{1T-RRFC}\) and to an unorthodox usage of cells ROC analysis software, termed \(\text{2T-RRRC}\) analysis, which involves replicating the CAD ratings as many times as there are radiologists, to simulate a second treatment, i.e., CAD is regarded as the second treatment. \(\text{1T-RRRC}\) analysis has 3 random parameters as compared to 6 parameters in \(\text{2T-RRRC}\) and one parameter in \(\text{1T-RRFC}\). As expected, since one is including an additional source of variability, both RRRC analyses (1T and 2T) yielded larger p-values and wider confidence intervals as compared to \(\text{1T-RRFC}\). For the F-statistic, degrees of freedom and p-value, both \(\text{1T-RRRC}\) and \(\text{2T-RRRC}\) analyses yielded exactly the same results. However, \(\text{2T-RRRC}\) model parameter estimates were unrealistic; for example, it yielded zero for between-reader variance, whereas \(\text{1T-RRRC}\) yielded the expected non-zero value, identical to that yielded by \(\text{1T-RRFC}\). The method is implemented in an open-source \texttt{R} package \texttt{RJafroc.}

\hypertarget{standalone-cad-radiologists-ker-words}{%
\subsection{Keywords}\label{standalone-cad-radiologists-ker-words}}

Technology assessment, computer-aided detection (CAD), screening mammography, standalone performance, single-treatment multi-reader ROC analysis.

\hypertarget{standalone-cad-radiologists-introduction}{%
\subsection{Introduction}\label{standalone-cad-radiologists-introduction}}

In the US the majority of screening mammograms are analyzed by computer aided detection (CAD) algorithms {[}@rao2010widely{]}. Almost all major imaging device manufacturers provide CAD as part of their imaging workstation display software. In the United States CAD is approved for use as a second reader {[}@fda2018guidance{]}, i.e., the radiologist first interprets the images (typically 4 views, 2 views of each breast) without CAD and then CAD information (i.e., cued suspicious regions, possibly shown with associated probabilities of malignancies) is shown and the radiologist has the opportunity to revise the initial interpretation. In response to the second reader usage, the evolution of CAD algorithms has been guided mainly by comparing observer performance of radiologists with and without CAD.

Clinical CAD systems sometimes only report the locations of suspicious regions, i.e., it may not provide ratings. However, a (continuous variable) malignancy index for every CAD-found suspicious region is available to the algorithm designer {[}@edwards2002maximum{]}. Standalone performance, i.e., performance of designer-level CAD by itself, regarded as an algorithmic reader, vs.~radiologists, is rarely measured. In breast cancer screening the authors are aware of only one study {[}@hupse2013standalone{]} where standalone performance was measured. {[}Standalone performance has been measured in CAD for computed tomography colonography, chest radiography and three dimensional ultrasound {[}@hein2010computeraided; @summers2008performance; @taylor2006computerassisted; @deBoo2011computeraided; @tan2012computeraided{]}{]}.

One possible reason for not measuring standalone performance of CAD is the lack of an accepted assessment methodology for such measurements. The purpose of this work is to remove that impediment.
It describes a method for comparing standalone performance of designer-level CAD to radiologists interpreting the same cases and compares the method to those described in two recent publications {[}@hupse2013standalone; @kooi2016comparison{]}.

\hypertarget{standalone-cad-radiologists-methods}{%
\subsection{Methods}\label{standalone-cad-radiologists-methods}}

Summarized are two recent studies of CAD vs.~radiologists in mammography. This is followed by comments on the methodologies used in the two studies.
The second study used cells ROC software in an unorthodox (or unconventional) way. A statistical model and analysis method is described that avoids unorthodox, and perhaps unjustified, use of ROC software and has fewer model parameters.

\hypertarget{standalone-cad-radiologists-two-previous-studies}{%
\subsubsection{Studies assessing performance of CAD vs.~radiologists}\label{standalone-cad-radiologists-two-previous-studies}}

The first study {[}@hupse2013standalone{]} measured performance in finding and localizing lesions in mammograms, i.e., search was involved, while the second study {[}@kooi2016comparison{]} measured lesion classification performance between non-diseased and diseased regions of interest - ROIs) previously found on mammograms by an independent algorithmic reader.

\hypertarget{standalone-cad-radiologists-study1}{%
\paragraph{Study - 1}\label{standalone-cad-radiologists-study1}}

The first study {[}@hupse2013standalone{]} compared standalone performance of a CAD device to that of 9 radiologists interpreting the same cases (120 non-diseased and 80 with a single malignant mass per case). It used the LROC paradigm {[}@starr1975visual; @metz1976observer; @swensson1996unified{]}, in which the observer gives an overall rating for presence of disease (an integer 0 to 100 scale was used) and indicates the location of the most suspicious region. On non-diseased cases the rating is classified as a false positive (FP), but on a diseased case the rating is classified as a \emph{correct localization} (CL) if the location is sufficiently close to the lesion, and otherwise it is classified as an \emph{incorrect localization}. For a given reporting threshold, the number of correct localizations divided by the number of diseased cases estimates the probability of correct localization (PCL) at that threshold. On non-diseased cases, the number of false positives (FPs) divided by the number of non-diseased cases estimates the probability of a false positive, or false positive fraction (FPF) at that threshold. The plot of PCL (ordinate) vs.~FPF defines the LROC curve. Study - 1 used as figures of merit (FOMs) the interpolated PCL at two values of FPF, specifically FPF = 0.05 and FPF = 0.2, denoted \(\text{PCL}_{0.05}\) and \(\text{PCL}_{0.2}\), respectively. The t-test between the radiologist \(\text{PCL}_{\text{FPF}}\) values and that of CAD was used to compute the two-sided p-value for rejecting the NH of equal performance. Study - 1 reported p-value = 0.17 for \(\text{PCL}_{0.05}\) and p-value \textless{} 0.001, with CAD being inferior, for \(\text{PCL}_{0.2}\).

\hypertarget{standalone-cad-radiologists-study2}{%
\paragraph{Study - 2}\label{standalone-cad-radiologists-study2}}

The second study {[}@kooi2016comparison{]} used 199 diseased and 199 non-diseased ROIs extracted by an independent CAD algorithm. These were interpreted using the ROC paradigm (i.e., rating only, no localization required) by a different CAD algorithmic observer from that used to determine the ROIs, and 4 expert radiologists. Again, an integer 0 to 100 rating scale was used. The figure of merit was the area (AUC) under the respective ROC curves (one per radiologist and one for CAD). The p-value for the difference in AUCs between the average radiologist and CAD was determined using an unorthodox application of the Dorfman-Berbaum-Metz {[}@dorfman1992receiver{]} multiple-reader multiple-case (DBM-MRMC) software with recent modifications {[}@hillis2008recent{]}, namely, in the input data file \emph{radiologists and CAD were entered as two modalities}. In cells (or orthodox) DBM-MRMC, the data file consists, for example, of ratings of a set of cases by 4 readers in two modalities, i.e., each reader provides two ratings per case. To accommodate the paired data structure assumed by the software, the authors of Study - 2 \emph{replicated the CAD ratings four times in the data file}, as explained in the caption to Table 1, in which sample ratings are only shown for the first and last radiologist and the first and last case. By this artifice they converted a single-treatment 5-reader (4 radiologists plus CAD) data file to a two-treatment 4-reader data file, in which the four readers in treatment 1 were the radiologists, and the four readers in treatment 2 were CAD. Note that the four readers in the second treatment yield identical ratings, since each is a replica of CAD. In the right half of Table 1 the replicated CAD observers are labeled C1, C2, C3 and C4.

\begin{table}

\caption{\label{tab:standalone-cad-table-cells}This table explains the differences between the data structures in cells DBM-MRMC analysis and the unorthodox application of the software used in Study - 2. There are four radiologists, labeled R1, R2, R3 and R4 interpreting 398 cases labeled 1, 2, â€¦, 398, in two treatments, labeled 1 and 2. Sample ratings are shown only for the first and last radiologist and the first and last case. In the first four columns, labeled "Standard DBM-MRMC", each radiologist interprets each case twice. In the next four columns, labeled "Unorthodox DBM-MRMC", the radiologists interpret each case once. CAD ratings are replicated four times to effectively create the second "treatment". The quotations emphasize that there is, in fact, only one treatment. The replicated CAD observers are labeled C1, C2, C3 and C4.}
\centering
\begin{tabular}[t]{lllllllll}
\toprule
\multicolumn{4}{c}{Standard DBM-MRMC} & \multicolumn{1}{c}{} & \multicolumn{4}{c}{Unorthodox DBM-MRMC} \\
\cmidrule(l{3pt}r{3pt}){1-4} \cmidrule(l{3pt}r{3pt}){6-9}
Reader & Treatment & Case & Rating &  & Reader & Treatment & Case & Rating\\
\midrule
R1 & 1 & 1 & 75 &  & R1 & 1 & 1 & 75\\
... & ... & ... & ... &  & ... & ... & ... & ...\\
R1 & 1 & 398 & 0 &  & R1 & 1 & 398 & 0\\
... & ... & ... & ... &  & ... & ... & ... & ...\\
R4 & 1 & 1 & 50 &  & R4 & 1 & 1 & 50\\
\addlinespace
... & ... & ... & ... &  & ... & ... & ... & ...\\
R4 & 1 & 398 & 25 &  & R4 & 1 & 398 & 25\\
 &  &  &  &  &  &  &  & \\
R1 & 2 & 1 & 45 &  & C1 & 2 & 1 & 55\\
... & ... & ... & ... &  & ... & ... & ... & ...\\
\addlinespace
R1 & 2 & 398 & 25 &  & C1 & 2 & 398 & 5\\
... & ... & ... & ... &  & ... & ... & ... & ...\\
R4 & 2 & 1 & 95 &  & C4 & 2 & 1 & 55\\
... & ... & ... & ... &  & ... & ... & ... & ...\\
R4 & 2 & 398 & 20 &  & C4 & 2 & 398 & 5\\
\bottomrule
\end{tabular}
\end{table}

Study -- 2 reported a not significant difference between CAD and the radiologists (p = 0.253).

\hypertarget{standalone-cad-radiologists-comments}{%
\paragraph{Comments}\label{standalone-cad-radiologists-comments}}

For the purpose of this work, which focuses on the respective analysis methods, the difference in observer performance paradigms between the two studies, namely a search paradigm in Study - 1 vs.~an ROI classification paradigm in Study -- 2, is inconsequential. The paired t-test used in Study - 1 treats the case-sample as fixed. In other words, the analysis is not accounting for case-sampling variability but it is accounting for reader variability. While not explicitly stated, the reason for the unorthodox analysis in Study -- 2 was the desire to include case-sampling variability. \footnote{Prof.~Karssemeijer (private communication, 10/27/2017) had consulted with a few ROC experts to determine if the procedure used in Study -- 2 was valid, and while the experts thought it was probably valid they were not sure.}

In what follows, the analysis in Study -- 1 is referred to as random-reader fixed-case (\(\text{1T-RRFC}\)) while that in Study -- 2 is referred to as dual-treatment random-reader random-case (\(\text{2T-RRRC}\)).

\hypertarget{standalone-cad-radiologists-2TRRRC-anlaysis}{%
\subsubsection{\texorpdfstring{The \(\text{2T-RRRC}\) analysis model}{The \textbackslash text\{2T-RRRC\} analysis model}}\label{standalone-cad-radiologists-2TRRRC-anlaysis}}

The following approach uses the Obuchowski and Rockette (OR) figure of merit model {[}@obuchowski1995hypothesis{]} for analyzing MRMC ROC studies, instead of the pseudovalue model used in the original DBM paper {[}@dorfman1992receiver{]}. Hillis has shown the two to be equivalent {[}@hillis2005comparison{]}. For fully paired multiple-reader multiple-treatment interpretations (i.e., assuming the data structure in the left half of Table 1) the OR model is:

\begin{equation}
\theta_{ij\{c\}}=\mu+\tau_i+\left ( \tau \text{R} \right )_{ij}+\epsilon_{ij\{c\}}
\label{eq:standalone-cad-model-theta-ij}
\end{equation}

Assuming two treatments, \(i\) (\(i = 1, 2\)) is the treatment index, \(j\) (\(j = 1, ..., J\)) is the radiologist index, and \(k\) (\(k = 1, ..., K\)) is the case index, and \(\theta_{ij\{c\}}\) is a figure of merit for reader \(j\) in treatment \(i\) and case-sample \(\{c\}\). A case-sample is a set or ensemble of cases, diseased and non-diseased, and different integer values of \(c\) correspond to different case-samples. The first two terms on the right hand side of Eqn. \eqref{eq:standalone-cad-model-theta-ij} are fixed effects (average performance and treatment effect, respectively). The next two terms are random effect variables that, by assumption, are sampled as follows:

\begin{equation}
\left.
\begin{aligned}  
R_j \sim  N\left ( 0,\sigma_R^2 \right )\\
\left ( \tau R \right )_{ij} \sim N\left ( 0,\sigma_{\tau R}^2 \right )\\
\end{aligned}
\right \}
\label{eq:standalone-cad-model-rj-taur-sampling}
\end{equation}

The terms \(R_j\) represents the random treatment-independent contribution of reader \(j\), modeled as a sample from a zero-mean normal distribution with variance \(\sigma_R^2\), \(\left ( \tau R \right )_{ij}\) represents the random treatment-dependent contribution of reader \(j\) in treatment \(i\), modeled as a sample from a zero-mean normal distribution with variance \(\sigma_{\tau R}^2\). The sampling of the last (error) term is described by:

\begin{equation}
\epsilon_{ij\{c\}}\sim N_{I \times J}\left ( \vec{0} , \Sigma \right )
\label{eq:standalone-cad-eps-sampling}
\end{equation}

Here \(N_{I \times J}\) is the \(I \times J\) variate normal distribution and \(\vec{0}\) denotes the \(I \times J\) length zero-vector. The covariance matrix \(\Sigma\) is defined by 4 parameters, \(Var\), \(Cov_1\), \(Cov_2\), \(Cov_3\), defined as follows:

\begin{equation}
Cov(\epsilon_{ij\{c\}},\epsilon_{i'j'\{c\}}) =
\left\{\begin{matrix}
\text{Var} \; (i=i',j=j') \\
\text{Cov1} \; (i\ne i',j=j')\\ 
\text{Cov2} \; (i = i',j \ne j')\\ 
\text{Cov3} \; (i\ne i',j \ne j')
\end{matrix}\right\}
\label{eq:standalone-cad-or-cov}
\end{equation}

Software \{U of Iowa and \texttt{RJafroc}\} yields estimates of all terms appearing on the right hand side of Eqn. \eqref{eq:standalone-cad-or-cov}. Excluding fixed effects, the model represented by Eqn. \eqref{eq:standalone-cad-model-theta-ij} contains six parameters:

\begin{equation}
\sigma_R^2, \sigma_{\tau R}^2, Var, Cov_1, Cov_2, Cov_3
\label{eq:standalone-var-comp}
\end{equation}

The meanings the last four terms are described in {[}@hillis2007comparison; @obuchowski1995hypothesis; @hillis2005comparison; @chakraborty2017observer{]}. Briefly, \(Var\) is the variance of a reader's FOMs, in a given treatment, over interpretations of different case-samples, averaged over readers and treatments; \(Cov_1/Var\) is the correlation of a reader's FOMs, over interpretations of different case-samples in different treatments, averaged over all different treatment same reader pairings; \(Cov_2/Var\) is the correlation of different reader's FOMs, over interpretations of different case-samples in the same treatment, averaged over all same treatment different reader pairings and finally, \(Cov_3/Var\) is the correlation of different reader's FOMs, over interpretations of different case-samples in different treatments, averaged over all different treatment different reader pairings. One expects the following inequalities to hold:

\begin{equation}
Var \geq Cov_1 \geq Cov_2 \geq Cov_3
\label{eq:standalone-var-comp-ordering}
\end{equation}

In practice, since one is usually limited to one case-sample, i.e., \(\{1\}\), resampling techniques {[}@efron1994introduction{]} -- e.g., the jackknife -- are used to estimate these terms.

\hypertarget{standalone-cad-radiologists-1TRRRC-anlaysis}{%
\subsubsection{\texorpdfstring{Random-reader random-case (\(\text{1T-RRRC}\)) analysis}{Random-reader random-case (\textbackslash text\{1T-RRRC\}) analysis}}\label{standalone-cad-radiologists-1TRRRC-anlaysis}}

In this work standalone CAD is regarded as an algorithmic reader, not a different treatment.
Therefore, needed is a single treatment method for analyzing readers and CAD, where the latter is regarded as an additional reader {[}@chakraborty2017observer{]}. The method should account for both reader variability and case variability. The proposed method is termed single-treatment RRRC (\(\text{1T-RRRC}\)) analysis. The cited reference uses as the starting point the {[}@obuchowski1995hypothesis{]} model, which for the radiologists (i.e., \emph{excluding} CAD) interpreting in a single-treatment reduces to the following equation:

\begin{equation}
\theta_{j\{c\}}=\mu+R_j+\epsilon_{j\{c\}}
\label{eq:standalone-or-model-single-treatment}
\end{equation}

\(\theta_{j\{c\}}\) is the figure of merit for radiologist \(j\) (\(j = 1, 2, ..., J\)) interpreting case-sample \(\{c\}\); \(R_j\) is the random effect of radiologist \(j\) and \(\epsilon_{j\{c\}}\) is the error term. For single-treatment multiple-reader interpretations the error term is distributed as:

\begin{equation}
\epsilon_{j\{c\}}\sim N_{J}\left ( \vec{0} , \Sigma \right )
\label{eq:standalone-cad-eps-sampling-single-treatment}
\end{equation}

The \(J \times J\) covariance matrix \(\Sigma\) is defined by two parameters, \(Var\) and \(Cov_2\), as follows:

\begin{equation}
\Sigma_{jj'} = \text{Cov}\left ( \epsilon_{j\{c\}}, \epsilon_{j'\{c\}} \right )
=
\left\{\begin{matrix}
Var & j = j'\\ 
Cov_2 & j \neq j'
\end{matrix}\right.
\label{eq:standalone-cad-var-cov2-single-treatment}
\end{equation}

The terms \(Var\) and \(Cov_2\) are estimated using resampling methods. Using the jackknife, and denoting the difference FOM with case k removed by \(\psi_{j(k)}\) (the index in parenthesis denotes deleted case \(k\), and since one is dealing with a single case-sample, the case-sample index \(c\{c\}\) is superfluous). The covariance matrix is estimated using (the dot symbol represents an average over the replaced index):

\begin{equation}
\Sigma_{jj'}|_\text{jack} = \frac{K-1}{K} \sum_{k=1}^{K} \left ( \psi_{j(k)}  - \psi_{j(\bullet)} \right ) \left ( \psi_{j'(k)}  - \psi_{j'(\bullet)} \right )
\label{eq:standalone-cad-single-treatment-sigma-jackknife}
\end{equation}

The final estimates of \(Var\) and \(Cov_2\) are averaged (indicated in the following equation by the angular brackets) over all pairings of radiologists satisfying the relevant equalities/inequalities shown just below the closing angular bracket:

\begin{equation}
\left.
\begin{aligned}  
Var = \left \langle \Sigma_{jj'}|_{\text{jack}} \right \rangle_{j=j'}\\
Cov_2 = \left \langle \Sigma_{jj'}|_{\text{jack}} \right \rangle_{j \neq j'}
\end{aligned}
\right \}
\label{eq:standalone-cad-final-estimates-var-cov2}
\end{equation}

Hillis' formulae {[}@hillis2005comparison; @hillis2007comparison{]} permit one to test the NH: \(\mu = \mu_0\), where \(\mu_0\) is a pre-specified constant. One could set \(\mu_0\) equal to the performance of CAD, but that would not be accounting for the fact that the performance of CAD is itself a random variable, whose case-sampling variability needs to be accounted for.

Instead, the following model was used for the figure of merit of the radiologists and CAD (\(j = 0\) is used to denote the CAD algorithmic reader):

\begin{equation}
\theta_{j\{c\}} = \theta_{0\{c\}} + \Delta \theta + R_j + \epsilon_{j\{c\}}\\
j=1,2,...J
\label{eq:standalone-cad-model-theta-j}
\end{equation}

\(\theta_{0\{c\}}\) is the CAD figure of merit for case-sample \(\{c\}\); \(\Delta \theta\) is the average figure of merit increment of the radiologists over CAD. To reduce this model to one to which existing formulae {[}@hillis2005comparison; @hillis2007comparison{]} are directly applicable, one subtracts the CAD figure of merit from each radiologist's figure of merit (for the same case-sample), and defines this as the difference figure of merit \(\psi_{j\{c\}}\) , i.e.,

\begin{equation}
\psi_{j\{c\}} = \theta_{j\{c\}} - \theta_{0\{c\}}
\label{eq:standalone-cad-diff-reader-def}
\end{equation}

Then Eqn. \eqref{eq:standalone-cad-model-theta-j} reduces to:

\begin{equation}
\psi_{j\{c\}} = \Delta \theta + R_j + \epsilon_{j\{c\}}\\
j=1,2,...J
\label{eq:standalone-cad-model-psi-j}
\end{equation}

Eqn. \eqref{eq:standalone-cad-model-psi-j} is identical in form to Eqn. \eqref{eq:standalone-or-model-single-treatment} with the difference that the figure of merit on the left hand side of Eqn. \eqref{eq:standalone-cad-model-psi-j} is a difference FOM, that between the radiologist's and CAD. Eqn. \eqref{eq:standalone-cad-model-psi-j} describes a model for \(J\) difference radiologists interpreting a common case set, each of whose performances is a difference from that of CAD; the difference is positive if the radiologist is better. Under the NH the expected difference is zero: \(\text{NH:} \Delta \theta = 0\). The method {[}@hillis2005comparison; @hillis2007comparison{]} for single-treatment multiple-reader analysis is now directly applicable to the model described by Eqn. \eqref{eq:standalone-cad-model-psi-j}.

Apart from fixed effects, the model in Eqn. \eqref{eq:standalone-cad-model-psi-j} contains three parameters:

\begin{equation}
\sigma_R^2, Var, Cov_2
\label{eq:standalone-cad-parameter-simplified-model}
\end{equation}

Setting \(Var = 0, Cov_2 = 0\) yields the \(\text{1T-RRFC}\) model, which contains only one random parameter, namely \(\sigma_R^2\). A valid analysis should yield identical estimates of this parameter from either \(\text{1T-RRFC}\) or \(\text{RRRC}\) analysis.

\hypertarget{standalone-cad-radiologists-computational-details}{%
\subsubsection{Computational details}\label{standalone-cad-radiologists-computational-details}}

The three analyses, namely random-reader fixed-case (\(\text{1T-RRFC}\)), dual-treatment random-reader random-case (\(\text{2T-RRRC}\)) and single-treatment random-reader random-case (\(\text{1T-RRRC}\)), are implemented in \texttt{RJafroc}, an R-package {[}@packageRJafroc{]}. The function calls necessary to reproduce the results that follow are in the Appendix. {[}The PT-Mono font is used to distinguish software specific terms from normal text.{]}

TBA opening comments on output

\begin{Shaded}
\begin{Highlighting}[]

\NormalTok{ret\_1T\_RRFC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{05}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRFC"}\NormalTok{)}
\NormalTok{ret\_2T\_RRRC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{05}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{method =} \StringTok{"2T{-}RRRC"}\NormalTok{)}
\NormalTok{ret\_1T\_RRRC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{05}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.05}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRRC"}\NormalTok{)}

\NormalTok{ret\_1T\_RRFC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{2}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRFC"}\NormalTok{)}
\NormalTok{ret\_2T\_RRRC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{2}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{method =} \StringTok{"2T{-}RRRC"}\NormalTok{)}
\NormalTok{ret\_1T\_RRRC\_PCL\_}\DecValTok{0}\NormalTok{\_}\DecValTok{2}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \FloatTok{0.2}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRRC"}\NormalTok{)}

\NormalTok{ret\_1T\_RRFC\_PCL\_}\DecValTok{1}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \DecValTok{1}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRFC"}\NormalTok{)}
\NormalTok{ret\_2T\_RRRC\_PCL\_}\DecValTok{1}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \DecValTok{1}\NormalTok{, }\DataTypeTok{method =} \StringTok{"2T{-}RRRC"}\NormalTok{)}
\NormalTok{ret\_1T\_RRRC\_PCL\_}\DecValTok{1}\NormalTok{ \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (datasetCadLroc, }
\DataTypeTok{FOM =} \StringTok{"PCL"}\NormalTok{, }\DataTypeTok{FPFValue =} \DecValTok{1}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRRC"}\NormalTok{)}

\NormalTok{ret\_1T\_RRFC\_AUC \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (dataset09, }
\DataTypeTok{FOM =} \StringTok{"Wilcoxon"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRFC"}\NormalTok{)}
\NormalTok{ret\_2T\_RRRC\_AUC \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (dataset09, }
\DataTypeTok{FOM =} \StringTok{"Wilcoxon"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"2T{-}RRRC"}\NormalTok{)}
\NormalTok{ret\_1T\_RRRC\_AUC \textless{}{-}}\StringTok{ }\KeywordTok{StSignificanceTestingCadVsRad}\NormalTok{ (dataset09, }
\DataTypeTok{FOM =} \StringTok{"Wilcoxon"}\NormalTok{, }\DataTypeTok{method =} \StringTok{"1T{-}RRRC"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

TBA closing comments on output

\hypertarget{standalone-cad-radiologists-results}{%
\subsection{Results}\label{standalone-cad-radiologists-results}}

The three methods, in historical order \(\text{1T-RRFC}\), \(\text{2T-RRRC}\) and \(\text{1T-RRRC}\), were applied to an LROC dataset similar to that used in Study -- 1 (I thank Prof.~Karssemeijer for making this dataset available).

Shown next, Table \ref{tab:standalone-cad-table2}, are the significance testing results corresponding to the three analyses.

\begin{table}[H]

\caption{\label{tab:standalone-cad-table2}Significance testing results of the analyses for an LROC dataset. Three sets of results, namely RRRC, 2T-RRRC and 1T-RRRC, are shown for each figure of merit (FOM). Because it is accounting for an additional source of variability, each of the rows labeled RRRC yields a larger p-value and wider confidence intervals than the corresponding row labeled 1T-RRFC. [$\theta_0$ = FOM CAD; $\theta_{\bullet}$ = average FOM of radiologists; $\psi_{\bullet}$ = average FOM of radiologists minus CAD; CI= 95 percent confidence interval of quantity indicated by the subscript, F = F-statistic; ddf = denominator degrees of freedom; p = p-value for rejecting the null hypothesis: $\psi_{\bullet} = 0$.]}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{lllllllllll}
\toprule
FOM & Analysis & $\theta_0$ & $CI_{\theta_0}$ & $\theta_{\bullet}$ & $CI_{\theta_{\bullet}}$ & $\psi_{\bullet}$ & $CI_{\psi_{\bullet}}$ & F & ddf & p\\
\midrule
 & 1T-RRFC &  & 0 &  & (4.18e-01,5.68e-01) &  & (-3.16e-02,1.18e-01) & 1.77e+00 & 8e+00 & 2.2e-01\\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\cmidrule{8-11}
 & 2T-RRRC &  & (2.58e-01,6.42e-01) &  & (3.76e-01,6.11e-01) &  &  &  &  & \\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_0\_05} & 1T-RRRC & \multirow{-3}{*}{\raggedright\arraybackslash 4.5e-01} & NA & \multirow{-3}{*}{\raggedright\arraybackslash 4.93e-01} & (2.93e-01,6.94e-01) & \multirow{-3}{*}{\raggedright\arraybackslash 4.33e-02} & \multirow{-2}{*}{\raggedright\arraybackslash (-1.57e-01,2.44e-01)} & \multirow{-2}{*}{\raggedright\arraybackslash 1.79e-01} & \multirow{-2}{*}{\raggedright\arraybackslash 7.84e+02} & \multirow{-2}{*}{\raggedright\arraybackslash 6.7e-01}\\
\cmidrule{1-11}
 & 1T-RRFC &  & 0 &  & (6.69e-01,7.51e-01) &  & (7.78e-02,1.59e-01) & 4.5e+01 & 8e+00 & 1.51e-04\\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\cmidrule{8-11}
 & 2T-RRRC &  & (4.78e-01,7.05e-01) &  & (6.33e-01,7.87e-01) &  &  &  &  & \\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_0\_2} & 1T-RRRC & \multirow{-3}{*}{\raggedright\arraybackslash 5.92e-01} & NA & \multirow{-3}{*}{\raggedright\arraybackslash 7.1e-01} & (5.96e-01,8.24e-01) & \multirow{-3}{*}{\raggedright\arraybackslash 1.19e-01} & \multirow{-2}{*}{\raggedright\arraybackslash (4.45e-03,2.33e-01)} & \multirow{-2}{*}{\raggedright\arraybackslash 4.16e+00} & \multirow{-2}{*}{\raggedright\arraybackslash 9.37e+02} & \multirow{-2}{*}{\raggedright\arraybackslash 4.2e-02}\\
\cmidrule{1-11}
 & 1T-RRFC &  & 0 &  & (7.4e-01,8.27e-01) &  & (6.48e-02,1.52e-01) & 3.3e+01 & 8e+00 & 4.33e-04\\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\cmidrule{8-11}
 & 2T-RRRC &  & (5.71e-01,7.79e-01) &  & (7.12e-01,8.54e-01) &  &  &  &  & \\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_1} & 1T-RRRC & \multirow{-3}{*}{\raggedright\arraybackslash 6.75e-01} & NA & \multirow{-3}{*}{\raggedright\arraybackslash 7.83e-01} & (6.8e-01,8.87e-01) & \multirow{-3}{*}{\raggedright\arraybackslash 1.08e-01} & \multirow{-2}{*}{\raggedright\arraybackslash (4.5e-03,2.12e-01)} & \multirow{-2}{*}{\raggedright\arraybackslash 4.2e+00} & \multirow{-2}{*}{\raggedright\arraybackslash 4.93e+02} & \multirow{-2}{*}{\raggedright\arraybackslash 4.1e-02}\\
\cmidrule{1-11}
 & 1T-RRFC &  & 0 &  & (8.26e-01,8.71e-01) &  & (8.96e-03,5.45e-02) & 1.03e+01 & 8e+00 & 1.24e-02\\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\cmidrule{8-11}
 & 2T-RRRC &  & (7.52e-01,8.82e-01) &  & (8.07e-01,8.9e-01) &  &  &  &  & \\
\cmidrule{2-2}
\cmidrule{4-4}
\cmidrule{6-6}
\multirow{-3}{*}{\raggedright\arraybackslash Wilcoxon} & 1T-RRRC & \multirow{-3}{*}{\raggedright\arraybackslash 8.17e-01} & NA & \multirow{-3}{*}{\raggedright\arraybackslash 8.49e-01} & (7.86e-01,9.11e-01) & \multirow{-3}{*}{\raggedright\arraybackslash 3.17e-02} & \multirow{-2}{*}{\raggedright\arraybackslash (-3.1e-02,9.45e-02)} & \multirow{-2}{*}{\raggedright\arraybackslash 9.86e-01} & \multirow{-2}{*}{\raggedright\arraybackslash 8.78e+02} & \multirow{-2}{*}{\raggedright\arraybackslash 3.2e-01}\\
\bottomrule
\end{tabular}}
\end{table}

Results are shown for the following FOMs: \(\text{PCL}_{0.05}\), \(\text{PCL}_{0.2}\), \(\text{PCL}_{1}\), and the empirical area (AUC) under the ROC curve estimated by the Wilcoxon statistic. The first two FOMs are identical to those used in Study -- 1. Columns 3 and 4 list the CAD FOM \(\theta_0\), and its 95\% confidence interval \(CI_{\theta_0}\), columns 5 and 6 list the average radiologist FOM \(\theta_{\bullet}\) (the dot symbol represents an average over the radiologist index) and its 95\% confidence interval \(CI_{\theta_{\bullet}}\), columns 7 and 8 list the average difference FOM \(\psi_{\bullet}\), i.e., radiologist minus CAD, and its 95\% confidence interval \(CI_{\psi_{\bullet}}\), and the last three columns list the F-statistic, the denominator degrees of freedom (ddf) and the p-value for rejecting the null hypothesis. The numerator degree of freedom of the F-statistic, not listed, is unity.

In Table \ref{tab:standalone-cad-table2} identical values in adjacent cells in vertical columns have been replaced by the common values. The last three columns show that \(\text{2T-RRRC}\) and \(\text{1T-RRRC}\) analyses yield \emph{identical F-statistics, ddf and p-values}. So the intuition of the authors of Study -- 2, that the unorthodox method of using DBM -- MRMC software to account for both reader and case-sampling variability, turns out to be correct. If interest is solely in these statistics one is justified in using the unorthodox method.

Commented on next are other aspects of the results evident in Table \ref{tab:standalone-cad-table2}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  Where a direct comparison is possible, namely \(\text{1T-RRFC}\) analysis using and as FOMs, the p-values in Table \ref{tab:standalone-cad-table2} are similar to those reported in Study -- 1.
\item
  All FOMs (i.e., \(\theta_0\), \(\theta_{\bullet}\) and \(\psi_{\bullet}\)) in Table \ref{tab:standalone-cad-table2} are independent of the method of analysis. However, the corresponding confidence intervals (i.e., \(CI_{\theta_0}\), \(CI_{\theta_{\bullet}}\) and \(CI_{\psi_{\bullet}}\)) depend on the analyses.
\item
  Since \(\text{1T-RRFC}\) analysis ignores case sampling variability, the CAD figure of merit is a constant, with zero-width confidence interval. For compactness the CI is listed as 0, rather than two identical values in parentheses. The confidence interval listed for \(\text{2T-RRRC}\) analyses is centered on the corresponding CAD value, as are all confidence intervals in Table \ref{tab:standalone-cad-table2}.
\item
  The LROC FOMs increase as the value of FPF (the subscript) increases.
  This should be obvious, as PCL increases as FPF increases, a general feature of any partial curve based figure of merit.
\item
  The area (AUC) under the ROC is larger than the largest PCL value, i.e., \(AUC \geq \text{PCL}_1\). This too should be obvious from the general features of the LROC {[}@swensson1996unified{]}.
\item
  The p-value for either RRRC analyses (2T or 1T) is larger than the corresponding \(\text{1T-RRFC}\) value. Accounting for case-sampling variability increases the p-value, leading to less possibility of finding a significant difference.
\item
  Partial curve-based FOMs, such as \(\text{PCL}_{FPF}\), lead, depending on the choice of \(FPF\), to different conclusions. The p-values generally decrease as FPF increases. Measuring performance on the steep part of the LROC curve (i.e., small FPF) needs to account for greater reader variability and risks lower statistical power.
\item
  Ignoring localization information (i.e., using the AUC FOM) led to a not-significant difference between CAD and the radiologists (\(p\) = 0.3210), while the corresponding FOM yielded a significant difference (\(p\) = 0.0409). Accounting for localization leads to a less ``noisy'' measurement. This has been demonstrated for the LROC paradigm {[}@swensson1996unified{]} and I have demonstrated this for the FROC paradigm {[}@chakraborty2008validation{]}.
\item
  For \(\text{1T-RRRC}\) analysis, is listed as NA, for not applicable, since is not a model parameter, see Eqn. \eqref{eq:standalone-cad-model-psi-j}.
\end{enumerate}

Shown next, Table \ref{tab:standalone-cad-table3}, are the model-parameters corresponding to the three analyses.

\begin{table}[H]

\caption{\label{tab:standalone-cad-table3}Parameter estimates for the analyses; NA = not applicable.}
\centering
\resizebox{\linewidth}{!}{
\begin{tabular}[t]{llllllll}
\toprule
FOM & Analysis & $\sigma_R^2$ & $\sigma_{\tau R}^2$ & Cov1 & Cov2 & Cov3 & Var\\
\midrule
 & 1T-RRFC & 9.5e-03 & NA & NA & NA & NA & NA\\
\cmidrule{2-8}
 & 2T-RRRC & 1.84e-18 & -5.71e-03 & 1.31e-03 & 6.01e-03 & 1.31e-03 & 1.65e-02\\
\cmidrule{2-8}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_0\_05} & 1T-RRRC & 9.5e-03 & NA & NA & 9.4e-03 & NA & 3.03e-02\\
\cmidrule{1-8}
 & 1T-RRFC & 2.81e-03 & NA & NA & NA & NA & NA\\
\cmidrule{2-8}
 & 2T-RRRC & -7.59e-19 & 2.65e-04 & 7.61e-04 & 2.29e-03 & 7.61e-04 & 3.43e-03\\
\cmidrule{2-8}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_0\_2} & 1T-RRRC & 2.81e-03 & NA & NA & 3.07e-03 & NA & 5.34e-03\\
\cmidrule{1-8}
 & 1T-RRFC & 3.2e-03 & NA & NA & NA & NA & NA\\
\cmidrule{2-8}
 & 2T-RRRC & 1.63e-18 & 1e-03 & 6.43e-04 & 1.86e-03 & 6.43e-04 & 2.46e-03\\
\cmidrule{2-8}
\multirow{-3}{*}{\raggedright\arraybackslash PCL\_1} & 1T-RRRC & 3.2e-03 & NA & NA & 2.44e-03 & NA & 3.64e-03\\
\cmidrule{1-8}
 & 1T-RRFC & 8.78e-04 & NA & NA & NA & NA & NA\\
\cmidrule{2-8}
 & 2T-RRRC & 2.98e-19 & 2.01e-04 & 2.62e-04 & 7.24e-04 & 2.62e-04 & 9.62e-04\\
\cmidrule{2-8}
\multirow{-3}{*}{\raggedright\arraybackslash Wilcoxon} & 1T-RRRC & 8.78e-04 & NA & NA & 9.24e-04 & NA & 1.4e-03\\
\bottomrule
\end{tabular}}
\end{table}

The following characteristics are evident from Table \ref{tab:standalone-cad-table3}.

\begin{enumerate}
\def\labelenumi{\arabic{enumi}.}
\tightlist
\item
  For \(\text{2T-RRRC}\) analyses \(\sigma_R^2 = 0\). Actually, the analysis yielded very small values, of the order of \(10^{-18}\) to \(10^{-19}\), which, being smaller than double precision accuracy, were replaced by zeroes in Table \ref{tab:standalone-cad-table2}. \(\sigma_R^2 = 0\) is clearly an incorrect result as the radiologists do not have identical performance. In contrast, \(\text{1T-RRRC}\) analyses yielded more realistic values, identical to those obtained by \(\text{1T-RRFC}\) analyses, and consistent with expectation -- see comment following Eqn. (15).
\item
  Because 2T analysis found zero reader variability, it follows from the definitions of the covariances {[}@obuchowski1995hypothesis{]}, that \(Cov_1 = Cov_3 = 0\), as evident in the table.
\item
  When they can be compared (i.e., \(\sigma_R^2\), \(Cov_2\) and \(Var\)), all variance and covariance estimates were smaller for the 2T method than for the 1T method.
\item
  For the 2T method the expected inequalities, Eqn. \eqref{eq:standalone-var-comp-ordering}, are not obeyed (specifically, \(Cov_1 \geq Cov_2 \geq Cov_3\) is not obeyed).
\end{enumerate}

For an analysis method to be considered statistically valid it needs to be tested with simulations to determine if it has the proper null hypothesis behavior. The design of a ratings simulator to statistically match a given dataset is addressed in Chapter 23 of reference {[}@chakraborty2017observer{]}. Using this simulator, the \(\text{1T-RRRC}\) method had the expected null hypothesis behavior (Table 23.5, ibid).

\hypertarget{standalone-cad-radiologists-discussion}{%
\subsection{Discussion}\label{standalone-cad-radiologists-discussion}}

TBA TODOLAST The argument often made for not measuring standalone performance is that since CAD will be used only as a second reader, it is only necessary to measure performance of radiologists without and with CAD. It has been stated {[}@nishikawa2011fundamental{]}:

\begin{quote}
High stand-alone performance is neither a necessary nor a sufficient condition for CAD to be truly useful clinically.
\end{quote}

Assessing CAD utility this way, i.e, by measuring performance with and without CAD, may have inadvertently set a low bar for CAD to be considered useful. As examples, CAD is not penalized for missing cancers as long as the radiologist finds them and CAD is not penalized for excessive false positives (FPs) as long as the radiologist ignores them. Moreover, since both such measurements include the variability of radiologists, there is additional noise introduces that presumably makes it harder to determine if the CAD system is optimal.

Described is an extension of the analysis used in Study -- 1 that accounts for case sampling variability. It extends {[}@hillis2005comparison{]} single-treatment analysis to a situation where one of the ``readers'' is a special reader, and the desire is to compare performance of this reader to the average of the remaining readers. The method, along with two other methods, was used to analyze an LROC data set using different figures of merit.

\(\text{1T-RRRC}\) analyses yielded identical overall results (specifically the F-statistic, degrees of freedom and p-value) to those yielded by the unorthodox application of DBM-MRMC software, termed \(\text{2T-RRRC}\) analyses, where the CAD reader is regarded as a second treatment. However, the values of the model parameters of the dual-treatment analysis lacked clear physical meanings. In particular, the result \(\sigma_R^2 = 0\) is clearly an artifact. One can only speculate as to what happens when software is used in a manner that it was not designed for: perhaps finding that all readers in the second treatment have identical FOMs led the software to yield \(\sigma_R^2 = 0\). The single-treatment model has half as many parameters as the dual-treatment model and the parameters have clear physical meanings and the values are realistic.

The paradigm used to collect the observer performance data - e.g., receiver operating characteristic (ROC) {[}@metz1986rocmethodology{]}, free-response ROC (FROC) {[}@Chakraborty1986DigitalVsConv{]}, location ROC (LROC) {[}@starr1975visual{]} or region of interest (ROI) {[}@obuchowski2010data{]} - is irrelevant -- all that is needed is a scalar performance measure for the actual paradigm used. In addition to PCL and AUC, RJafroc currently implements the partial area under the LROC, from FPF = 0 to a specified value as well other FROC-paradigm based FOMs.

While there is consensus that CAD works for microcalcifications, for masses its performance is controversial27,28. Two large clinical studies TBA 29,30 (222,135 and 684,956 women, respectively) showed that CAD actually had a detrimental effect on patient outcome. A more recent large clinical study has confirmed the negative view of CAD31 and there has been a call for ending Medicare reimbursement for CAD interpretations32.

In my opinion standalone performance is the most direct measure of CAD performance. Lack of clear-cut methodology to assess standalone CAD performance may have limited past CAD research. The current work hopoefully removes that impediment. Going forward, assessment of standalone performance of CAD vs.~expert radiologists is strongly encouraged.

\hypertarget{standalone-cad-radiologists-appendix}{%
\subsection{Appendix}\label{standalone-cad-radiologists-appendix}}

Assuming \texttt{RJafroc} has been installed, the following commands yield the results in Tables 2 and 3. Note that \texttt{R} is case sensitive.

\{Table 4 goes here\}

\hypertarget{standalone-cad-radiologists-references}{%
\subsection{References}\label{standalone-cad-radiologists-references}}

\end{document}
