# FROC vs. wAFROC {#froc-paradigm-froc-vs-afroc}

```{r setup, include = FALSE}
  knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
  )
  library(RJafroc)
  library(ggplot2)
  library(kableExtra)
  library(gridExtra)
  library(abind)
  library(here)
```


## Introduction {#froc-paradigm-froc-vs-afroc-froc-vs-afrocs-intro}
The FROC curve was introduced in [@RN2453] and ever since has become a widely used method for evaluating performance in the free-response paradigm, particularly in CAD algorithm development. Typically CAD researchers report "sensitivity was observed to be xx at yy false positives per image." Alternatively, using less ambiguous terminology, they are reporting an observed operating point on the FROC, as in "LLF was observed to be xx at NLF = yy". 

In the previous chapter I issued a recommendation against its continued usage. Instead, I recommended adoption of the wAFROC / AUC as the preferred operating characteristic / figure of merit in assessing performance in the free-response paradigm. This chapter details some studies supporting my recommendation.

## FROC vs. wAFROC
This section examines RSM-predicted FROC and wAFROC plots for a simulated CAD and a simulated RAD observer. Recall that the RSM is defined by 3 parameters $\mu, \lambda, \nu$ and a lowest threshold parameter $\zeta_1$ which determines if latent localizations are actually marked. Both observers share the same $\lambda, \nu$. These are defined at lines 3 and 4 of the following code: $\lambda = \nu = 1$. The simulated CAD observer is defined at line 7 by by $\mu_{CAD} = 1$ and the simulated RAD observer is defined at line 8 by by $\mu_{RAD} = 1.5$. The corresponding threshold parameters are $\zeta_{1} = -1$ for CAD and $\zeta_{1} = 1.5$ for RAD. 

The number of simulated cases is determined, lines 5-6, by $K_1 = 500$ and $K_2 = 700$. Relatively large numbers of cases were chosen to minimize sampling variability. 

The maximum number of lesions per case is chosen at line 7 `Lmax` = 2. The actual number of lesions per case `Lk2` is determined at line 14 (`Lk2` is a $K_2$ length array consisting of random integers 1 or 2).

Line 16 calls the helper function `CadVsRad()` (sourced at line 1) which generates two plots. The FROC is extracted at line 18 and labeled A, while the wAFROC is extracted at line 19 and labeled B. 


```{r, cache = TRUE, attr.source = ".numberLines"}
source(here("R/CH13-CadVsRad/CadVsRad.R"))

nu <- 1
lambda <- 1
K1 <- 500
K2 <- 700
muCad <- 1.0
muRad <- 1.5
zeta1Cad <- -1
zeta1Rad <- 1.5
Lmax <- 2
seed <- 1
set.seed(seed)
Lk2 <- floor(runif(K2, 1, Lmax + 1))

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc1 <- ret$froc$Plot + labs(tag = "A")
wafroc1 <- ret$wafroc$Plot + labs(tag = "B")
fomCad1 <- ret$fomCad
fomRad1 <- ret$fomRad

zeta1Cad <- -Inf
zeta1Rad <- -Inf

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc2 <- ret$froc$Plot + labs(tag = "C")
wafroc2 <- ret$wafroc$Plot + labs(tag = "D")
fomCad2 <- ret$fomCad
fomRad2 <- ret$fomRad
```


Because of the chosen parameters the RAD observer has greater classification and search performances than CAD ^[Even though the *intrinsic* search parameters $\lambda, \nu$ are identical, because of the higher $\mu$ parameter, search performance is effectively much better for RAD - the distinction between intrinsic and physical parameters is clarified in Chapter TBA.] and, *for plots A and B*, a higher reporting threshold. One expects the FROC for the CAD observer to extend to much larger NLF values while that for the RAD observer is expected to be relatively short and steep, as in Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot1), plot A. 


```{r froc-paradigm-froc-vs-afroc-plot1, fig.cap="Plots A and B are for CAD $\\zeta_1 = -1$ and RAD $\\zeta_1 = 1.5$ and plots C and D are plots for CAD $\\zeta_1 = -\\infty$ and RAD $\\zeta_1 = -\\infty$. A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves.", fig.show='hold', echo=FALSE}
grid.arrange(froc1,wafroc1,froc2,wafroc2,nrow=2,ncol=2)
```


Note the much steeper rise and shorter horizontal traverse of the RAD observer in A, suggestive of superior performance, but difficult to quantify from the FROC curves *due to the lack of a common NLF range for the two plots* ^[If a common NLF range is forced, for example defined as the common NLF range 0 to 0.05 where both curves contribute, it would ignore most NLs from the CAD observer.]. CAD algorithm developers typically quote LLF at a specified NLF. According to the two plots in A, the RAD observer is better if the NLF value is chosen to less than 0.05 while the CAD observer is better for larger values of NLF. A similar problem was encountered in ROC analysis when comparing a pair of sensitivity-specificity values, where, given differing choices of thresholds, ambiguous results can be obtained, as in Fig. TBA. Indeed, this was the rationale for using AUC under the ROC curve as an unambiguous measure of performance. Like the ROC, the wAFROC is contained within the unit square.
 

wAFROC curves, for the same datasets whose FROC curves are shown in plot A, are shown in plot B. The AUC under the RAD observer is visibly greater than that for the CAD observer, even though due to the choice of a higher threshold the AUC estimate is actually biased downward against RAD ^[Because the RAD observer is adopting $\zeta_1 = 1.5$, $\text{LLF}_{\text{max}}$ is smaller than it would have been with a less strict criterion, and consequently the area under the large straight line segment from the uppermost non-trivial operating point to (1,1) is smaller than would have been the case with $\zeta_1 = -\infty$]. AUCs under the two wAFROC plots in B are `r fomCad1` for CAD and `r fomRad1` for RAD, consistent with the visual impression of RAD > CAD. 


**The basic problem with the FROC-based comparison, namely the lack of a common NLF range in order to compare the two plots, is solved by the wAFROC-based comparison, in which the FPF range is identical for the two observers, namely 0 to 1.** 


Lines 23-24 set the two threshold parameters to $-\infty$ each ^[This is impractical with the RAD observer but possible with CAD.] and line 24 calls the function `CadVsRad()` again with these new values. The FROC is extracted at line 28 and labeled C, while the wAFROC is extracted at line 29 and labeled D. 


With the new thresholds one expects *all* latent localizations to be actually marked, in other words one would observe the entire extent of the curves. Plot C in Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot1) corresponds to $\zeta_1 = -\infty$, so the entire latent FROC curves are visible for both observers. This confirms the expectation that RAD is actually the better observer. Plot D shows corresponding wAFROC curves and the corresponding AUCs are `r fomCad2` and `r fomRad2`. The differences from the previous values (corresponding to B) namely `r fomCad1` for CAD and `r fomRad1` for RAD, is much larger for the RAD observer than for the CAD observer. This is because the CAD observer was already adopting a low threshold $\zeta_1 = -1$, so lowering it to $-\infty$ is expected to have a small effect: AUC under the wAFROC decreased slightly from `r fomCad1` to `r fomCad2` (since the initial threshold was already low, lowering it further does not appreciably increase $\text{LLF}_{\text{max}}$, rather it increases $\text{FPF}_{\text{max}}$ and the net AUC decreases slightly). In contrast, AUC for the RAD observer increases from `r fomRad1` to `r fomRad2`.  


From the left plot one suspects the RAD observer is performing better than CAD, because of the much steeper rise and much shorter traverse along the NLF axis for the RAD observer as compared to CAD. The RAD observer is better at finding lesions and producing fewer NLs, both of which are desirable characteristics. One suspects that if this observer could be induced to relax the threshold and report more NLs, then LLF would exceed that of the CAD observer while $\text{NLF}_{\text{max}}$ would remain smaller than the corresponding value for CAD. 


Two other examples are given. 

```{r, cache = TRUE, echo=FALSE}
source(here("R/CH13-CadVsRad/CadVsRad.R"))

nu <- 1
lambda <- 1
K1 <- 500
K2 <- 700
muCad <- 1.0
muRad <- 2
zeta1Cad <- -1
zeta1Rad <- 2
Lmax <- 2
seed <- 1
set.seed(seed)
Lk2 <- floor(runif(K2, 1, Lmax + 1))

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc1 <- ret$froc$Plot + labs(tag = "A")
wafroc1 <- ret$wafroc$Plot + labs(tag = "B")
fomCad1 <- ret$fomCad
fomRad1 <- ret$fomRad

zeta1Cad <- -Inf
zeta1Rad <- -Inf

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc2 <- ret$froc$Plot + labs(tag = "C")
wafroc2 <- ret$wafroc$Plot + labs(tag = "D")
fomCad2 <- ret$fomCad
fomRad2 <- ret$fomRad
```


Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot2) (A) exaggerates the difference between CAD and RAD. The CAD parameters are the same as in Fig. 13.6, but the RAD parameters are $\mu = 2$ and $\zeta_1$ = +2. Doubling the separation parameter over that of CAD has a huge effect on performance. The end-point coordinates for RAD are:   = 0.015,   = 0.421. This time AUC under the common region defined by NLF = zero to NLF =   would exclude almost all of the NL and LL marks made by CAD. The wAFROCs in plot B show the markedly greater performance of RAD compared to CAD (the AUCs are 0.608 for CAD and 0.708 for RAD). The difference is larger, in spite of the downward bias working against the wAFROC-RAD-AUC, Fig. 13.6 (D).



```{r froc-paradigm-froc-vs-afroc-plot2, fig.cap="Plots A and B are for CAD $\\zeta_1 = -1$ and RAD $\\zeta_1 = 2$ and plots C and D are plots for CAD $\\zeta_1 = -\\infty$ and RAD $\\zeta_1 = -\\infty$. A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves.", fig.show='hold', echo=FALSE}
grid.arrange(froc1,wafroc1,froc2,wafroc2,nrow=2,ncol=2)
```


 
Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot2) (A) FROC curves for CAD observer (red line) and the RAD observer (green line). The CAD observer is identical to that shown in Fig. 13.6. The RAD observer is characterized by $\mu = 2$ and $\zeta_1 = 2$. This time it is impossible to compare the two FROC curves, as the common range is very small. However, wAFROC clearly shows the expected superiority of the RAD observer, in spite of the severe underestimate of the corresponding AUC. AUCs under the two wAFROC plots are 0.608 for CAD and 0.708 for RAD. Plots C and D correspond to A and B, respectively, with $\zeta_1$ = $-\infty$ for both readers. AUCs under the two wAFROC plots are 0.601 for CAD and 0.872 for RAD.



The final example, Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot3) shows that *when there is a small difference in performance*, there is less ambiguity in using the FROC as a basis for measuring performance. The CAD parameters are the same as in Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot1) but the RAD parameters are $\mu = 1.1$ and $\zeta_1$ = -1. This time there is much more common overlap in plot (A) and the area measure is counting most of the marks for both readers (but still not accounting for unmarked non-diseased cases). The superior wAFROC-based performance of RAD is also apparent in (B). 


```{r, cache = TRUE, echo=FALSE}
source(here("R/CH13-CadVsRad/CadVsRad.R"))

nu <- 1
lambda <- 1
K1 <- 500
K2 <- 700
muCad <- 1.0
muRad <- 1.1
zeta1Cad <- -1
zeta1Rad <- -1
Lmax <- 2
seed <- 1
set.seed(seed)
Lk2 <- floor(runif(K2, 1, Lmax + 1))

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc1 <- ret$froc$Plot + labs(tag = "A")
wafroc1 <- ret$wafroc$Plot + labs(tag = "B")
fomCad1 <- ret$fomCad
fomRad1 <- ret$fomRad

zeta1Cad <- -Inf
zeta1Rad <- -Inf

ret <- CadVsRad (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed)

froc2 <- ret$froc$Plot + labs(tag = "C")
wafroc2 <- ret$wafroc$Plot + labs(tag = "D")
fomCad2 <- ret$fomCad
fomRad2 <- ret$fomRad
```



```{r froc-paradigm-froc-vs-afroc-plot3, fig.cap="Plots A and B are for CAD $\\zeta_1 = -1$ and RAD $\\zeta_1 = -1$ and plots C and D are plots for CAD $\\zeta_1 = -\\infty$ and RAD $\\zeta_1 = -\\infty$. A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves.", fig.show='hold', echo=FALSE}
grid.arrange(froc1,wafroc1,froc2,wafroc2,nrow=2,ncol=2)
```


A misconception exists that using the rating of only one NL mark, as in wAFROC, must sacrifice statistical power. In fact, the chosen mark is a special one, namely the highest rated NL mark on a non-diseased case, which carries more information than a randomly chosen NL mark. If the sampling distribution of the z-sample were uniform, then the highest sample is a sufficient statistic, meaning that it carries all the information in the samples. The highest rated z-sampler from a normal distribution is not a sufficient statistic, so there is some loss of information, but not as much as would occur with a randomly picked z-sample.

 
(A)	 
(B)
 
(C)	 
(D)
Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot3): (A, B) FROC/wAFROC curves for CAD and RAD observers. The CAD observer is identical to that shown in Fig. \@ref(fig:froc-paradigm-froc-vs-afroc-plot2) (A, B). The RAD observer is characterized by mu = 1.1 and $\zeta_1$ = -1. This time it is possible to compare the two FROC curves, as the common NLF range is large. Both FROC and wAFROC show the expected slight superiority of the RAD observer. AUCs under the two wAFROC plots are 0.608 for CAD and 0.634 for RAD. Plots C and D correspond to A and B, respectively, with $\zeta_1$ = $-\infty$ for both observers. Since $\zeta_1$ in A and B is already quite small, lowering it to  $-\infty$ does not pick up too many marks. AUCs under the two wAFROC plots in D are 0.601 for CAD and 0.624 for RAD.
13.16.4: Other issues with the FROC
Loss of statistical power is not the only issue with the FROC. Because it counts NLs on both diseased and non-diseased cases, the curve depends on disease-prevalence in the dataset. Because the numbers of LLs per case is variable, the curve gives undue importance to those diseased cases with unusually large numbers of lesions. As noted in 13.16.2, the clinical importance of a NL on a non-diseased case differs from that on a diseased case. The FROC curve ignores this distinction.







## Discussion{#froc-paradigm-froc-vs-afroc-froc-vs-afrocs-Discussion}


## References {#froc-paradigm-froc-vs-afroc-froc-vs-afrocs-references}

