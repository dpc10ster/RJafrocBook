<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Sources of AUC variability | The RJafroc Book</title>
  <meta name="description" content="Updated observer-performance book based on RJafroc." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Sources of AUC variability | The RJafroc Book" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Updated observer-performance book based on RJafroc." />
  <meta name="github-repo" content="dpc10ster/RJafrocBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Sources of AUC variability | The RJafroc Book" />
  
  <meta name="twitter:description" content="Updated observer-performance book based on RJafroc." />
  

<meta name="author" content="Dev P. Chakraborty, PhD" />


<meta name="date" content="2020-09-17" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="BinormalModel.html"/>
<link rel="next" href="HypothesisTesting.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">RJafroc documentation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#a-note-on-the-online-distribution-mechanism-of-the-book"><i class="fa fa-check"></i>A note on the online distribution mechanism of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributing-to-this-book"><i class="fa fa-check"></i>Contributing to this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#is-this-book-relevant-to-you-and-what-are-the-alternatives"><i class="fa fa-check"></i>Is this book relevant to you and what are the alternatives?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#todos"><i class="fa fa-check"></i>ToDos</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>1</b> Preliminaries</a>
<ul>
<li class="chapter" data-level="1.1" data-path="preliminaries.html"><a href="preliminaries.html#preliminariesIntro"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="preliminaries.html"><a href="preliminaries.html#clinical-tasks"><i class="fa fa-check"></i><b>1.2</b> Clinical tasks</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="preliminaries.html"><a href="preliminaries.html#workflow-in-an-imaging-study"><i class="fa fa-check"></i><b>1.2.1</b> Workflow in an imaging study</a></li>
<li class="chapter" data-level="1.2.2" data-path="preliminaries.html"><a href="preliminaries.html#the-screening-and-diagnostic-workup-tasks"><i class="fa fa-check"></i><b>1.2.2</b> The screening and diagnostic workup tasks</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="preliminaries.html"><a href="preliminaries.html#imaging-device-development-and-its-clinical-deployment"><i class="fa fa-check"></i><b>1.3</b> Imaging device development and its clinical deployment</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="preliminaries.html"><a href="preliminaries.html#physical-measurements"><i class="fa fa-check"></i><b>1.3.1</b> Physical measurements</a></li>
<li class="chapter" data-level="1.3.2" data-path="preliminaries.html"><a href="preliminaries.html#quality-control-and-image-quality-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Quality Control and Image quality optimization</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="preliminaries.html"><a href="preliminaries.html#image-quality-vs.-task-performance"><i class="fa fa-check"></i><b>1.4</b> Image quality vs. task performance</a></li>
<li class="chapter" data-level="1.5" data-path="preliminaries.html"><a href="preliminaries.html#why-physical-measures-of-image-quality-are-not-enough"><i class="fa fa-check"></i><b>1.5</b> Why physical measures of image quality are not enough</a></li>
<li class="chapter" data-level="1.6" data-path="preliminaries.html"><a href="preliminaries.html#model-observers"><i class="fa fa-check"></i><b>1.6</b> Model observers</a></li>
<li class="chapter" data-level="1.7" data-path="preliminaries.html"><a href="preliminaries.html#measuring-observer-performance-four-paradigms"><i class="fa fa-check"></i><b>1.7</b> Measuring observer performance: four paradigms</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="preliminaries.html"><a href="preliminaries.html#basic-approach-to-the-analysis"><i class="fa fa-check"></i><b>1.7.1</b> Basic approach to the analysis</a></li>
<li class="chapter" data-level="1.7.2" data-path="preliminaries.html"><a href="preliminaries.html#historical-notes"><i class="fa fa-check"></i><b>1.7.2</b> Historical notes</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="preliminaries.html"><a href="preliminaries.html#hierarchy-of-assessment-methods"><i class="fa fa-check"></i><b>1.8</b> Hierarchy of assessment methods</a></li>
<li class="chapter" data-level="1.9" data-path="preliminaries.html"><a href="preliminaries.html#overview-of-the-book-and-how-to-use-it"><i class="fa fa-check"></i><b>1.9</b> Overview of the book and how to use it</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="preliminaries.html"><a href="preliminaries.html#overview-of-the-book"><i class="fa fa-check"></i><b>1.9.1</b> Overview of the book</a></li>
<li class="chapter" data-level="1.9.2" data-path="preliminaries.html"><a href="preliminaries.html#how-to-use-the-book"><i class="fa fa-check"></i><b>1.9.2</b> How to use the book</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-Summary"><i class="fa fa-check"></i><b>1.10</b> Summary</a></li>
<li class="chapter" data-level="1.11" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-Discussion"><i class="fa fa-check"></i><b>1.11</b> Discussion</a></li>
<li class="chapter" data-level="1.12" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-references"><i class="fa fa-check"></i><b>1.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="binaryTask0.html"><a href="binaryTask0.html"><i class="fa fa-check"></i><b>2</b> The Binary Task</a>
<ul>
<li class="chapter" data-level="2.1" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0Intro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0Truth"><i class="fa fa-check"></i><b>2.2</b> The fundamental 2x2 table</a></li>
<li class="chapter" data-level="2.3" data-path="binaryTask0.html"><a href="binaryTask0.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3</b> Sensitivity and specificity</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="binaryTask0.html"><a href="binaryTask0.html#reasons-for-the-names-sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3.1</b> Reasons for the names sensitivity and specificity</a></li>
<li class="chapter" data-level="2.3.2" data-path="binaryTask0.html"><a href="binaryTask0.html#estimating-sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3.2</b> Estimating sensitivity and specificity</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="binaryTask0.html"><a href="binaryTask0.html#disease-prevalence"><i class="fa fa-check"></i><b>2.4</b> Disease prevalence</a></li>
<li class="chapter" data-level="2.5" data-path="binaryTask0.html"><a href="binaryTask0.html#accuracy"><i class="fa fa-check"></i><b>2.5</b> Accuracy</a></li>
<li class="chapter" data-level="2.6" data-path="binaryTask0.html"><a href="binaryTask0.html#negative-and-positive-predictive-values"><i class="fa fa-check"></i><b>2.6</b> Negative and positive predictive values</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0NpvPpvCode"><i class="fa fa-check"></i><b>2.6.1</b> Example calculation of PPV, NPV and accuracy</a></li>
<li class="chapter" data-level="2.6.2" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0NpvPpvComments"><i class="fa fa-check"></i><b>2.6.2</b> Comments</a></li>
<li class="chapter" data-level="2.6.3" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0NpvPpvIrrel2LabTasks"><i class="fa fa-check"></i><b>2.6.3</b> PPV and NPV are irrelevant to laboratory tasks</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0-Summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0-Discussion"><i class="fa fa-check"></i><b>2.8</b> Discussion</a></li>
<li class="chapter" data-level="2.9" data-path="binaryTask0.html"><a href="binaryTask0.html#binaryTask0-references"><i class="fa fa-check"></i><b>2.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="binaryTask.html"><a href="binaryTask.html"><i class="fa fa-check"></i><b>3</b> Modeling the Binary Task</a>
<ul>
<li class="chapter" data-level="3.1" data-path="binaryTask.html"><a href="binaryTask.html#binaryTaskIntro"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="binaryTask.html"><a href="binaryTask.html#decision-variable-and-decision-threshold"><i class="fa fa-check"></i><b>3.2</b> Decision variable and decision threshold</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="binaryTask.html"><a href="binaryTask.html#existence-of-a-decision-variable"><i class="fa fa-check"></i><b>3.2.1</b> Existence of a decision variable</a></li>
<li class="chapter" data-level="3.2.2" data-path="binaryTask.html"><a href="binaryTask.html#existence-of-a-decision-threshold"><i class="fa fa-check"></i><b>3.2.2</b> Existence of a decision threshold</a></li>
<li class="chapter" data-level="3.2.3" data-path="binaryTask.html"><a href="binaryTask.html#adequacy-of-the-training-session"><i class="fa fa-check"></i><b>3.2.3</b> Adequacy of the training session</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="binaryTask.html"><a href="binaryTask.html#changing-the-decision-threshold-example-i"><i class="fa fa-check"></i><b>3.3</b> Changing the decision threshold: Example I</a></li>
<li class="chapter" data-level="3.4" data-path="binaryTask.html"><a href="binaryTask.html#changing-the-decision-threshold-example-ii"><i class="fa fa-check"></i><b>3.4</b> Changing the decision threshold: Example II</a></li>
<li class="chapter" data-level="3.5" data-path="binaryTask.html"><a href="binaryTask.html#the-equal-variance-binormal-model"><i class="fa fa-check"></i><b>3.5</b> The equal-variance binormal model</a></li>
<li class="chapter" data-level="3.6" data-path="binaryTask.html"><a href="binaryTask.html#the-normal-distribution"><i class="fa fa-check"></i><b>3.6</b> The normal distribution</a></li>
<li class="chapter" data-level="3.7" data-path="binaryTask.html"><a href="binaryTask.html#analytic-expressions-for-specificity-and-sensitivity"><i class="fa fa-check"></i><b>3.7</b> Analytic expressions for specificity and sensitivity</a></li>
<li class="chapter" data-level="3.8" data-path="binaryTask.html"><a href="binaryTask.html#demonstration-of-the-concepts-of-sensitivity-and-specificity"><i class="fa fa-check"></i><b>3.8</b> Demonstration of the concepts of sensitivity and specificity</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="binaryTask.html"><a href="binaryTask.html#estimating-mu-from-a-finite-sample"><i class="fa fa-check"></i><b>3.8.1</b> Estimating mu from a finite sample</a></li>
<li class="chapter" data-level="3.8.2" data-path="binaryTask.html"><a href="binaryTask.html#changing-the-seed-variable-case-sampling-variability"><i class="fa fa-check"></i><b>3.8.2</b> Changing the seed variable: case-sampling variability</a></li>
<li class="chapter" data-level="3.8.3" data-path="binaryTask.html"><a href="binaryTask.html#increasing-the-numbers-of-cases"><i class="fa fa-check"></i><b>3.8.3</b> Increasing the numbers of cases</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="binaryTask.html"><a href="binaryTask.html#inverse-variation-of-sensitivity-and-specificity-and-the-need-for-a-single-fom"><i class="fa fa-check"></i><b>3.9</b> Inverse variation of sensitivity and specificity and the need for a single FOM</a></li>
<li class="chapter" data-level="3.10" data-path="binaryTask.html"><a href="binaryTask.html#the-roc-curve"><i class="fa fa-check"></i><b>3.10</b> The ROC curve</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="binaryTask.html"><a href="binaryTask.html#the-chance-diagonal"><i class="fa fa-check"></i><b>3.10.1</b> The chance diagonal</a></li>
<li class="chapter" data-level="3.10.2" data-path="binaryTask.html"><a href="binaryTask.html#the-guessing-observer"><i class="fa fa-check"></i><b>3.10.2</b> The guessing observer</a></li>
<li class="chapter" data-level="3.10.3" data-path="binaryTask.html"><a href="binaryTask.html#symmetry-with-respect-to-negative-diagonal"><i class="fa fa-check"></i><b>3.10.3</b> Symmetry with respect to negative diagonal</a></li>
<li class="chapter" data-level="3.10.4" data-path="binaryTask.html"><a href="binaryTask.html#area-under-the-roc-curve"><i class="fa fa-check"></i><b>3.10.4</b> Area under the ROC curve</a></li>
<li class="chapter" data-level="3.10.5" data-path="binaryTask.html"><a href="binaryTask.html#properties-of-the-equal-variance-binormal-model-roc-curve"><i class="fa fa-check"></i><b>3.10.5</b> Properties of the equal-variance binormal model ROC curve</a></li>
<li class="chapter" data-level="3.10.6" data-path="binaryTask.html"><a href="binaryTask.html#comments"><i class="fa fa-check"></i><b>3.10.6</b> Comments</a></li>
<li class="chapter" data-level="3.10.7" data-path="binaryTask.html"><a href="binaryTask.html#physical-interpretation-of-the-mu-parameter"><i class="fa fa-check"></i><b>3.10.7</b> Physical interpretation of the mu-parameter</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="binaryTask.html"><a href="binaryTask.html#assigning-confidence-intervals-to-an-operating-point"><i class="fa fa-check"></i><b>3.11</b> Assigning confidence intervals to an operating point</a></li>
<li class="chapter" data-level="3.12" data-path="binaryTask.html"><a href="binaryTask.html#variability-in-sensitivity-and-specificity-the-beam-et-al-study"><i class="fa fa-check"></i><b>3.12</b> Variability in sensitivity and specificity: the Beam et al study</a></li>
<li class="chapter" data-level="3.13" data-path="binaryTask.html"><a href="binaryTask.html#binaryTask-Summary"><i class="fa fa-check"></i><b>3.13</b> Summary</a></li>
<li class="chapter" data-level="3.14" data-path="binaryTask.html"><a href="binaryTask.html#binaryTask-Discussion"><i class="fa fa-check"></i><b>3.14</b> Discussion</a></li>
<li class="chapter" data-level="3.15" data-path="binaryTask.html"><a href="binaryTask.html#binaryTask-references"><i class="fa fa-check"></i><b>3.15</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html"><i class="fa fa-check"></i><b>4</b> Ratings Paradigm</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-roc-counts-table"><i class="fa fa-check"></i><b>4.2</b> The ROC counts table</a></li>
<li class="chapter" data-level="4.3" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#operating-points-from-counts-table"><i class="fa fa-check"></i><b>4.3</b> Operating points from counts table</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#labeling-the-points"><i class="fa fa-check"></i><b>4.3.1</b> Labeling the points</a></li>
<li class="chapter" data-level="4.3.2" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#examples"><i class="fa fa-check"></i><b>4.3.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#automating-all-this"><i class="fa fa-check"></i><b>4.4</b> Automating all this</a></li>
<li class="chapter" data-level="4.5" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#relation-between-ratings-paradigm-and-the-binary-paradigm"><i class="fa fa-check"></i><b>4.5</b> Relation between ratings paradigm and the binary paradigm</a></li>
<li class="chapter" data-level="4.6" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratings-are-not-numerical-values"><i class="fa fa-check"></i><b>4.6</b> Ratings are not numerical values</a></li>
<li class="chapter" data-level="4.7" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#a-single-clinical-operating-point-from-ratings-data"><i class="fa fa-check"></i><b>4.7</b> A single “clinical” operating point from ratings data</a></li>
<li class="chapter" data-level="4.8" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-forced-choice-paradigm"><i class="fa fa-check"></i><b>4.8</b> The forced choice paradigm</a></li>
<li class="chapter" data-level="4.9" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#observer-performance-studies-as-laboratory-simulations-of-clinical-tasks"><i class="fa fa-check"></i><b>4.9</b> Observer performance studies as laboratory simulations of clinical tasks</a></li>
<li class="chapter" data-level="4.10" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#discrete-vs.-continuous-ratings-the-miller-study"><i class="fa fa-check"></i><b>4.10</b> Discrete vs. continuous ratings: the Miller study</a></li>
<li class="chapter" data-level="4.11" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-controversy"><i class="fa fa-check"></i><b>4.11</b> The controversy</a></li>
<li class="chapter" data-level="4.12" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratingsParadigm-discussion"><i class="fa fa-check"></i><b>4.12</b> Discussion</a></li>
<li class="chapter" data-level="4.13" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratingsParadigm-references"><i class="fa fa-check"></i><b>4.13</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="empirical-AUC.html"><a href="empirical-AUC.html"><i class="fa fa-check"></i><b>5</b> Empirical AUC</a>
<ul>
<li class="chapter" data-level="5.1" data-path="empirical-AUC.html"><a href="empirical-AUC.html#empirical-AUC-Intro"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="empirical-AUC.html"><a href="empirical-AUC.html#empirical-ROC-plot"><i class="fa fa-check"></i><b>5.2</b> The empirical ROC plot</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="empirical-AUC.html"><a href="empirical-AUC.html#notation-for-cases"><i class="fa fa-check"></i><b>5.2.1</b> Notation for cases</a></li>
<li class="chapter" data-level="5.2.2" data-path="empirical-AUC.html"><a href="empirical-AUC.html#an-empirical-operating-point"><i class="fa fa-check"></i><b>5.2.2</b> An empirical operating point</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="empirical-AUC.html"><a href="empirical-AUC.html#empirical-operating-points-from-ratings-data"><i class="fa fa-check"></i><b>5.3</b> Empirical operating points from ratings data</a></li>
<li class="chapter" data-level="5.4" data-path="empirical-AUC.html"><a href="empirical-AUC.html#auc-under-the-empirical-roc-plot"><i class="fa fa-check"></i><b>5.4</b> AUC under the empirical ROC plot</a></li>
<li class="chapter" data-level="5.5" data-path="empirical-AUC.html"><a href="empirical-AUC.html#the-wilcoxon-statistic"><i class="fa fa-check"></i><b>5.5</b> The Wilcoxon statistic</a></li>
<li class="chapter" data-level="5.6" data-path="empirical-AUC.html"><a href="empirical-AUC.html#bambers-equivalence-theorem"><i class="fa fa-check"></i><b>5.6</b> Bamber’s Equivalence theorem</a></li>
<li class="chapter" data-level="5.7" data-path="empirical-AUC.html"><a href="empirical-AUC.html#importance-of-bambers-theorem"><i class="fa fa-check"></i><b>5.7</b> Importance of Bamber’s theorem</a></li>
<li class="chapter" data-level="5.8" data-path="empirical-AUC.html"><a href="empirical-AUC.html#discussion-summary"><i class="fa fa-check"></i><b>5.8</b> Discussion / Summary</a></li>
<li class="chapter" data-level="5.9" data-path="empirical-AUC.html"><a href="empirical-AUC.html#appendix-5.a-details-of-wilcoxon-theorem"><i class="fa fa-check"></i><b>5.9</b> Appendix 5.A: Details of Wilcoxon theorem</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="empirical-AUC.html"><a href="empirical-AUC.html#upper-triangle"><i class="fa fa-check"></i><b>5.9.1</b> Upper triangle</a></li>
<li class="chapter" data-level="5.9.2" data-path="empirical-AUC.html"><a href="empirical-AUC.html#lowest-trapezoid"><i class="fa fa-check"></i><b>5.9.2</b> Lowest trapezoid</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="empirical-AUC.html"><a href="empirical-AUC.html#empirical-AUC-references"><i class="fa fa-check"></i><b>5.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="BinormalModel.html"><a href="BinormalModel.html"><i class="fa fa-check"></i><b>6</b> Binormal model</a>
<ul>
<li class="chapter" data-level="6.1" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModelIntro"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModelTheModel"><i class="fa fa-check"></i><b>6.2</b> The binormal model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="BinormalModel.html"><a href="BinormalModel.html#binning-the-data"><i class="fa fa-check"></i><b>6.2.1</b> Binning the data</a></li>
<li class="chapter" data-level="6.2.2" data-path="BinormalModel.html"><a href="BinormalModel.html#invariance-of-the-binormal-model-to-arbitrary-monotone-transformations"><i class="fa fa-check"></i><b>6.2.2</b> Invariance of the binormal model to arbitrary monotone transformations</a></li>
<li class="chapter" data-level="6.2.3" data-path="BinormalModel.html"><a href="BinormalModel.html#expressions-for-sensitivity-and-specificity"><i class="fa fa-check"></i><b>6.2.3</b> Expressions for sensitivity and specificity</a></li>
<li class="chapter" data-level="6.2.4" data-path="BinormalModel.html"><a href="BinormalModel.html#binormal-model-in-standard-notation"><i class="fa fa-check"></i><b>6.2.4</b> Binormal model in standard notation</a></li>
<li class="chapter" data-level="6.2.5" data-path="BinormalModel.html"><a href="BinormalModel.html#properties-of-the-binormal-model-roc-curve"><i class="fa fa-check"></i><b>6.2.5</b> Properties of the binormal model ROC curve</a></li>
<li class="chapter" data-level="6.2.6" data-path="BinormalModel.html"><a href="BinormalModel.html#density-functions-pdfs-of-the-binormal-model"><i class="fa fa-check"></i><b>6.2.6</b> Density functions (pdfs) of the binormal model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="BinormalModel.html"><a href="BinormalModel.html#fitting-an-roc-curve-to-data-points"><i class="fa fa-check"></i><b>6.3</b> Fitting an ROC curve to data points</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="BinormalModel.html"><a href="BinormalModel.html#a-java-fitted-roc-curve"><i class="fa fa-check"></i><b>6.3.1</b> A JAVA fitted ROC curve</a></li>
<li class="chapter" data-level="6.3.2" data-path="BinormalModel.html"><a href="BinormalModel.html#a-simplistic-straight-line-fit-to-the-roc-curve"><i class="fa fa-check"></i><b>6.3.2</b> A simplistic straight line fit to the ROC curve</a></li>
<li class="chapter" data-level="6.3.3" data-path="BinormalModel.html"><a href="BinormalModel.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>6.3.3</b> Maximum likelihood estimation (MLE)</a></li>
<li class="chapter" data-level="6.3.4" data-path="BinormalModel.html"><a href="BinormalModel.html#code-implementing-mle"><i class="fa fa-check"></i><b>6.3.4</b> Code implementing MLE</a></li>
<li class="chapter" data-level="6.3.5" data-path="BinormalModel.html"><a href="BinormalModel.html#validating-the-fitting-model"><i class="fa fa-check"></i><b>6.3.5</b> Validating the fitting model</a></li>
<li class="chapter" data-level="6.3.6" data-path="BinormalModel.html"><a href="BinormalModel.html#estimating-the-covariance-matrix"><i class="fa fa-check"></i><b>6.3.6</b> Estimating the covariance matrix</a></li>
<li class="chapter" data-level="6.3.7" data-path="BinormalModel.html"><a href="BinormalModel.html#estimating-the-variance-of-az"><i class="fa fa-check"></i><b>6.3.7</b> Estimating the variance of Az</a></li>
<li class="chapter" data-level="6.3.8" data-path="BinormalModel.html"><a href="BinormalModel.html#single-fom-derived-from-roc-curve"><i class="fa fa-check"></i><b>6.3.8</b> Single FOM derived from ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModel-Discussion"><i class="fa fa-check"></i><b>6.4</b> Discussion</a></li>
<li class="chapter" data-level="6.5" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModel-references"><i class="fa fa-check"></i><b>6.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html"><i class="fa fa-check"></i><b>7</b> Sources of AUC variability</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#sourcesVariabilityaucIntro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#sourcesVariabilityauc3sources"><i class="fa fa-check"></i><b>7.2</b> Three sources of variability</a></li>
<li class="chapter" data-level="7.3" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#dependence-of-auc-on-the-case-sample"><i class="fa fa-check"></i><b>7.3</b> Dependence of AUC on the case sample</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#case-sampling-induced-variability-of-auc"><i class="fa fa-check"></i><b>7.3.1</b> Case sampling induced variability of AUC</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#estimating-case-sampling-variability-using-the-delong-method"><i class="fa fa-check"></i><b>7.4</b> Estimating case-sampling variability using the DeLong method</a></li>
<li class="chapter" data-level="7.5" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#bootstrap-estimation-of-auc-case-sampling-variability"><i class="fa fa-check"></i><b>7.5</b> Bootstrap estimation of AUC case-sampling variability</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#demonstration-of-the-bootstrap-method"><i class="fa fa-check"></i><b>7.5.1</b> Demonstration of the bootstrap method</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#jackknife-estimation-of-auc-case-sampling-variability"><i class="fa fa-check"></i><b>7.6</b> Jackknife estimation of AUC case-sampling variability</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#estimating-auc-case-sampling-variability-using-calibrated-simulator"><i class="fa fa-check"></i><b>7.6.1</b> Estimating AUC case-sampling variability using calibrated simulator</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#dependence-of-auc-on-reader-expertise"><i class="fa fa-check"></i><b>7.7</b> Dependence of AUC on reader expertise</a></li>
<li class="chapter" data-level="7.8" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#dependence-of-auc-on-modality"><i class="fa fa-check"></i><b>7.8</b> Dependence of AUC on modality</a></li>
<li class="chapter" data-level="7.9" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#effect-on-empirical-auc-of-variations-in-thresholds-and-numbers-of-bins"><i class="fa fa-check"></i><b>7.9</b> Effect on empirical AUC of variations in thresholds and numbers of bins</a></li>
<li class="chapter" data-level="7.10" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#empirical-vs.-fitted-aucs"><i class="fa fa-check"></i><b>7.10</b> Empirical vs. fitted AUCs</a></li>
<li class="chapter" data-level="7.11" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#sourcesVariabilityauc-Discussion"><i class="fa fa-check"></i><b>7.11</b> Discussion</a></li>
<li class="chapter" data-level="7.12" data-path="sourcesVariabilityauc.html"><a href="sourcesVariabilityauc.html#sourcesVariabilityauc-references"><i class="fa fa-check"></i><b>7.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTesting-introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#single-modality-single-reader-roc-study"><i class="fa fa-check"></i><b>8.2</b> Single-modality single-reader ROC study</a></li>
<li class="chapter" data-level="8.3" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#type-i-errors"><i class="fa fa-check"></i><b>8.3</b> Type-I errors</a></li>
<li class="chapter" data-level="8.4" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#one-vs.-two-sided-tests"><i class="fa fa-check"></i><b>8.4</b> One vs. two sided tests</a></li>
<li class="chapter" data-level="8.5" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#statistical-power"><i class="fa fa-check"></i><b>8.5</b> Statistical power</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#factors-affecting-statistical-power"><i class="fa fa-check"></i><b>8.5.1</b> Factors affecting statistical power</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTestingComments"><i class="fa fa-check"></i><b>8.6</b> Comments</a></li>
<li class="chapter" data-level="8.7" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#why-alpha-is-chosen-as-5"><i class="fa fa-check"></i><b>8.7</b> Why alpha is chosen as 5%</a></li>
<li class="chapter" data-level="8.8" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTestingDiscussion"><i class="fa fa-check"></i><b>8.8</b> Discussion</a></li>
<li class="chapter" data-level="8.9" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTesting-references"><i class="fa fa-check"></i><b>8.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html"><i class="fa fa-check"></i><b>9</b> DBM method background</a>
<ul>
<li class="chapter" data-level="9.1" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-introduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#historical-background"><i class="fa fa-check"></i><b>9.1.1</b> Historical background</a></li>
<li class="chapter" data-level="9.1.2" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#the-wagner-analogy"><i class="fa fa-check"></i><b>9.1.2</b> The Wagner analogy</a></li>
<li class="chapter" data-level="9.1.3" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#the-shortage-of-numbers-to-analyze-and-a-pivotal-breakthrough"><i class="fa fa-check"></i><b>9.1.3</b> The shortage of numbers to analyze and a pivotal breakthrough</a></li>
<li class="chapter" data-level="9.1.4" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#organization-of-chapter"><i class="fa fa-check"></i><b>9.1.4</b> Organization of chapter</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-random-fixed-factors"><i class="fa fa-check"></i><b>9.2</b> Random and fixed factors</a></li>
<li class="chapter" data-level="9.3" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-reader-case-populations"><i class="fa fa-check"></i><b>9.3</b> Reader and case populations</a></li>
<li class="chapter" data-level="9.4" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-threeAnalyses"><i class="fa fa-check"></i><b>9.4</b> Three types of analyses</a></li>
<li class="chapter" data-level="9.5" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-approach"><i class="fa fa-check"></i><b>9.5</b> General approach</a></li>
<li class="chapter" data-level="9.6" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-summary"><i class="fa fa-check"></i><b>9.6</b> Summary TBA</a></li>
<li class="chapter" data-level="9.7" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-references"><i class="fa fa-check"></i><b>9.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html"><i class="fa fa-check"></i><b>10</b> Significance Testing using the DBM Method</a>
<ul>
<li class="chapter" data-level="10.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-dbm-sampling-model"><i class="fa fa-check"></i><b>10.1</b> The DBM sampling model</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#explanation-of-terms-in-the-model"><i class="fa fa-check"></i><b>10.1.1</b> Explanation of terms in the model</a></li>
<li class="chapter" data-level="10.1.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#meanings-of-variance-components-in-the-dbm-model-tba-this-section-can-be-improved"><i class="fa fa-check"></i><b>10.1.2</b> Meanings of variance components in the DBM model (<strong>TBA this section can be improved</strong>)</a></li>
<li class="chapter" data-level="10.1.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#definitions-of-mean-squares"><i class="fa fa-check"></i><b>10.1.3</b> Definitions of mean-squares</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#expected-values-of-mean-squares"><i class="fa fa-check"></i><b>10.2</b> Expected values of mean squares</a></li>
<li class="chapter" data-level="10.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-RRRC-analysis"><i class="fa fa-check"></i><b>10.3</b> Random-reader random-case (RRRC) analysis</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#calculation-of-mean-squares-an-example"><i class="fa fa-check"></i><b>10.3.1</b> Calculation of mean squares: an example</a></li>
<li class="chapter" data-level="10.3.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-sig-testing"><i class="fa fa-check"></i><b>10.3.2</b> Significance testing</a></li>
<li class="chapter" data-level="10.3.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-satterthwaite-approximation"><i class="fa fa-check"></i><b>10.3.3</b> The Satterthwaite approximation</a></li>
<li class="chapter" data-level="10.3.4" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#decision-rules-p-value-and-confidence-intervals"><i class="fa fa-check"></i><b>10.3.4</b> Decision rules, p-value and confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#sample-size-estimation-for-random-reader-random-case-generalization"><i class="fa fa-check"></i><b>10.4</b> Sample size estimation for random-reader random-case generalization</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-non-centrality-parameter"><i class="fa fa-check"></i><b>10.4.1</b> The non-centrality parameter</a></li>
<li class="chapter" data-level="10.4.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-denominator-degrees-of-freedom"><i class="fa fa-check"></i><b>10.4.2</b> The denominator degrees of freedom</a></li>
<li class="chapter" data-level="10.4.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#example-of-sample-size-estimation-rrrc-generalization"><i class="fa fa-check"></i><b>10.4.3</b> Example of sample size estimation, RRRC generalization</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#significance-testing-and-sample-size-estimation-for-fixed-reader-random-case-generalization"><i class="fa fa-check"></i><b>10.5</b> Significance testing and sample size estimation for fixed-reader random-case generalization</a></li>
<li class="chapter" data-level="10.6" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#significance-testing-and-sample-size-estimation-for-random-reader-fixed-case-generalization"><i class="fa fa-check"></i><b>10.6</b> Significance testing and sample size estimation for random-reader fixed-case generalization</a></li>
<li class="chapter" data-level="10.7" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-summary"><i class="fa fa-check"></i><b>10.7</b> Summary TBA</a></li>
<li class="chapter" data-level="10.8" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#things-for-me-to-think-about"><i class="fa fa-check"></i><b>10.8</b> Things for me to think about</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#expected-values-of-mean-squares-1"><i class="fa fa-check"></i><b>10.8.1</b> Expected values of mean squares</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-references"><i class="fa fa-check"></i><b>10.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html"><i class="fa fa-check"></i><b>11</b> DBM method special cases</a>
<ul>
<li class="chapter" data-level="11.1" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#FRRCDBMAnalysis"><i class="fa fa-check"></i><b>11.1</b> Fixed-reader random-case (FRRC) analysis</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#FRRCSingleReaderDBMAnalysis"><i class="fa fa-check"></i><b>11.1.1</b> Single-reader multiple-treatment analysis</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#DBMSpecialCases-RRFCAnalysis"><i class="fa fa-check"></i><b>11.2</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="11.3" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#DBMSpecialCases-references"><i class="fa fa-check"></i><b>11.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html"><i class="fa fa-check"></i><b>12</b> Introduction to the Obuchowski-Rockette method</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#OR1RMTModel"><i class="fa fa-check"></i><b>12.2</b> Single-reader multiple-treatment</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#definitions-of-covariance-and-correlation"><i class="fa fa-check"></i><b>12.2.1</b> Definitions of covariance and correlation</a></li>
<li class="chapter" data-level="12.2.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#special-case-when-variables-have-equal-variances"><i class="fa fa-check"></i><b>12.2.2</b> Special case when variables have equal variances</a></li>
<li class="chapter" data-level="12.2.3" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#estimating-the-variance-covariance-matrix"><i class="fa fa-check"></i><b>12.2.3</b> Estimating the variance-covariance matrix</a></li>
<li class="chapter" data-level="12.2.4" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#the-variance-inflation-factor"><i class="fa fa-check"></i><b>12.2.4</b> The variance inflation factor</a></li>
<li class="chapter" data-level="12.2.5" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#meaning-of-the-covariance-matrix-in-eqn.-refeqexamplesigma"><i class="fa fa-check"></i><b>12.2.5</b> Meaning of the covariance matrix in Eqn. @ref(eq:ExampleSigma)</a></li>
<li class="chapter" data-level="12.2.6" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#code-illustrating-the-covariance-matrix"><i class="fa fa-check"></i><b>12.2.6</b> Code illustrating the covariance matrix</a></li>
<li class="chapter" data-level="12.2.7" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#SignificanceTesting1ROR"><i class="fa fa-check"></i><b>12.2.7</b> Significance testing</a></li>
<li class="chapter" data-level="12.2.8" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-pvalue-ci"><i class="fa fa-check"></i><b>12.2.8</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="12.2.9" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-CompareDBM2OR41R"><i class="fa fa-check"></i><b>12.2.9</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#SignificanceTestingORMRMC"><i class="fa fa-check"></i><b>12.3</b> Multiple-reader multiple-treatment</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#StrCovMatrix"><i class="fa fa-check"></i><b>12.3.1</b> Structure of the covariance matrix</a></li>
<li class="chapter" data-level="12.3.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#PhysicalMeaningsOfCovMatrix"><i class="fa fa-check"></i><b>12.3.2</b> Physical meanings of the covariance terms</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-Summary"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
<li class="chapter" data-level="12.5" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-Discussion"><i class="fa fa-check"></i><b>12.5</b> Discussion</a></li>
<li class="chapter" data-level="12.6" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-references"><i class="fa fa-check"></i><b>12.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html"><i class="fa fa-check"></i><b>13</b> Obuchowski Rockette (OR) Analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-introduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#OR_RRRC"><i class="fa fa-check"></i><b>13.2</b> Random-reader random-case</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#TwoAnecdotes"><i class="fa fa-check"></i><b>13.2.1</b> Two anecdotes</a></li>
<li class="chapter" data-level="13.2.2" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#Hills-ddf"><i class="fa fa-check"></i><b>13.2.2</b> Hillis ddf</a></li>
<li class="chapter" data-level="13.2.3" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#decision-rule-p-value-and-confidence-interval"><i class="fa fa-check"></i><b>13.2.3</b> Decision rule, p-value and confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#OR-FRRC"><i class="fa fa-check"></i><b>13.3</b> Fixed-reader random-case</a></li>
<li class="chapter" data-level="13.4" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-RRFCAnalysis"><i class="fa fa-check"></i><b>13.4</b> Random-reader fixed-case</a></li>
<li class="chapter" data-level="13.5" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-Summary"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
<li class="chapter" data-level="13.6" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-Discussion"><i class="fa fa-check"></i><b>13.6</b> Discussion</a></li>
<li class="chapter" data-level="13.7" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-references"><i class="fa fa-check"></i><b>13.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ORApplications.html"><a href="ORApplications.html"><i class="fa fa-check"></i><b>14</b> Obuchowski Rockette Applications</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-introduction"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset02-hand"><i class="fa fa-check"></i><b>14.2</b> Hand calculation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.2.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.2.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3</b> RJafroc: dataset02</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.3.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.3.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-RJafroc"><i class="fa fa-check"></i><b>14.4</b> RJafroc: dataset04</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04"><i class="fa fa-check"></i><b>14.4.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.4.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04"><i class="fa fa-check"></i><b>14.4.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.4.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04"><i class="fa fa-check"></i><b>14.4.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-FROC-RJafroc"><i class="fa fa-check"></i><b>14.5</b> RJafroc: dataset04, FROC</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.5.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.5.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-FROC-DBM-RJafroc"><i class="fa fa-check"></i><b>14.6</b> RJafroc: dataset04, FROC/DBM</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.6.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.6.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-Summary"><i class="fa fa-check"></i><b>14.7</b> Summary</a></li>
<li class="chapter" data-level="14.8" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-Discussion"><i class="fa fa-check"></i><b>14.8</b> Discussion</a></li>
<li class="chapter" data-level="14.9" data-path="ORApplications.html"><a href="ORApplications.html#ToMullOver1-tentative"><i class="fa fa-check"></i><b>14.9</b> Tentative</a></li>
<li class="chapter" data-level="14.10" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-references"><i class="fa fa-check"></i><b>14.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html"><i class="fa fa-check"></i><b>15</b> Sample size estimation for ROC studies DBM method</a>
<ul>
<li class="chapter" data-level="15.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-introduction"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#StatPower1"><i class="fa fa-check"></i><b>15.2</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#observed-vs.-anticipated-effect-size"><i class="fa fa-check"></i><b>15.2.1</b> Observed vs. anticipated effect-size</a></li>
<li class="chapter" data-level="15.2.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-dependence-of-stats-power"><i class="fa fa-check"></i><b>15.2.2</b> Dependence of statistical power on estimates of model parameters</a></li>
<li class="chapter" data-level="15.2.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRRC-sample-size-estimation"><i class="fa fa-check"></i><b>15.2.3</b> Formulae for random-reader random-case (RRRC) sample size estimation</a></li>
<li class="chapter" data-level="15.2.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-sig-testing"><i class="fa fa-check"></i><b>15.2.4</b> Significance testing</a></li>
<li class="chapter" data-level="15.2.5" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-pvalue-ci"><i class="fa fa-check"></i><b>15.2.5</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="15.2.6" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-CompareDBM2OR"><i class="fa fa-check"></i><b>15.2.6</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-FRRC-sample-size-estimation"><i class="fa fa-check"></i><b>15.3</b> Formulae for fixed-reader random-case (FRRC) sample size estimation</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRFC-sample-size-estimation"><i class="fa fa-check"></i><b>15.3.1</b> Formulae for random-reader fixed-case (RRFC) sample size estimation</a></li>
<li class="chapter" data-level="15.3.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-FRRCAnalysis"><i class="fa fa-check"></i><b>15.3.2</b> Fixed-reader random-case (FRRC) analysis TBA</a></li>
<li class="chapter" data-level="15.3.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRFCAnalysis"><i class="fa fa-check"></i><b>15.3.3</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="15.3.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-STMRAnalysis"><i class="fa fa-check"></i><b>15.3.4</b> Single-treatment multiple-reader analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#discussionsummary2"><i class="fa fa-check"></i><b>15.4</b> Discussion/Summary/2</a></li>
<li class="chapter" data-level="15.5" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-references"><i class="fa fa-check"></i><b>15.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html"><i class="fa fa-check"></i><b>16</b> Sample size estimation for ROC studies OR method</a>
<ul>
<li class="chapter" data-level="16.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-introduction"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#StatPower2"><i class="fa fa-check"></i><b>16.2</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#sample-size-estimation-for-random-reader-random-cases"><i class="fa fa-check"></i><b>16.2.1</b> Sample size estimation for random-reader random-cases</a></li>
<li class="chapter" data-level="16.2.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-dependence-of-stats-power"><i class="fa fa-check"></i><b>16.2.2</b> Dependence of statistical power on estimates of model parameters</a></li>
<li class="chapter" data-level="16.2.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRRC-sample-size-estimation"><i class="fa fa-check"></i><b>16.2.3</b> Formulae for random-reader random-case (RRRC) sample size estimation</a></li>
<li class="chapter" data-level="16.2.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-sig-testing"><i class="fa fa-check"></i><b>16.2.4</b> Significance testing</a></li>
<li class="chapter" data-level="16.2.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-pvalue-ci"><i class="fa fa-check"></i><b>16.2.5</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="16.2.6" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-CompareDBM2OR"><i class="fa fa-check"></i><b>16.2.6</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-FRRC-sample-size-estimation"><i class="fa fa-check"></i><b>16.3</b> Formulae for fixed-reader random-case (FRRC) sample size estimation</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRFC-sample-size-estimation"><i class="fa fa-check"></i><b>16.3.1</b> Formulae for random-reader fixed-case (RRFC) sample size estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#example-1"><i class="fa fa-check"></i><b>16.3.2</b> Example 1</a></li>
<li class="chapter" data-level="16.3.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-FRRCAnalysis"><i class="fa fa-check"></i><b>16.3.3</b> Fixed-reader random-case (FRRC) analysis</a></li>
<li class="chapter" data-level="16.3.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRFCAnalysis"><i class="fa fa-check"></i><b>16.3.4</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="16.3.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-STMRAnalysis"><i class="fa fa-check"></i><b>16.3.5</b> Single-treatment multiple-reader analysis</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#discussionsummary3"><i class="fa fa-check"></i><b>16.4</b> Discussion/Summary/3</a></li>
<li class="chapter" data-level="16.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-references"><i class="fa fa-check"></i><b>16.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html"><i class="fa fa-check"></i><b>17</b> Split Plot Study Design</a>
<ul>
<li class="chapter" data-level="17.1" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#mean-square-rt"><i class="fa fa-check"></i><b>17.1</b> Mean Square R(T)</a></li>
<li class="chapter" data-level="17.2" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#SplitPlotChapter-references"><i class="fa fa-check"></i><b>17.2</b> References</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>REFERENCES</a></li>
<li class="part"><span><b>APPENDICES</b></span></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="rocdataformat.html"><a href="rocdataformat.html"><i class="fa fa-check"></i><b>A</b> ROC DATA FORMAT</a>
<ul>
<li class="chapter" data-level="A.1" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformatIntro"><i class="fa fa-check"></i><b>A.1</b> Introduction</a></li>
<li class="chapter" data-level="A.2" data-path="rocdataformat.html"><a href="rocdataformat.html#note-to-existing-users"><i class="fa fa-check"></i><b>A.2</b> Note to existing users</a></li>
<li class="chapter" data-level="A.3" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExceldataformat"><i class="fa fa-check"></i><b>A.3</b> The Excel data format</a></li>
<li class="chapter" data-level="A.4" data-path="rocdataformat.html"><a href="rocdataformat.html#illustrative-toy-file"><i class="fa fa-check"></i><b>A.4</b> Illustrative toy file</a></li>
<li class="chapter" data-level="A.5" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelTruthdataformat"><i class="fa fa-check"></i><b>A.5</b> The <code>Truth</code> worksheet</a></li>
<li class="chapter" data-level="A.6" data-path="rocdataformat.html"><a href="rocdataformat.html#the-structure-of-an-roc-dataset"><i class="fa fa-check"></i><b>A.6</b> The structure of an ROC dataset</a></li>
<li class="chapter" data-level="A.7" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelFPdataformat"><i class="fa fa-check"></i><b>A.7</b> The false positive (FP) ratings</a></li>
<li class="chapter" data-level="A.8" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelTPdataformat"><i class="fa fa-check"></i><b>A.8</b> The true positive (TP) ratings</a></li>
<li class="chapter" data-level="A.9" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-between-nl-member-of-dataset-and-the-fp-worksheet"><i class="fa fa-check"></i><b>A.9</b> Correspondence between <code>NL</code> member of dataset and the <code>FP</code> worksheet</a></li>
<li class="chapter" data-level="A.10" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-between-ll-member-of-dataset-and-the-tp-worksheet"><i class="fa fa-check"></i><b>A.10</b> Correspondence between <code>LL</code> member of dataset and the <code>TP</code> worksheet</a></li>
<li class="chapter" data-level="A.11" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-using-the-which-function"><i class="fa fa-check"></i><b>A.11</b> Correspondence using the <code>which</code> function</a></li>
<li class="chapter" data-level="A.12" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-Summary"><i class="fa fa-check"></i><b>A.12</b> Summary</a></li>
<li class="chapter" data-level="A.13" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-Discussion"><i class="fa fa-check"></i><b>A.13</b> Discussion</a></li>
<li class="chapter" data-level="A.14" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-references"><i class="fa fa-check"></i><b>A.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="frocdataformat.html"><a href="frocdataformat.html"><i class="fa fa-check"></i><b>B</b> FROC data format</a>
<ul>
<li class="chapter" data-level="B.1" data-path="frocdataformat.html"><a href="frocdataformat.html#purpose"><i class="fa fa-check"></i><b>B.1</b> Purpose</a></li>
<li class="chapter" data-level="B.2" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformatIntro"><i class="fa fa-check"></i><b>B.2</b> Introduction</a></li>
<li class="chapter" data-level="B.3" data-path="frocdataformat.html"><a href="frocdataformat.html#frocExceldataformat"><i class="fa fa-check"></i><b>B.3</b> The Excel data format</a></li>
<li class="chapter" data-level="B.4" data-path="frocdataformat.html"><a href="frocdataformat.html#frocExcelTruthdataformat"><i class="fa fa-check"></i><b>B.4</b> The <code>Truth</code> worksheet</a></li>
<li class="chapter" data-level="B.5" data-path="frocdataformat.html"><a href="frocdataformat.html#the-structure-of-an-froc-dataset"><i class="fa fa-check"></i><b>B.5</b> The structure of an FROC dataset</a></li>
<li class="chapter" data-level="B.6" data-path="frocdataformat.html"><a href="frocdataformat.html#the-false-positive-fp-ratings"><i class="fa fa-check"></i><b>B.6</b> The false positive (FP) ratings</a></li>
<li class="chapter" data-level="B.7" data-path="frocdataformat.html"><a href="frocdataformat.html#the-true-positive-tp-ratings"><i class="fa fa-check"></i><b>B.7</b> The true positive (TP) ratings</a></li>
<li class="chapter" data-level="B.8" data-path="frocdataformat.html"><a href="frocdataformat.html#on-the-distribution-of-numbers-of-lesions-in-abnormal-cases"><i class="fa fa-check"></i><b>B.8</b> On the distribution of numbers of lesions in abnormal cases</a>
<ul>
<li class="chapter" data-level="B.8.1" data-path="frocdataformat.html"><a href="frocdataformat.html#definition-of-lesdistr-array"><i class="fa fa-check"></i><b>B.8.1</b> Definition of <code>lesDistr</code> array</a></li>
</ul></li>
<li class="chapter" data-level="B.9" data-path="frocdataformat.html"><a href="frocdataformat.html#definition-of-leswghtdistr-array"><i class="fa fa-check"></i><b>B.9</b> Definition of <code>lesWghtDistr</code> array</a></li>
<li class="chapter" data-level="B.10" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-Summary"><i class="fa fa-check"></i><b>B.10</b> Summary</a></li>
<li class="chapter" data-level="B.11" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-Discussion"><i class="fa fa-check"></i><b>B.11</b> Discussion</a></li>
<li class="chapter" data-level="B.12" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-references"><i class="fa fa-check"></i><b>B.12</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">The RJafroc Book</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sourcesVariabilityauc" class="section level1" number="7">
<h1><span class="header-section-number">Chapter 7</span> Sources of AUC variability</h1>
<div id="sourcesVariabilityaucIntro" class="section level2" number="7.1">
<h2><span class="header-section-number">7.1</span> Introduction</h2>
<p>In previous chapters the area AUC under the ROC plot was introduced as the preferred way of summarizing performance in the ROC task, as compared to a pair of sensitivity and specificity values. It can be estimated either non-parametrically, as in Chapter <a href="empirical-AUC.html#empirical-AUC">5</a>, or parametrically, as in Chapter <a href="BinormalModel.html#BinormalModel">6</a>, and even better ways of estimating it are described in TBA Chapter 18 and Chapter 20.</p>
<p>Irrespective of how it is estimated AUC is a realization of a random variable, and as such, it is subject to sampling variability. Any measurement based on a finite number of samples from a parent population is subject to sampling variability. This is because no finite sample is unique: someone else conducting a similar study would, in general, obtain a different sample. [Case-sampling variability is estimated by the binormal model in the previous chapter. It is related to the sharpness of the peak of the likelihood function, §6.4.4. The sharper that the peak, the smaller the case sampling variability. This chapter focuses on general sources of variability affecting AUC, regardless of how it is estimated, and other (i.e., not binormal model based) ways of estimating it.]</p>
<p>Here is an outline of this chapter. The starting point is the identification of different sources of variability affecting AUC estimates. Considered next is dependence of AUC on the case-set index <span class="math inline">\(\{c\}\)</span>, <span class="math inline">\(c = 1,2,...,C\)</span>. Considered next is estimating case-sampling variability of the empirical estimate of AUC by an analytic method. This is followed by descriptions of two resampling-based methods, namely the bootstrap and the jackknife, both of which have wide applicability (i.e., they are not restricted to ROC analysis). The methods are demonstrated using <code>R</code> code and the implementation of a calibrated simulator is shown and used to demonstrate their validity, i.e., showing that the different methods of estimating variability agree. The dependence of AUC on reader expertise and modality is considered. An important source of variability, namely the radiologist’s choice of internal sensory thresholds, is described. A cautionary comment is made regarding indiscriminate usage of empirical AUC as a measure of performance.</p>
<p>TBA Online Appendix 7.A describes coding of the bootstrap method; Online Appendix 7.B is the corresponding implementation of the jackknife method. Online Appendix 7.C describes implementation of the calibrated simulator for single-modality single-reader ROC datasets. Online Appendix 7.D describes the code that allows comparison of the different methods of estimating case-sampling variability.</p>
</div>
<div id="sourcesVariabilityauc3sources" class="section level2" number="7.2">
<h2><span class="header-section-number">7.2</span> Three sources of variability</h2>
<p>Statistics deals with variability. Understanding sources of variability affecting AUC is critical to an appreciation of ROC analysis. Three sources of variability are identified in <span class="citation">(Swets and Pickett <a href="#ref-RN412" role="doc-biblioref">1982</a>)</span>: case sampling, between-reader and within-reader variability.</p>
<ol style="list-style-type: decimal">
<li>Consider a single reader interpreting different case samples. Case-sampling variability arises from the finite number of cases comprising the dataset, compared to the potentially very large population of cases. [If one could sample every case there exists and have them interpreted by the same reader, there would be no case-sampling variability and the poor reader’s AUC values (from repeated interpretations of the entire population) would reflect only within reader variability, see #3 below.] Each case-set <span class="math inline">\(\{c\}\)</span>, consisting of <span class="math inline">\(K_1\)</span> non-diseased and <span class="math inline">\(K_2\)</span> diseased cases interpreted by the reader, yields an AUC value. The notation <span class="math inline">\(\{c\}\)</span> means different <em>case sets</em>. Thus <span class="math inline">\(\{c\}\)</span> = <span class="math inline">\(\{1\}\)</span>, <span class="math inline">\(\{2\}\)</span>, etc., denote different case sets, each consisting of <span class="math inline">\(K_1\)</span> non-diseased and <span class="math inline">\(K_2\)</span> diseased cases.</li>
</ol>
<p>There is much “data compression” in going from individual case ratings to AUC. For a single reader and given case-set <span class="math inline">\(\{c\}\)</span>, the ratings can be converted to an <span class="math inline">\(A_{z\{c\}}\)</span> estimate, TBA Eqn. (6.49). The notation shows explicitly the dependence of the measure on the case-set <span class="math inline">\(\{c\}\)</span>. One can conceptualize the distribution of <span class="math inline">\(A_{z\{c\}}\)</span>’s over different case-sets, each of the same size <span class="math inline">\(K_1+K_2\)</span>, as a normal distribution, i.e.,</p>
<p><span class="math display" id="eq:sourcesVariabilityauc-cs-wr">\[\begin{equation} 
A_{z\{c\}}\sim N(A_{z\{\bullet\}},\sigma_{\text{cs+wr}}^2)
\tag{7.1}
\end{equation}\]</span></p>
<p>The dot notation <span class="math inline">\(\{\bullet\}\)</span> denotes an average over all case sets. Thus, <span class="math inline">\(A_{z\{\bullet\}}\)</span> is an estimate of the case-sampling mean of <span class="math inline">\(A_z\)</span> for a single fixed reader and <span class="math inline">\(\sigma_{\text{cs+wr}}^2\)</span> is the <em>case sampling plus within-reader</em> variance. The reason for adding the within-reader variance is explained in #3 below. The concept is that a specified reader interpreting different case-sets effectively samples different parts of the population of cases, resulting in variability in measured <span class="math inline">\(A_z\)</span>. Sometimes easier cases are sampled, and sometimes more difficult ones. This source of variability is expected to decrease with increasing case-set size, i.e., increasing <span class="math inline">\(K_1+K_2\)</span>, which is the reason for seeking large numbers of cases in clinical trials. Case-sampling and within-reader variability also decreases as the cases become more homogenous. An example of a more homogenous case sample would be cases originating from a small geographical region with, for example, limited ethnic variability. This is the reason for seeking multi-institutional clinical trials, because they tend to sample more of the population than patients seen at a single institution.</p>
<ol start="2" style="list-style-type: decimal">
<li>Consider different readers interpreting a fixed case sample. Between-reader variability arises from the finite number of readers compared to the population of readers; the population of readers could be all board certified radiologists interpreting screening mammograms in the US. This time one envisages different readers interpreting a fixed case set <span class="math inline">\(\{1\}\)</span>. The different reader’s <span class="math inline">\(A_{z;j}\)</span> values (<span class="math inline">\(j\)</span> is the reader index, <span class="math inline">\(j = 1, 2, ..., J\)</span>, where <span class="math inline">\(J\)</span> is the total number of readers in the dataset) are distributed:</li>
</ol>
<p><span class="math display" id="eq:sourcesVariabilityauc-br-wr">\[\begin{equation} 
A_{z;j}\sim N(A_{z;\bullet},\sigma_{\text{br+wr}}^2)
\tag{7.2}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(A_{z;\bullet}\)</span> is an estimate of the reader population AUC mean (the bullet symbol replacing the reader index averages over a set of readers) for the fixed case-set <span class="math inline">\(\{1\}\)</span> and <span class="math inline">\(\sigma_{\text{br+wr}}^2\)</span> is the <em>between-reader plus within-reader</em> variance. The reason for adding the within-reader variance is explained in #3 below. The concept is that different groups of <span class="math inline">\(J\)</span> readers interpret the same case set <span class="math inline">\(\{1\}\)</span>, thereby sampling different parts of the reader distribution, causing fluctuations in the measured <span class="math inline">\(A_{z;j}\)</span> of the readers. Sometimes better readers are sampled and sometimes not so good ones are sampled. This time there is no “data compression” – each reader in the sample has an associated <span class="math inline">\(A_{z;j}\)</span>. However, variability of the average <span class="math inline">\(A_{z;\bullet}\)</span> over the <span class="math inline">\(J\)</span> readers is expected to decrease with increasing <span class="math inline">\(J\)</span>. This is the reason for seeking large reader-samples.</p>
<ol start="3" style="list-style-type: decimal">
<li>Consider a fixed reader, e.g., <span class="math inline">\(j = 1\)</span>, interpreting a fixed case-sample <span class="math inline">\(\{1\}\)</span>. Within-reader variability is due to variability of the ratings for the same case: the same reader interpreting the same case on different occasions will give different ratings to it, causing fluctuations in the measured AUC. This assumes that memory effects are minimized, for example, by sufficient time between successive interpretations as otherwise, if a case is shown twice in succession, the reader would give it the same rating each time. Since this is an intrinsic source of variability (analogous to the internal noise of a voltmeter) affecting each reader’s interpretations, it cannot be separated from case sampling variability, i.e., it cannot be “turned off”. The last sentence needs further explanation. A measurement of case-sampling variability requires a reader, and the reader comes with an intrinsic source of variability that gets added to the case-sampling variance, so what is measured is the sum of case sampling and within-reader variances, denoted <span class="math inline">\(\sigma_{\text{cs+wr}}^2\)</span>. Likewise, a measurement of between-reader variability requires a fixed case-set interpreted by different readers, each of whom comes with an intrinsic source of variability that gets added to the between-reader variance, yielding <span class="math inline">\(\sigma_{\text{br+wr}}^2\)</span>. To emphasize this point, an estimate of case-sampling variability <em>always</em> includes within reader variability. Likewise, an estimate of between-reader variability <em>always</em> includes within-reader variability.</li>
</ol>
<p>With this background, the purpose of this chapter is to delve into variability in some detail and in particular describe computational methods for estimating them. This chapter introduces the concept of resampling a dataset to estimate variability and the widely used bootstrap and jackknife methods of estimating variance are described. In a later chapter, these are extended to estimating covariance (essentially a scaled version of the correlation) between two random variables.</p>
<p>The starting point is the simplest scenario: a single reader interpreting a case-set.</p>
</div>
<div id="dependence-of-auc-on-the-case-sample" class="section level2" number="7.3">
<h2><span class="header-section-number">7.3</span> Dependence of AUC on the case sample</h2>
<p>Suppose a researcher conducts a ROC study with a single reader. The researcher starts by selecting a case-sample, i.e., a set of proven-truth non-diseased and diseased cases. Another researcher conducting another ROC study at the same institution selects a different case-sample, i.e., a different set of proven-truth non-diseased and diseased cases. The two case-sets contain the same numbers <span class="math inline">\(K_1,K_2\)</span> of non-diseased and diseased cases, respectively. Even if the same radiologist interprets the two case-sets, and the reader is perfectly reproducible, the AUC values are expected to be different. Therefore, AUC must depend on a case sample index, which is denoted <span class="math inline">\(\{c\}\)</span>, where <span class="math inline">\(c\)</span> is an integer: <span class="math inline">\(c = 1, 2\)</span>, as there are two case-sets in the study as envisaged.</p>
<p><span class="math display" id="eq:sourcesVariabilityauc-case-set">\[\begin{equation} 
AUC\rightarrow AUC_{\{c\}}
\tag{7.3}
\end{equation}\]</span></p>
<p>Note that <span class="math inline">\(\{c\}\)</span> is not an individual <em>case</em> index, rather it is a <em>case-set</em> index, i.e., different integer values of <span class="math inline">\(c\)</span> denote different sets, or samples, or groups, or collections of cases. [The dependence of AUC on the case sample index is not explicitly shown in the literature.]</p>
<p>What does the dependence of AUC on the <span class="math inline">\(c\)</span> index mean? Different case samples differ in their <em>difficulty</em> levels. A difficult case set contains a greater fraction of difficult cases than is usual. A difficult diseased case is one where disease is difficult to detect. For example, the lesions could be partly obscured by overlapping normal structures in the patient anatomy; i.e., the lesion does not “stick out”. Alternatively, variants of normal anatomy could mimic a lesion, like a blood vessel viewed end on in a chest radiograph, causing the radiologist to miss the real lesion(s) and mistake these blood vessels for lesions. An easy diseased case is one where the disease is easy to detect. For example, the lesion is projected over smooth background tissue, because of which it “sticks out”, or is more conspicuous2. How does difficulty level affect non-diseased cases? A difficult non-diseased case is one where variants of normal anatomy mimic actual lesions and could cause the radiologist to falsely diagnose the patient as diseased. Conversely, an easy non-diseased case is like a textbook illustration of normal anatomy. Every structure in it is clearly visualized and accounted for by the radiologist’s knowledge of the patient’s non-diseased anatomy, and the radiologist is confident that any abnormal structure, <em>if present</em>, would be readily seen. The radiologist is unlikely to falsely diagnose the patient as diseased. Difficult cases tend to be rated in the middle of the rating scale, while easy ones tend to be rated at the ends of the rating scale.</p>
<div id="case-sampling-induced-variability-of-auc" class="section level3" number="7.3.1">
<h3><span class="header-section-number">7.3.1</span> Case sampling induced variability of AUC</h3>
<p>An easy case sample will cause AUC to increase over its average value; interpreting many case-sets and averaging the AUCs determines the average value. Conversely, a difficult case sample will cause AUC to decrease. Case sampling variability causes variability in the measured AUC. How does one estimate this essential source of variability? One method, totally impractical in the clinic but easy with simulations, is to have the same radiologist interpret repeated samples of case-sets from the population of cases (i.e., patients), termed <em>population sampling</em>, or more viscerally, as the “brute force” method.</p>
<p>Even if one could get a radiologist to interpret different case-sets, it is even more impractical to actually acquire the different case samples of truth-proven cases. Patients do not come conveniently labeled as non-diseased or diseased. Rather, one needs to follow-up on the patients, perhaps do other imaging tests, in order to establish true disease status, or ground-truth. In screening mammography, a woman who continues to be diagnosed as non-diseased on successive yearly screening tests in the US, and has no other symptoms of breast disease, is probably disease-free. Likewise, a woman diagnosed as diseased and the diagnosis is confirmed by biopsy (i.e., the biopsy comes back showing a malignancy in the sampled tissues) is known to be diseased. However, not all patients who are diseased are actually diagnosed as diseased: a typical false negative fraction is 20% in screening mammography3. This is where follow-up imaging can help determine true disease status at the initial screen. A false negative mistake is unlikely to be repeated at the next screen. After a year, the tumor may have grown, and is more likely to be detected. Having detected the tumor in the most recent screen, radiologists can go back and retrospectively view it in the initial screen, at which it was missed during the “live” interpretation. If one knows where to look, the cancer is easier to see. The previous screen images would be an example of a difficult diseased case. In unfortunate instances, the patient may die from the previously undetected cancer, which would establish the truth status at the initial screen, too late to do the patient any good. The process of determining actual truth is often referred to as defining the “gold standard”, the <em>ground truth</em>: or simply <em>truthing</em>.</p>
<p><em>One can appreciate from this discussion that acquiring independently proven cases, particularly diseased ones, is one of the most difficult aspects of conducting an observer performance study</em>.</p>
<p>There has to be a better way of estimating case-sampling variability. With a parametric model, the maximum likelihood procedure provides a means of estimating variability of each of the estimated parameters, which can be used to estimate the variability of <span class="math inline">\(A_z\)</span>, as in Chapter <a href="BinormalModel.html#BinormalModel">6</a>. The estimate corresponds to case-sampling variability (including an inseparable within-reader variability). If unsure about this point, the reader should run some of the examples in Chapter <a href="BinormalModel.html#BinormalModel">6</a> with increased numbers of cases. The variability is seen to decrease.</p>
<p>There are other options available for estimating case-sampling variance of AUC, and this chapter is not intended to be comprehensive. Three commonly used options are described: the DeLong et al method, the bootstrap and the jackknife resampling methods.</p>
</div>
</div>
<div id="estimating-case-sampling-variability-using-the-delong-method" class="section level2" number="7.4">
<h2><span class="header-section-number">7.4</span> Estimating case-sampling variability using the DeLong method</h2>
<p>If the figure-of-merit is the empirical AUC, then a procedure developed by DeLong et al4 (henceforth abbreviated to DeLong) is applicable that is based on earlier work by <span class="citation">(Noether <a href="#ref-RN2530" role="doc-biblioref">1967</a>)</span> and <span class="citation">(Bamber <a href="#ref-RN2174" role="doc-biblioref">1975</a>)</span>. The author will not go into details of this procedure but limit to showing that it “works”. However, before one can show that it “works”, one needs to know the true value of the variance of empirical AUC. Even if data were simulated using the binormal model, one cannot use the binormal model based estimate of variance as it is an estimate, not to be confused with a true value. Estimates are realizations of random numbers and are themselves subject to variability, which decreases with increasing case-set size. Instead, a “brute-force” (i.e., simulated population sampling) approach is adopted to determine the true value of the variance of AUC. The simulator provides a means of repeatedly generating case-sets interpreted by the same radiologist, and by sampling it enough time, e.g., <span class="math inline">\(C\)</span> = 10,000 times, each time calculating AUC, one determines the population mean and standard deviation. The standard deviation determined this way is compared to that yielded by the DeLong method to check if the latter actually works.</p>
<div class="sourceCode" id="cb31"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb31-1"><a href="sourcesVariabilityauc.html#cb31-1"></a>bruteForceEstimation &lt;-</span>
<span id="cb31-2"><a href="sourcesVariabilityauc.html#cb31-2"></a><span class="st">  </span><span class="cf">function</span>(seed, mu, sigma, K1, K2) {</span>
<span id="cb31-3"><a href="sourcesVariabilityauc.html#cb31-3"></a>    <span class="co"># brute force method to</span></span>
<span id="cb31-4"><a href="sourcesVariabilityauc.html#cb31-4"></a>    <span class="co"># find the population </span></span>
<span id="cb31-5"><a href="sourcesVariabilityauc.html#cb31-5"></a>    <span class="co"># meanempAuc and stdDevempAuc</span></span>
<span id="cb31-6"><a href="sourcesVariabilityauc.html#cb31-6"></a>    empAuc &lt;-<span class="st"> </span><span class="kw">array</span>(<span class="dt">dim =</span> <span class="dv">10000</span>)</span>
<span id="cb31-7"><a href="sourcesVariabilityauc.html#cb31-7"></a>    <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(empAuc)) {</span>
<span id="cb31-8"><a href="sourcesVariabilityauc.html#cb31-8"></a>      zk1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K1)</span>
<span id="cb31-9"><a href="sourcesVariabilityauc.html#cb31-9"></a>      zk2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K2, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)</span>
<span id="cb31-10"><a href="sourcesVariabilityauc.html#cb31-10"></a>      empAuc[i] &lt;-<span class="st"> </span><span class="kw">Wilcoxon</span>(zk1, zk2)</span>
<span id="cb31-11"><a href="sourcesVariabilityauc.html#cb31-11"></a>    }</span>
<span id="cb31-12"><a href="sourcesVariabilityauc.html#cb31-12"></a>    stdDevempAuc  &lt;-<span class="st">  </span><span class="kw">sqrt</span>(<span class="kw">var</span>(empAuc))</span>
<span id="cb31-13"><a href="sourcesVariabilityauc.html#cb31-13"></a>    meanempAuc   &lt;-<span class="st">  </span><span class="kw">mean</span>(empAuc)</span>
<span id="cb31-14"><a href="sourcesVariabilityauc.html#cb31-14"></a>    <span class="kw">return</span>(<span class="kw">list</span>(</span>
<span id="cb31-15"><a href="sourcesVariabilityauc.html#cb31-15"></a>      <span class="dt">meanempAuc =</span> meanempAuc,</span>
<span id="cb31-16"><a href="sourcesVariabilityauc.html#cb31-16"></a>      <span class="dt">stdDevempAuc =</span> stdDevempAuc</span>
<span id="cb31-17"><a href="sourcesVariabilityauc.html#cb31-17"></a>    ))</span>
<span id="cb31-18"><a href="sourcesVariabilityauc.html#cb31-18"></a>  }</span></code></pre></div>
<div class="sourceCode" id="cb32"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb32-1"><a href="sourcesVariabilityauc.html#cb32-1"></a>seed &lt;-<span class="st"> </span><span class="dv">1</span>;<span class="kw">set.seed</span>(seed)</span>
<span id="cb32-2"><a href="sourcesVariabilityauc.html#cb32-2"></a>mu &lt;-<span class="st"> </span><span class="fl">1.5</span>;sigma &lt;-<span class="st"> </span><span class="fl">1.3</span>;K1 &lt;-<span class="st"> </span><span class="dv">50</span>;K2 &lt;-<span class="st"> </span><span class="dv">52</span></span>
<span id="cb32-3"><a href="sourcesVariabilityauc.html#cb32-3"></a>ret &lt;-<span class="st"> </span><span class="kw">bruteForceEstimation</span>(seed, mu, sigma, K1, K2)</span>
<span id="cb32-4"><a href="sourcesVariabilityauc.html#cb32-4"></a><span class="co"># one more trial</span></span>
<span id="cb32-5"><a href="sourcesVariabilityauc.html#cb32-5"></a>zk1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K1)</span>
<span id="cb32-6"><a href="sourcesVariabilityauc.html#cb32-6"></a>zk2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K2, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)</span>
<span id="cb32-7"><a href="sourcesVariabilityauc.html#cb32-7"></a>empAuc &lt;-<span class="st"> </span><span class="kw">Wilcoxon</span>(zk1, zk2)</span>
<span id="cb32-8"><a href="sourcesVariabilityauc.html#cb32-8"></a>ret1  &lt;-<span class="st"> </span><span class="kw">DeLongVar</span>(zk1,zk2)</span>
<span id="cb32-9"><a href="sourcesVariabilityauc.html#cb32-9"></a>stdDevDeLong &lt;-<span class="st"> </span><span class="kw">sqrt</span>(ret1)</span>
<span id="cb32-10"><a href="sourcesVariabilityauc.html#cb32-10"></a><span class="kw">cat</span>(<span class="st">&quot;brute force estimates:&quot;</span>,</span>
<span id="cb32-11"><a href="sourcesVariabilityauc.html#cb32-11"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">empAuc = &quot;</span>,</span>
<span id="cb32-12"><a href="sourcesVariabilityauc.html#cb32-12"></a>    ret<span class="op">$</span>meanempAuc,</span>
<span id="cb32-13"><a href="sourcesVariabilityauc.html#cb32-13"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">population standard deviation =&quot;</span>,</span>
<span id="cb32-14"><a href="sourcesVariabilityauc.html#cb32-14"></a>    ret<span class="op">$</span>stdDevempAuc, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb32-15"><a href="sourcesVariabilityauc.html#cb32-15"></a><span class="co">#&gt; brute force estimates: </span></span>
<span id="cb32-16"><a href="sourcesVariabilityauc.html#cb32-16"></a><span class="co">#&gt; empAuc =  0.819178 </span></span>
<span id="cb32-17"><a href="sourcesVariabilityauc.html#cb32-17"></a><span class="co">#&gt; population standard deviation = 0.04176683</span></span>
<span id="cb32-18"><a href="sourcesVariabilityauc.html#cb32-18"></a></span>
<span id="cb32-19"><a href="sourcesVariabilityauc.html#cb32-19"></a><span class="kw">cat</span>(<span class="st">&quot;single sample estimates = &quot;</span>,</span>
<span id="cb32-20"><a href="sourcesVariabilityauc.html#cb32-20"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">empirical AUC&quot;</span>,</span>
<span id="cb32-21"><a href="sourcesVariabilityauc.html#cb32-21"></a>    empAuc,</span>
<span id="cb32-22"><a href="sourcesVariabilityauc.html#cb32-22"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">standard deviation DeLong = &quot;</span>,</span>
<span id="cb32-23"><a href="sourcesVariabilityauc.html#cb32-23"></a>    stdDevDeLong, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb32-24"><a href="sourcesVariabilityauc.html#cb32-24"></a><span class="co">#&gt; single sample estimates =  </span></span>
<span id="cb32-25"><a href="sourcesVariabilityauc.html#cb32-25"></a><span class="co">#&gt; empirical AUC 0.8626923 </span></span>
<span id="cb32-26"><a href="sourcesVariabilityauc.html#cb32-26"></a><span class="co">#&gt; standard deviation DeLong =  0.03804135</span></span></code></pre></div>
<p>Two functions needed for this code to work are not shown: <code>Wilcoxon()</code> calculates the Wilcoxon statistic and the <code>DeLongVar()</code> implements the DeLong variance computation method (the DeLong method also calculates co-variances, but these are not needed in the current context). Line 1 sets the <code>seed</code> of the random number generator to 1. The <code>seed</code> variable is completely analogous to the case-set index <code>c</code>. Keeping <code>seed</code> fixed realizes the same random numbers each time the program is run. Different values of <code>seed</code> result in different, i.e., statistically independent, random samples. Line 2 initialize the values <span class="math inline">\((\mu, \sigma, K_1, K_2)\)</span> needed by the data simulator: the normal distributions are separated by <span class="math inline">\(\mu = 1.5\)</span>, the standard deviation of the diseased distribution is <span class="math inline">\(\sigma = 1.3\)</span>, and there are <span class="math inline">\(K_1 = 50\)</span> non-diseased and <span class="math inline">\(K_2 = 52\)</span> diseased cases. Line 3 calls <code>bruteForceEstimation</code>, the “brute force” method for estimating mean and standard deviation of the population distribution of AUC, returned by this function, which are the “correct” value to which the DeLong standard deviation estimate will be compared. Lines 4-9 generates a fresh ROC dataset to which the DeLong method is applied.</p>
<p>Two runs of this code were made, one with the smaller sample size, and the other with 10 times the sample size (the second run takes much longer). A third run was made with the larger sample size but with a different seed value. The results follow:</p>
<div class="sourceCode" id="cb33"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb33-1"><a href="sourcesVariabilityauc.html#cb33-1"></a>seed &lt;-<span class="st"> </span><span class="dv">2</span>;<span class="kw">set.seed</span>(seed)</span>
<span id="cb33-2"><a href="sourcesVariabilityauc.html#cb33-2"></a>mu &lt;-<span class="st"> </span><span class="fl">1.5</span>;sigma &lt;-<span class="st"> </span><span class="fl">1.3</span>;K1 &lt;-<span class="st"> </span><span class="dv">500</span>;K2 &lt;-<span class="st"> </span><span class="dv">520</span></span>
<span id="cb33-3"><a href="sourcesVariabilityauc.html#cb33-3"></a>ret &lt;-<span class="st"> </span><span class="kw">bruteForceEstimation</span>(seed, mu, sigma, K1, K2)</span>
<span id="cb33-4"><a href="sourcesVariabilityauc.html#cb33-4"></a><span class="co"># one more trial</span></span>
<span id="cb33-5"><a href="sourcesVariabilityauc.html#cb33-5"></a>zk1 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K1)</span>
<span id="cb33-6"><a href="sourcesVariabilityauc.html#cb33-6"></a>zk2 &lt;-<span class="st"> </span><span class="kw">rnorm</span>(K2, <span class="dt">mean =</span> mu, <span class="dt">sd =</span> sigma)</span>
<span id="cb33-7"><a href="sourcesVariabilityauc.html#cb33-7"></a>empAuc &lt;-<span class="st"> </span><span class="kw">Wilcoxon</span>(zk1, zk2)</span>
<span id="cb33-8"><a href="sourcesVariabilityauc.html#cb33-8"></a>ret1  &lt;-<span class="st"> </span><span class="kw">DeLongVar</span>(zk1,zk2)</span>
<span id="cb33-9"><a href="sourcesVariabilityauc.html#cb33-9"></a>stdDevDeLong &lt;-<span class="st"> </span><span class="kw">sqrt</span>(ret1)</span>
<span id="cb33-10"><a href="sourcesVariabilityauc.html#cb33-10"></a><span class="kw">cat</span>(<span class="st">&quot;brute force estimates:&quot;</span>,</span>
<span id="cb33-11"><a href="sourcesVariabilityauc.html#cb33-11"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">empAuc = &quot;</span>,</span>
<span id="cb33-12"><a href="sourcesVariabilityauc.html#cb33-12"></a>    ret<span class="op">$</span>meanempAuc,</span>
<span id="cb33-13"><a href="sourcesVariabilityauc.html#cb33-13"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">population standard deviation =&quot;</span>,</span>
<span id="cb33-14"><a href="sourcesVariabilityauc.html#cb33-14"></a>    ret<span class="op">$</span>stdDevempAuc, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb33-15"><a href="sourcesVariabilityauc.html#cb33-15"></a><span class="co">#&gt; brute force estimates: </span></span>
<span id="cb33-16"><a href="sourcesVariabilityauc.html#cb33-16"></a><span class="co">#&gt; empAuc =  0.8194988 </span></span>
<span id="cb33-17"><a href="sourcesVariabilityauc.html#cb33-17"></a><span class="co">#&gt; population standard deviation = 0.01300203</span></span>
<span id="cb33-18"><a href="sourcesVariabilityauc.html#cb33-18"></a></span>
<span id="cb33-19"><a href="sourcesVariabilityauc.html#cb33-19"></a><span class="kw">cat</span>(<span class="st">&quot;single sample estimates = &quot;</span>,</span>
<span id="cb33-20"><a href="sourcesVariabilityauc.html#cb33-20"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">empirical AUC&quot;</span>,</span>
<span id="cb33-21"><a href="sourcesVariabilityauc.html#cb33-21"></a>    empAuc,</span>
<span id="cb33-22"><a href="sourcesVariabilityauc.html#cb33-22"></a>    <span class="st">&quot;</span><span class="ch">\n</span><span class="st">standard deviation DeLong = &quot;</span>,</span>
<span id="cb33-23"><a href="sourcesVariabilityauc.html#cb33-23"></a>    stdDevDeLong, <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</span>
<span id="cb33-24"><a href="sourcesVariabilityauc.html#cb33-24"></a><span class="co">#&gt; single sample estimates =  </span></span>
<span id="cb33-25"><a href="sourcesVariabilityauc.html#cb33-25"></a><span class="co">#&gt; empirical AUC 0.8047269 </span></span>
<span id="cb33-26"><a href="sourcesVariabilityauc.html#cb33-26"></a><span class="co">#&gt; standard deviation DeLong =  0.01356696</span></span></code></pre></div>
<ol style="list-style-type: decimal">
<li>An important observation is that as sample-size increases, case-sampling variability decreases: 0.0417 for the smaller sample size vs. 0.01309 for the larger sample size, and the dependence is as the inverse square root of the numbers of cases, as expected from the central limit theorem.</li>
<li>With the smaller sample size (K1/K2 = 50/52; the back-slash notation, not to be confused with division, is a convenient way of summarizing the case-sample size) the estimated standard deviation (0.038) is within 10% of that estimated by population sampling (0.042). With the larger sample size, (K1/K2 = 500/520) the two are practically identical (0.01300203 vs. 0.01356696 – the latter value is for seed = 2).</li>
<li>Notice also that the one sample empirical AUC for the smaller case-size is 0.863, which is less than two standard deviations from the population mean 0.819. The “two standard deviations” comes from rounding up 1.96: as in Eqn. <a href="binaryTask.html#eq:binaryTask-def-z-alpha2">(3.32)</a>, where <span class="math inline">\(z_{\alpha/2}\)</span> was defined as the upper <span class="math inline">\(1-\alpha/2\)</span> quantile of the unit normal distribution and <span class="math inline">\(z_{0.025}=1.96\)</span>.</li>
<li>To reiterate, with clinical data the DeLong procedure estimates case sampling plus within reader variability. With simulated data as in this example, there is no within-reader variability as the simulator yields identical values for fixed seed.</li>
</ol>
<p>This demonstration should convince the reader that one does have recourse other than the “brute force” method, at least when the figure of merit is the empirical area under the ROC. That should come as a relief, as population sampling is impractical in the clinical context. It should also impress the reader, as the DeLong method is able to use information present in a <em>single dataset</em> to tease out its variability. [This is not magic: the MLE estimate is also able to tease out variability based on a parametric fit to a single dataset and examination of the sharpness of the peak of the log-likelihood function, Chapter <a href="BinormalModel.html#BinormalModel">6</a>, as are the resampling methods described next.]</p>
<p>Next, two resampling–based methods of estimating case-sampling variance of AUC are introduced. The word “resampling” means that the dataset itself is regarded as containing information regarding its variability, which can be extracted by sampling from the original data (hence the word “resampling”). These are general and powerful techniques, applicable to any scalar statistic, not just the empirical AUC, which one might be able to use in other contexts.</p>
</div>
<div id="bootstrap-estimation-of-auc-case-sampling-variability" class="section level2" number="7.5">
<h2><span class="header-section-number">7.5</span> Bootstrap estimation of AUC case-sampling variability</h2>
<p>The simplest resampling method, at least at the conceptual level, is the bootstrap. <em>The bootstrap method is based on the assumption that one can regard the observed sample as defining the population from which it was sampled.</em> Since by definition a population cannot be exhausted, the idea is to resample, <em>with replacement</em>, from the observed sample. Each resampling step realizes a particular bootstrap sample set denoted <span class="math inline">\(\{b\}\)</span>, where <span class="math inline">\(b = 1, 2, ..., B\)</span>. The curly brackets emphasize that different integer values of <span class="math inline">\(b\)</span> denote different <em>sets of cases</em>, not individual cases. [In contrast, the notation <span class="math inline">\((k)\)</span> will be used to denote <em>removing</em> a specific case, <span class="math inline">\(k\)</span>, as in the jackknife procedure to be described shortly. The index <span class="math inline">\(b\)</span> should not be confused with the index <span class="math inline">\(c\)</span>, the case sampling index; the latter denotes repeated sampling from the population, which is impractical in real life; the bootstrap index denotes repeated sampling from the dataset, which is quite feasible.] The procedure is repeated <span class="math inline">\(B\)</span> times, typically <span class="math inline">\(B\)</span> can be as small as 200, but to be safe the author generally use about 1000 - 2000 bootstraps. The following example uses Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a> from Chapter <a href="ratingsParadigm.html#ratingsParadigm">4</a>.</p>
<p>For convenience, let us denote cases as follows. The 30 non-diseased cases that received the 1 rating are denoted <span class="math inline">\(k_{1,1},k_{2,1},...,k_{30,1}\)</span>. The second index denotes the truth state of the cases. Likewise, the 19 non-diseased cases that received the 2 rating are denoted <span class="math inline">\(k_{31,1},k_{32,1},...,k_{49,1}\)</span> and so on for the remaining non-diseased cases. The 5 diseased cases that received the 1 rating are denoted <span class="math inline">\(k_{1,2},k_{2,2},...,k_{5,2}\)</span>, the 6 diseased cases that received the 2 rating are denoted <span class="math inline">\(k_{6,2},k_{7,2},...,k_{11,2}\)</span>, and so on. Let us figuratively “put” all non-diseased cases (think of each case as an index card, with the case notation and rating recorded on it) into one hat (the non-diseased hat) and all the diseased cases into another hat (the diseased hat). Next, one randomly picks one case (card) from the non-diseased hat, records it’s rating, and puts the case back in the hat, so that it is free to be possibly picked again. This is repeated 60 times for the non-diseased hat resulting in 60 ratings from non-diseased cases. A similar procedure is performed using the diseased hat, resulting in 50 ratings from diseased cases. The author has just described, in painful detail (one might say) the realization of the 1st bootstrap sample, denoted <span class="math inline">\(\{b=1\}\)</span>. This is used to construct the 1st bootstrap counts table, Table <a href="sourcesVariabilityauc.html#tab:sourcesVariabilityaucbs1">7.1</a>.</p>
<table>
<caption>
<span id="tab:sourcesVariabilityaucbs1">TABLE 7.1: </span>Representative counts table.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 5\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 4\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 3\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 2\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
non-diseased
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
16
</td>
<td style="text-align:right;">
35
</td>
</tr>
<tr>
<td style="text-align:left;">
diseased
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
7
</td>
</tr>
</tbody>
</table>
<p>So what happened? Consider the 35 non-diseased cases with a 1 rating. If each non-diseased case rated 1 in Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a> were picked one time, the total would have been 30, but it is 35. Therefore, some of the original non-diseased cases rated 1 must have been picked multiple times, but one must also make allowance as there is no guarantee that a specific case was picked at all. Still focusing on the 35 non-diseased cases with a 1 rating in the first bootstrap sample, the picked labels, reordered after the fact, with respect to the first index, might be:</p>
<p><span class="math display" id="eq:sourcesVariabilityaucbs1-bs1-non-diseased">\[\begin{equation} 
k_{2,1},k_{2,1},k_{4,1},k_{4,1},k_{4,1},k_{6,1},k_{7,1},k_{7,1},k_{9,1},...,k_{28,1},k_{28,1},k_{30,1},k_{30,1}
\tag{7.4}
\end{equation}\]</span></p>
<p>In this example, case <span class="math inline">\(k_{1,1}\)</span> was not picked, case <span class="math inline">\(k_{2,1}\)</span> was picked twice, case <span class="math inline">\(k_{3,1}\)</span> was not picked, case <span class="math inline">\(k_{4,1}\)</span> was picked three times, case <span class="math inline">\(k_{5,1}\)</span> was not picked, case <span class="math inline">\(k_{6,1}\)</span> was picked once, etc. The total number of cases in Eqn. <a href="sourcesVariabilityauc.html#eq:sourcesVariabilityaucbs1-bs1-non-diseased">(7.4)</a> is 35, and similarly for the other cells in Table <a href="sourcesVariabilityauc.html#tab:sourcesVariabilityaucbs1">7.1</a>. Next, one estimates AUC for this table. Using the Eng website referred to earlier, one gets AUC = 0.843. [It is OK to use a parametric FOM since the bootstrap is a general procedure applicable, in principle, to any FOM, not just the empirical AUC, unlike the DeLong method, which is restricted to empirical AUC.] The corresponding value for the original data, Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a>, was AUC = 0.870. The first bootstrapped dataset yielded a smaller value than the original dataset because one happened to have picked an unusually difficult bootstrap sample.</p>
<p>[Notice that in the original data there were 6 + 5 = 11 diseased cases that were rated 1 and 2, but in the bootstrapped dataset there are 7 + 9 = 16 diseased cases that were rated 1 and 2; in other words, the number of incorrect decisions on diseased cases went up, which would tend to lower AUC. Counteracting this effect is the increase in number of correct decisions on diseased cases: 8 + 19 = 27 cases rated 4 and 5, as compared to 12 + 22 = 34 in the original dataset. Reinforcing the effect is that increase in the number of correct decisions on non-diseased cases, albeit minimally: 35 + 16 = 51 rated 1 and 2 vs. 30 + 19 = 49 in the original dataset, and zero counts rated 4 and 5 in the non-diseased vs. 2 + 1 = 3 in the diseased. The complexity of following this <em>post-facto justification</em> illustrates the difficulty, in fact the futility, of correctly predicting which way performance from comparison of the two ROC counts tables – too many numbers are changing and in the above one did not even consider the change in counts in the bin labeled 4. Hence, the need for an objective figure of merit, such as the binormal model based AUC or the empirical AUC.]</p>
<p>To complete the description of the bootstrap method, one repeats the procedure described in the preceding paragraphs <span class="math inline">\(B = 200\)</span> times, each time running the website calculator and the final result is <span class="math inline">\(B\)</span> values of AUC, denoted:</p>
<p><span class="math display">\[AUC_{\{1\}},AUC_{\{2\}},...,AUC_{\{B\}}\]</span></p>
<p>where <span class="math inline">\(AUC_{\{1\}}=0.843\)</span>, etc. The bootstrap estimate of the variance of AUC is defined by <span class="citation">(Efron and Tibshirani <a href="#ref-RN2261" role="doc-biblioref">1993</a>)</span>:</p>
<p><span class="math display" id="eq:sourcesVariabilityaucVar-bs">\[\begin{equation} 
\text{Var}\left ( AUC \right )=\frac{1}{B-1}\sum_{b=1}^{B}\left ( AUC_{\{b\}}-AUC_{\{ \bullet\}} \right )^2
\tag{7.5}
\end{equation}\]</span></p>
<p>The right hand side is the traditional definition of (unbiased) variance. The dot represents the average over the <em>replaced index</em>. Of course, running the website code 200 times and recording the outputs is not a productive use of time. The following code implements two methods for estimating AUC, the binormal model estimate of AUC, described in Chapter 06, and the empirical AUC, described in Chapter 05.</p>
<div id="demonstration-of-the-bootstrap-method" class="section level3" number="7.5.1">
<h3><span class="header-section-number">7.5.1</span> Demonstration of the bootstrap method</h3>
<p>Open the project file for this chapter and the file mainBootstrapSd.R, Online Appendix 7.A. Make sure the seed variable at line 12 is initialized to 1 and source the code, yielding the following output. Think of the seed variable as the case sample index . Selecting a different seed generates a different case sample. Since the bootstrap method is applicable to any scalar figure of merit, two options are provided in the code, lines 10 -11; currently FOM &lt;- “Az”, which uses the binormal model estimate, but if one reverses the commenting the empirical AUC is used. Source the code file. In about 2 seconds on the author’s computer yielded the following output:</p>
<p>7.5.1.1: Code Output for seed = 1
&gt; source(‘~/book2/02 A ROC analysis/A7 Sources of variability in AUC/software/mainBootstrapSd.R’)
FOM = Az , seed = 1 , B = 200
OrigAUC = 0.8704519 , meanAUC = 0.8671713 , stdAUC = 0.04380523</p>
<p>This shows that the AUC of the original data (i.e., before bootstrapping) is 0.870, the mean AUC of the B = 200 bootstrapped datasets is 0.867, and the standard deviation of the 200 bootstraps is 0.0438. Now if one runs the website calculator referenced in the previous chapter on the dataset shown in Table 7.1, one finds that the MLE of the standard deviation of the AUC of the fitted ROC curve is 0.0378. The standard deviation is itself a statistic and there is sampling variability associated with it, i.e., there exists such a beast as a standard deviation of a standard deviation; the bootstrap estimate is near the MLE estimate.</p>
<p>By setting seed to different values, one gets an idea of the variability in the estimate of the standard deviation of AUC (to repeat, seed is like the case sample index ; different values correspond to different case sets). For example, with seed &lt;- 2, one gets:</p>
<p>Note that both the mean of the bootstrap samples and the standard deviation have changed, but both are close to the MLE values. One should experiment with other values of seed. Examined next is the dependence of the estimates on B, the number of bootstraps. With seed &lt;- 1 and B &lt;- 2000 one gets:</p>
<p>The estimates are evidently rather insensitive to B, but the computation time was longer, ~13 seconds (running MLE 2000 times in 13 seconds is not bad). It is always a good idea to test the stability of the results to different B and seed values. Unlike the DeLong method, the bootstrap is broadly applicable to other figures of merit; specifically, it is not limited to the empirical area under the ROC. However, do beware that it depends on the assumption that the sample itself is representative of the population. With limited numbers of cases, this could be a bad assumption. With small sample sizes, it is relatively easy to enumerate the different outcomes of the sampling process and, more importantly, their respective probabilities, leading to what is termed the exact bootstrap. It is exact in the sense that there is no seed variable or number of bootstrap dependence.</p>
</div>
</div>
<div id="jackknife-estimation-of-auc-case-sampling-variability" class="section level2" number="7.6">
<h2><span class="header-section-number">7.6</span> Jackknife estimation of AUC case-sampling variability</h2>
<p>Attention now turns to the second resampling method, termed the jackknife, which is computationally less demanding, but as was seen with the bootstrap, with modern personal computers computational limitations are no longer that important, at least for the types of analyses that this book is concerned with.</p>
<p>In this method, the first case is removed, or jackknifed, from the set of cases and the MLE (or empirical estimation) is conducted on the resulting dataset, which has one less case. Let us denote by the resulting value of ROC-AUC. The parentheses around the subscript 1 are meant to emphasize that the AUC value corresponds to that with the first case removed from the original dataset. Next, the first case is replaced, and now the second case is removed, the new dataset is analyzed yielding , and so on, yielding K (K is the total number of cases; ) jackknife AUC values:</p>
<p>. (7.6)</p>
<p>The corresponding jackknife pseudovalues are defined by:</p>
<p>. (7.7)</p>
<p>Here AUC denotes the estimate using the entire dataset, i.e., not removing any cases. The jackknife pseudovalues will turn out to be of central importance in Chapter 09.</p>
<p>The jackknife estimate of the variance is defined by7</p>
<p>. (7.8)</p>
<p>Since variance of K scalars is defined by:</p>
<p>. (7.9)</p>
<p>. (7.10)</p>
<p>In Eqn. (7.8) the author has deliberately not simplified the right hand side by cancelling out K-1. The purpose is to show, Eqn.(7.10), that the usual expression for the variance needs to be multiplied by a variance inflation factor , which is approximately equal to K, in order to obtain the correct jackknife estimate of variance of AUC. This factor was not necessary when one used the bootstrap method. That is because the bootstrap samples are more representative of the actual spread in the data. The jackknife samples are more restricted than the bootstrap samples, so the spread of the data is smaller; hence the need for the variance inflation factor7.</p>
<p>Source the file mainJackknifeSd.R, Online Appendix 7.B, after ensuring that Az is selected as the FOM, yielding the following results:</p>
<p>Notice that the code does not use a set.seed() statement, as no random number generator is needed in the jackknife method (systematically removing and replacing each case in sequence, one at a time, is not random sampling, which should further explain the need for the variance inflation factor in Eqn. (7.10)). The bootstrap and jackknife methods are broadly applicable to other figures of merit; specifically, they are not limited to the empirical area under the ROC.</p>
<div id="estimating-auc-case-sampling-variability-using-calibrated-simulator" class="section level3" number="7.6.1">
<h3><span class="header-section-number">7.6.1</span> Estimating AUC case-sampling variability using calibrated simulator</h3>
<p>In real life one does have the luxury of sampling from the population of cases, but with a simulator almost anything is possible. The population sampling method used previously, §7.3.2, to compare the DeLong method to a known standard used arbitrarily set simulator values (mu = 1.5 and sigma = 1.3 at line 5 of mainDeLongSd.R). One does not know if these values are actually representative of real clinical data. In this section a simple method of implementing population sampling using a calibrated simulator is described. The code is in mainCalSimulator.R in Online Appendix 7.C. A calibrated simulator is one whose parameters are chosen to match those of an actual clinical dataset, so the simulator is calibrated to the specific one-and-only-one dataset. Why might one wish to do that? Rather than “fish in the dark” and set arbitrary values for the simulator parameters, one needs to find realistic values that match an actual clinical dataset. This way one has at least some assurance that the simulator is realistic and therefore its verdict on a proposed method or analysis is more likely to be correct.</p>
<p>As an example, consider a real clinical dataset, such as in Table 7.1. This data set analyzed by MLE yielded model parameters, a, b and the 4 thresholds . The specific values were (in the same order): 1.320453, 0.607497, 0.007675259, 0.8962713, 1.515645 and 2.39671 (listed in 7.7.1: Code Output below). On each pass through the simulator one samples 60 values from the non-diseased distribution and 50 values from the diseased distribution, implemented in SimulateRocCountsTable.R, Online Appendix 7.C, which returns a simulated ROC counts table like Table 7.1. MLE on the ROC counts table yields . The process is repeated P = 2000 (p is the population sampling index, ranging from 1 to P) and finally one calculates the mean and standard deviation of the 2000 values. Open the file mainCalSimulator.R, Online Appendix 7.C, confirm that FOM is set to “Az” at line 11 (i.e., it is not commented out) and source it. Shown are results of two runs with different values for the seed (namely, 1 and 2):
7.7.1: Code Output
&gt; source(‘~/book2/02 A ROC analysis/A7 Sources of variability in AUC/software/mainCalSimulator.R’)
seed = 1 , FOM = Az , P = 2000
Calibrated simulator values: a, b, zetas:
1.320453 0.607497 0.007675259 0.8962713 1.515645 2.39671
seed = 1 OrigAUC = 0.8704519 meanAUC = 0.8676727 stdAUC = 0.04033307</p>
<blockquote>
<p>source(‘~/book2/02 A ROC analysis/A7 Sources of variability in AUC/software/mainCalSimulator.R’)
seed = 2 , FOM = Az , P = 2000
Calibrated simulator values: a, b, zetas:
1.320453 0.607497 0.007675259 0.8962713 1.515645 2.39671
seed = 2 OrigAUC = 0.8704519 meanAUC = 0.8681855 stdAUC = 0.04055164</p>
</blockquote>
<p>The seed = 1 estimate of standard deviation of AUC (0.0403) is recorded in Table 7.3, row A, sub-row “Population”. The entry for sub-row “MLE” was obtained using the ROCFIT equivalent Eng’s JAVA program <span class="citation">(Eng <a href="#ref-RN2114" role="doc-biblioref">2006</a>)</span>, §6.2.6. The DeLong method entry for row A was obtained using mainDeLongSd.R with FOM set to " Wilcoxon“, as indicated by the asterisk; see §7.3.2. The bootstrap entry was obtained using mainBootstrapSd.R, and the jackknife entry was obtained using mainJackknifeSd.R; in both cases FOM was set to”Az". Note that the four estimates are close to each other, around 0.04. This confirms the validity of the different approaches to estimating the case sampling standard deviation, and is a self-consistency check on the calibration process.</p>
<p>Row B repeats the values in row A, except that this time the empirical AUC is being used as the figure of merit. The flexibility afforded by the calibrated simulator is that using it one can test various ideas. For example, what happens if the number of cases is increased? One expects the standard deviations in the last column of Table 7.3 to decrease, but by how much. Row B uses datasets generated by the simulator calibrated to the data in Table 7.3. Since the numbers of cases has not changed, the values are similar to those in row A. In row-C the number of cases has been inflated by a factor of 10, and the standard deviations decrease by about a factor of square root of 10. [Since rows B, C and D use empirical AUC, MLE estimates are inapplicable.]</p>
<p>Exercise: Use the calibrated simulator to test the effect of changing simulator parameters, particularly mu. As mu increases, the standard deviation is expected to decrease, because there is “less room” for AUC to vary, since it is constrained to be ≤1.</p>
<p>Table 7.3: Comparison of different estimates of the standard deviation of AUC, namely MLE, the DeLong method, bootstrap, jackknife and population sampling. MLE = maximum likelihood estimate; shown are results for a real dataset (A, B) and two simulated datasets (C and D) and two choices for estimating AUC: parametric and empirical. * The entry for the DeLong method was obtained using the empirical AUC. (P = 2000) (B = 2000)</p>
</div>
</div>
<div id="dependence-of-auc-on-reader-expertise" class="section level2" number="7.7">
<h2><span class="header-section-number">7.7</span> Dependence of AUC on reader expertise</h2>
<p>Suppose one conducts an ROC study with J readers where typically J is about 5 but can be as low as 3 and as high as 20 (the wide variability reflects, in the author’s opinion, lack of understanding of the factors affecting the optimal choice of J and the related issue of statistical power). Each reader interprets the same case sample, i.e., the same set of cases, but because they have different expertise levels and for other reasons (see below), the observed ROC counts tables will not be identical. The variance of the observed values is an empirical estimate of between-reader variance (including the inseparable within-reader component). Here is an example, in file MainBetweenReaderSd.R. This file loads the Van Dyke dataset, consisting of two modalities and five readers described in Online Chapter 24. Source the code file to get:
7.8.1: Code Output
&gt; source(‘~/book2/02 A ROC analysis/A7 Sources of variability in AUC/software/mainBetweenReaderSd.R’)
between-reader variance in modality 1 = 0.003082629
between-reader variance in modality 2 = 0.001304602
avg. between-reader variance in both modalities = 0.002193615</p>
<p>Notice that the between-reader (including, as always, within-reader) variance appears to be modality dependent. Determining if the difference is significant requires more analysis. For now one simply averages the two estimates.</p>
<p>How can one handle between-reader variability in the notation? Each reader’s interpretation can be analyzed by MLE to get the corresponding AUC value. The notation for the observed AUC values is:</p>
<p>. (7.11)</p>
<p>How does one conceptualize reader variability? As stated before, it is due to differences in expertise levels, but there is more to it. Since the single reader is characterized by parameters (R is the number of ratings bins; it is assumed that all readers employ the same number of bins, although they may employ it in different ways, i.e., the values of the thresholds may be different). While the non-diseased distribution for each reader could have mean different from 0 and variance different from unity, one can always translate it to zero and scale it to assure that the non-diseased distribution is the unit normal distribution. However, one cannot be assured that the separation and the width of the diseased distribution, and the thresholds, will not depend on the reader. Therefore, the most general way of thinking of reader variability is to put a j subscript on each of the model parameters, yielding . Now the first two of these define the population ROC curve for reader j, and the corresponding AUC value is (this equation was derived in Chapter 06, Eqn. (6.92.24)):</p>
<p>. (7.12)</p>
<p>All else being equal, readers with larger will perform better because they are better able to separate the non-diseased and diseased cases in z-space than their fellow readers. It is difficult and possibly misleading to try to estimate the differences directly from the observed ROC counts tables, but in general better readers will yield counts more skewed towards the low end of the rating scale on non-diseased cases and more skewed towards the high end of the rating scale for diseased cases. The ideal reader would rate all diseased cases one value (e.g. 5) and all non-diseased cases a smaller fixed value (e.g., 1, 2, 3, or 4), resulting in unit AUC, i.e., perfect performance. According to Eqn. (7.12), a reader with smaller will also perform better. As noted before, typically the parameter is greater than unity. The reasons for this general finding will be discussed later, but accept the author’s word for now that the best the reader can is to reduce this parameter to unity. See Summary of Chapter 06 for reasons for the observation that generally the variance of the diseased distribution is larger than one – it has to do with the inhomogeneity of the distribution of diseased cases and the possibility that a mixture distribution is involved. As regards thresholds, while the population based performance for a particular reader does not depend on thresholds, the thresholds determine the ROC counts table, so differences in usage of the thresholds will translate to differences in estimates of , but this is expected to be a smaller effect compared to the dependence on . To summarize, variability of readers can be attributed to variability in the binormal model parameters and, to a lesser extent, to variability in adopted thresholds.</p>
</div>
<div id="dependence-of-auc-on-modality" class="section level2" number="7.8">
<h2><span class="header-section-number">7.8</span> Dependence of AUC on modality</h2>
<p>Suppose one conducts an ROC study with j (j =1,2,…J) readers but there are I (i=1,2,…I) modalities. This is frequently referred to as the multiple reader multiple case (MRMC) paradigm. Each reader interprets the same case sample, i.e., the same set of cases, in two or more modalities. Here is an example, in file MainModalityEffect.R. This file loads the Van Dyke dataset, consisting of two modalities and five readers described in Online Chapter 24. Source the code file to get:
7.9.1: Code Output
&gt; source(‘~/book2/02 A ROC analysis/A7 Sources of variability in AUC/software/mainModalityEffect.R’)
reader-average FOM in modality 1 = 0.897037 reader-average FOM in modality 2 = 0.9408374 , effect size, i.e., fom modality 1 minus modality 2 = -0.04380032</p>
<p>Notice that the second modality has a higher FOM. Determining if the difference is significant requires more analysis as described in Chapter 09. The difference between the reader-averaged FOMs is referred to as the observed effect size.</p>
<p>How does on handle modality dependence of the FOM in the notation? If K is the total number of cases, the total number of interpretations involved is IJK, each of which results in a rating. MLE analysis yields IJ values for AUC, one for each modality-reader combination. The appropriate notation is</p>
<p>. (7.13)</p>
<p>The most general way of thinking of reader and modality variability is to put ij subscripts on each of the model parameters, yielding . For a particular combination of modality and reader, the population ROC curve as fitted by the binormal model, yields the area under the ROC curve:</p>
<p>. (7.14)</p>
<p>Given an MRMC dataset, using MLE one can estimate the parameters for each modality-reader combination, and this could be used to design a simulator that is calibrated to the specific clinical dataset, which in turn can be used to illustrate the ideas and to test any proposed method of analyzing the data. However, the problem is more complex; the procedure needs to also account for the correlations arising from the large number of pairings inherent is such a dataset (e.g., reader 1 in modality 1 vs. reader 2 in modality 2, since both interpret a common dataset). Designing a MRMC calibrated simulator was until recently, an unsolved problem, which necessitated recent work9 by the author and Mr. Xuetong Zhai. Chapter 23 describes recent progress towards this end.</p>
</div>
<div id="effect-on-empirical-auc-of-variations-in-thresholds-and-numbers-of-bins" class="section level2" number="7.9">
<h2><span class="header-section-number">7.9</span> Effect on empirical AUC of variations in thresholds and numbers of bins</h2>
<p>There are actually two effects. (1) The empirical AUC will tend to be smaller than the true AUC. If there are few operating points, and they are clustered together, the difference may be large, Fig. 7.1 (A).</p>
<p>7.10.1: Code listing</p>
<p>This figure was generated by a binormal model simulator, with thresholds chosen to exaggerate the effect, line 4 - 7. The true or population AUC is 0.8664, while the empirical AUC is 0.8030, line 13. However, since interest is in differences in AUCs, e.g., between two modalities, and the underestimates may tend to cancel, this may not be a serious issue. However, an effect that may be problematical is that the operating points for a given reader may not span the same FPF ranges in the two modalities, in which case the empirical AUCs will be different, as depicted in Fig. 7.1 (A - B). The AUC in modality (B), where the operating points span the entire range, is 0.8580, line 21, which is closer to the population value. Since the usage of the bins is not under the researcher’s control, this effect cannot be ruled out. Fitted AUCs are expected to be less sensitive, but not immune, to this effect. Fig. 7.1 (C) is a contaminated binormal model (CBM) fitted curve, line 14, to the same data as in (A), fitted AUC = 0.892, while Fig. 7.1 (D) is a CBM fitted curve, line 22, to the same data as in (B), fitted AUC = 0.867. The difference in AUCs between (A) and (B) is 0.055, while that between (C) and (D) is 0.024. The consequences of these effects on the validity of analyses using the empirical AUC have not been studied. [The parameters of the model were a = 1.33 and b = 0.667, which yields the quoted value of the population AUC. The population value is that predicted by the parameters; it has zero sampling variability. The fitted curves are those predicted by the CBM, discussed in Chapter 20.]</p>
<ol start="2" style="list-style-type: decimal">
<li>The second effect is varying numbers of thresholds or bins between the readers. One could be a radiologist, capable of maintaining at most about 6 bins, and the other an algorithmic observer, such as CAD, capable of maintaining more bins. Moreover, if the radiologist is an expert, the data points will tend to cluster near the initial near vertical part of the ROC (see Chapter 17 for explanation). This is illustrated using code in file mainBinVariability.R. Sourcing this code yields Fig. 7.1 (E – F) and the AUC values shown in these plots.</li>
</ol>
<p>7.10.2: Code listing</p>
<p>In Fig. 7.1(E) and Fig. 7.1(F) the effect is dramatic. The expert radiologist trapezoidal AUC is 0.7418, while that for CAD is 0.8632; the latter is close to the population value. It is left as an exercise for the reader to demonstrate that using CBM one can avoid the severe underestimate of performance that occurs in plot (E).</p>
<ol style="list-style-type: upper-alpha">
<li><p>AUC = 0.8030<br />
</p></li>
<li><p>AUC = 0.8580</p></li>
<li><p>AUC = 0.892<br />
</p></li>
<li><p>AUC = 0.867</p></li>
<li><p>AUC = 0.7418<br />
</p></li>
<li><p>AUC = 0.8632
Fig. 7.1 (A-D): Plots (A - B) depict empirical plots for two simulated datasets for the same model, i.e., same continuous ratings, using different thresholds. In (A) the thresholds are clustered at low FPF values, while in (B) they are more evenly spaced. Empirical AUCs for the plots are 0.803 for (A) and 0.858 for (B). The clustering in (A) leads to a low estimate of AUC. Plots (C) and (D) are fitted curves corresponding to the same data as in (A) and (B), respectively. For each plot, the population AUC is 0.866. The fitted curves are less sensitive, but not immune, to the data clustering variations. With a large number of evenly spaced points, the empirical AUC is close to that of the fitted curve. This effect is demonstrated in plots (E) and (F). The plots were generated by mainEmpVsFit.R and mainBinVariability.R.</p></li>
</ol>
</div>
<div id="empirical-vs.-fitted-aucs" class="section level2" number="7.10">
<h2><span class="header-section-number">7.10</span> Empirical vs. fitted AUCs</h2>
<p>There is a preference with some researchers to using the empirical AUC as a figure of merit. Its usage enables analyses10-14 variously referred to as the “probabilistic”, mechanistic" or “first-principles” approach and the “one-shot” approach15 to multiple reader multiple case analysis. The author is aware of some statisticians who distrust parametric modeling and the associate normality assumptions (the author trusts that the demonstrations in §6.2.2 may assuage the concerns). In addition, empirical AUC frees the researcher from problems with binormal model based fitting, e.g., handling degenerate datasets (these problems go away with two of the fitting methods described in later chapters). The fact that the empirical AUC can always be calculated, even, for example, with a single operating point, can make the analyst blissfully unaware of anomalous data structures. In contrast, the binormal curve-fitting method in Chapter 06 will complain when the ratings bins are not well populated, e.g., by failing to converge. This at least alerts the analyst that conditions are not optimal, and prompt data visualization and consideration of alternate fitting methods.</p>
<p>If empirical AUC is defined by a large number of operating points, such as with continuous ratings obtained with algorithmic observers, then empirical AUC will be nearly equal to the true AUC, to within sampling error. However, with human observers one rarely gets more than about 6 distinct ratings. The researcher has no control over the internal sensory thresholds used by the radiologist to bin the data, and these could depend on the modality. As demonstrated in the previous section, the empirical AUC is sensitive to the choice of thresholds, especially when the number of thresholds is small, as is usually the case with radiologists, and when the operating points are clustered on the initial near vertical section of the plot, as is also the case with experts.</p>
<ol style="list-style-type: upper-alpha">
<li></li>
<li></li>
<li></li>
<li></li>
<li>Fig. 7.2 (A-E): This figure shows a small sample of the 236 viewable plots in the cited online document. In this figure, each panel corresponds to a different reader (the j-index in the labels). The modality is the same (the i-index) and the dataset is labeled D1. The three curves correspond to different advanced method of fitting ROC data. The interest in this chapter is on the positions of the operating points. Reader (C) traverses more of the FPF range than does reader (E). Empirical AUC may result in a greater error for reader (E) than for reader (C). An explanation of the three fits is deferred to Chapter 18</li>
</ol>
</div>
<div id="sourcesVariabilityauc-Discussion" class="section level2" number="7.11">
<h2><span class="header-section-number">7.11</span> Discussion</h2>
<p>This chapter focused on the factors affecting variability of AUC, namely case-sampling and between-reader variability, each of which contain an inseparable within-reader contribution. The only way to get an estimate of within-reader variability is to have the same reader re-interpret the same case-set on multiple occasions (with sufficient time delay to minimize memory effects). This is rarely done and is unnecessary, in the ROC context, to sound experimental design and analysis. Some early publications have suggested that such re-interpretations are needed to estimate the within-reader component, but modern analysis, described in the next part of the book, does not require re-interpretations. Indeed, it is a waste of precious reader-time resources. Rather than have the same readers re-interpret the same case-set on multiple occasions, it makes much more sense to recruit more readers and/or collect more cases, guided by a systematic sample size estimation method. Another reason the author is not in favor of re-interpretations is that the within-reader variance is usually smaller than case-sampling and between-reader variances. Re-interpretations would minimize a quantity that is already small, which is not good science.</p>
<p>In the author’s judgment, current literature on this topic lacks notational clarity, particularly when it comes to case sampling. An important part of this chapter is the explicit usage of the case-set index to describe a key-factor, namely the case-sample, on which AUC depends. This index is assumed in the literature, which can lead to confusion; especially understanding one the methods used to analyze ROC MRMC data, see Chapter 10. Different simulated datasets correspond to different values of . This indexing leads to a natural, in the author’s opinion, understanding of the bootstrap method; one simply replaces with , the bootstrap case-set index.</p>
<p>The bootstrap and jackknife methods described in this chapter have wide applicability. Later they will be extended to estimating the covariance (essentially a scaled correlation) between two random variables. Also described was the DeLong method, applicable to the empirical AUC. Using a real dataset and simulators, all methods were shown to agree with each other, especially when the numbers of cases is large, Table 7.3 (row-D).</p>
<p>The concept of a calibrated simulator was introduced as a way of “anchoring” a simulator to a real dataset. While relatively easy for a single dataset, the concept has yet to be extended to where it would be useful, namely designing a simulator calibrated to a dataset consisting of interpretations by multiple readers in multiple modalities of a common dataset. Just as a calibrated simulator allowed comparison of the different variance estimation methods to a known standard, obtained by population sampling, a more general calibrated simulator would allow better testing the validity of the analysis described in the next few chapters.</p>
<p>A source of variability not generally considered, namely threshold variability, is introduced, and a cautionary note is struck with respect to indiscriminate usage of the empirical AUC. Finally, the author wishes to reemphasize the importance of viewing ROC plots, to detect anomalous conditions that might be otherwise overlooked.</p>
<p>This concludes Part A of this book. The next chapter begins Part B, namely the statistical analysis of multiple-reader multiple-case (MRMC) ROC datasets.</p>
</div>
<div id="sourcesVariabilityauc-references" class="section level2" number="7.12">
<h2><span class="header-section-number">7.12</span> References</h2>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-RN2174">
<p>Bamber, Donald. 1975. “The Area Above the Ordinal Dominance Graph and the Area Below the Receiver Operating Characteristic Graph.” Journal Article. <em>Journal of Mathematical Psychology</em> 12 (4): 387–415. <a href="https://doi.org/10.1016/0022-2496(75)90001-2">https://doi.org/10.1016/0022-2496(75)90001-2</a>.</p>
</div>
<div id="ref-RN2261">
<p>Efron, Bradley, and Robert J. Tibshirani. 1993. <em>An Introduction to the Bootstrap</em>. Book. Vol. 57. Monographs on Statistics and Applied Probability. Boca Raton: Chapman; Hall/CRC.</p>
</div>
<div id="ref-RN2114">
<p>Eng, J. 2006. “ROC Analysis: Web-Based Calculator for ROC Curves, Http://Www.jrocfit.org.” Journal Article. <a href="http://www.jrocfit.org.">http://www.jrocfit.org.</a></p>
</div>
<div id="ref-RN2530">
<p>Noether, Gottfried E. 1967. “Elements of Nonparametric Statistics.” Report. Wiley; Sons.</p>
</div>
<div id="ref-RN412">
<p>Swets, John A., and Ronald M. Pickett. 1982. <em>Evaluation of Diagnostic Systems: Methods from Signal Detection Theory</em>. Book. First. Series in Cognition and Perception. New York: Academic Press.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="BinormalModel.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="HypothesisTesting.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["RJafrocBook.pdf", "RJafrocBook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
