[
["ORAnalysis.html", "Chapter 5 Obuchowski Rockette (OR) Analysis 5.1 Introduction 5.2 Single-reader multiple-treatment model 5.3 Multiple-reader multiple-treatment OR model 5.4 Two anecdotes 5.5 Back to the main story 5.6 Discussion/Summary 5.7 References", " Chapter 5 Obuchowski Rockette (OR) Analysis 5.1 Introduction In previous chapters the DBM significance testing procedure (Dorfman, Berbaum, and Metz 1992) for analyzing MRMC ROC data, along with improvements (Hillis 2014), has been described. Because the method assumes that jackknife pseudovalues can be regarded as independent and identically distributed case-level figures of merit, it has been criticized by Hillis and others (Zhou, McClish, and Obuchowski 2009). Hillis states that the method “works” but lacks firm statistical foundations (Hillis et al. 2005; Hillis 2007; Hillis, Berbaum, and Metz 2008). In my book I gave a justification for why the method “works”. Specifically, the empirical AUC pseudovalues qualify as case-level FOMs - this property has also been noted by (Hajian-Tilaki et al. 1997). However, this property applies only to the empirical AUC, so an alternate approach that applies to any figure of merit is highly desirable. Hillis’ has proposed that a method based on an earlier publication (Obuchowski and Rockette 1995), which does not depend on pseudovalues, is preferable from both conceptual and practical points of view. This chapter is named “OR Analysis”, where OR stands for Obuchowski and Rockette. The OR method has advantages in being able to handle more complex study designs (Hillis 2014) that are addressed in subsequent chapters, and it is likely that applications to other FOMs (e.g., the FROC paradigm uses a rather different FOM from empirical ROC-AUC) are better performed with the OR method. This chapter starts with a gentle introduction to the Obuchowski and Rockette method. The reason is that the method was rather opaque to me, and I suspect most non-statistician users. Part of the problem, in my opinion, is the notation, namely lack of the case-set index \\(\\{c\\}\\). While this may seem like a trivial point to statisticians, it did present a problem for me. A key difference of the Obuchowski and Rockette method from DBM is in how the error term is modeled by a non-diagonal covariance matrix. Therefore, the structure of the covariance matrix is examined in some detail. In the first step of the “gentle” introduction a single reader interpreting a case-set in multiple treatments is analyzed and the results compared to that using DBM fixed-reader analysis described in the previous chapter. In the second step multiple readers interpreting a case-set in multiple treatments is analyzed and the two results, DBM and OR, are compared for the same dataset. The special cases of fixed-reader and fixed-case analyses are described. Single treatment analysis, where interest is in comparing average performance of readers to a fixed value, is described. Three methods of estimating the covariance matrix are described. Before proceeding, it is understood that datasets analyzed in this chapter follow a factorial design, sometimes call fully-factorial or fully-crossed design. Basically, the data structure is symmetric, e.g., all readers interpret all cases in all modalities. The next chapter will describe the analysis of split-plot datasets, where, for example, some readers interpret all cases in one modality, while the remaining readers interpret all cases in the other modality. 5.2 Single-reader multiple-treatment model Consider a single-reader providing ROC interpretations of a common case-set \\(\\{c\\}\\) in multiple-treatments \\(i\\) (\\(i\\) = 1, 2, …, \\(I\\)). Before proceeding, we note that this is not homologous (i.e., formally equivalent) to multiple-readers providing ROC interpretations in a single treatment. This is because reader is a random factor while treatment is a fixed factor. The figure of merit \\(\\theta\\) is modeled as: \\[\\begin{equation} \\theta_{i\\{c\\}}=\\mu+\\tau_i+\\epsilon_{i\\{c\\}} \\tag{5.1} \\end{equation}\\] In the OR method one models the figure-of-merit, not the pseudovalues; indeed this is a key differences from the DBM method. Eqn. (5.1) models the observed figure-of-merit \\(\\theta_{i\\{c\\}}\\) as a constant term \\(\\mu\\) plus a treatment dependent term \\(\\tau_i\\) (the treatment-effect) with the constraint: \\[\\begin{equation} \\sum_{i=1}^{I}\\tau_i=0 \\tag{5.2} \\end{equation}\\] The left hand side of Eqn. (5.1) is the figure-of-merit \\(\\theta_i\\{c\\}\\) for treatment \\(i\\) and case-set index \\(\\{c\\}\\), where \\(c\\) = 1, 2, …, \\(C\\) denotes different independent case-sets sampled from the population, i.e., different collections of \\(K_1\\) non-diseased and \\(K_2\\) diseased cases. In my opinion, the case-set index is essential for clarity; without it \\(\\theta_i\\) is a fixed quantity - the figure of merit estimate for treatment \\(i\\) - lacking an index allowing for sampling related variability. Obuchowski and Rockette define a k-index, the “\\(k^{th}\\) repetition of the study involving the same diagnostic test, reader and patient (sic)”. In my opinion, what is meant is a case-set index instead of a repetition index. Repeating a study with the same treatment, reader and cases yields within-reader variability, which is different from sampling the population of cases with new case-sets, which yields case-sampling plus within-reader variability (Swets and Pickett 1982). As noted earlier, within-reader variability cannot be “turned off” and affects the interpretations of all case-sets. It is shown below that usage of the case-set index interpretation yields the same results using the DBM or the OR methods. Finally, and this is where I had some difficulty understanding what was going on, Eqn. (5.1) has an additive random error term \\(\\epsilon_{i\\{c\\}}\\) whose sampling behavior is described by a multivariate normal distribution with an I-dimensional zero mean vector and an \\(I \\times I\\) dimensional covariance matrix \\(\\Sigma\\): \\[\\begin{equation} \\epsilon_{i\\{c\\}} \\sim N_I\\left ( \\vec{0} , \\Sigma\\right ) \\tag{5.3} \\end{equation}\\] Here \\(N_I\\) is the I-variate normal distribution (i.e., each sample yields \\(I\\) random numbers). For the single-reader model Eqn. (5.1), the covariance matrix has the following structure : \\[\\begin{equation} \\Sigma_{ii&#39;}=Cov\\left ( \\epsilon_{i\\{c\\}}, \\epsilon_{i&#39;\\{c\\}} \\right )=\\left\\{\\begin{matrix} Var \\qquad (i=i&#39;)\\\\ Cov_1 \\qquad (i\\neq i&#39;) \\end{matrix}\\right. \\tag{5.4} \\end{equation}\\] The reason for the subscript “1” in \\(Cov_1\\) will become clear when one extends this model to multiple readers. The \\(I \\times I\\) covariance matrix \\(\\Sigma\\) is: \\[\\begin{equation} \\Sigma= \\begin{pmatrix} Var &amp; Cov_1 &amp; \\ldots &amp; Cov_1 &amp; Cov_1 \\\\ Cov_1 &amp; Var &amp; \\ldots &amp;Cov_1 &amp; Cov_1 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ Cov_1 &amp; Cov_1 &amp; \\ldots &amp; Var &amp; Cov_1 \\\\ Cov_1 &amp; Cov_1 &amp; \\ldots &amp; Cov_1 &amp; Var \\end{pmatrix} \\tag{5.5} \\end{equation}\\] If \\(I\\) = 2 then \\(\\Sigma\\) is a symmetric 2 x 2 matrix, whose diagonal terms are the common variances in the two treatments (each assumed equal to \\(Var\\)) and whose off-diagonal terms (each assumed equal to \\(Cov_1\\)) are the co-variances. With \\(I\\) = 3 one has a 3 x 3 symmetric matrix with all diagonal elements equal to \\(Var\\) and all off-diagonal terms are equal to \\(Cov_1\\), etc. An important aspect of the Obuchowski and Rockette model is that the variances and co-variances are assumed to be treatment independent. This implies that \\(Var\\) estimates need to be averaged over all treatments. Likewise, \\(Cov_1\\) estimates need to be averaged over all distinct treatment-treatment pairings. A more complex model, with more parameters and therefore more difficult to work with, would allow the variances to be treatment dependent, and the covariances to depend on the specific treatment pairings. For obvious reasons (“Occam’s Razor” or the law of parsimony ) one wishes to start with the simplest model that, one hopes, captures essential characteristics of the data. Some elementary statistical results are presented next. 5.2.1 Definitions of covariance and correlation The covariance of two scalar random variables X and Y is defined by: \\[\\begin{equation} Cov(X,Y) =\\frac{\\sum_{i=1}^{N}(x_{i}-x_{\\bullet})(y_{i}-y_{\\bullet})}{N-1}=E(XY)-E(X)-E(Y) \\tag{5.6} \\end{equation}\\] Here \\(E(X)\\) is the expectation value of the random variable \\(X\\), i.e., the integral of x multiplied by its \\(\\text{pdf}\\) over the range of \\(x\\): \\[E(X)=\\int \\text{pdf(x)} x dx\\] The covariance can be thought of as the common part of the variance of two random variables. The variance, a special case of covariance, of \\(X\\) is defined by: \\[Var(X,X) = Cov(X,X)=E(X^2)-(E(X))^2=\\sigma_x^2\\] It can be shown, this is the Cauchy–Schwarz inequality, that: \\[\\mid Cov(X,Y) \\mid^2 \\le Var(X)Var(Y)\\] A related quantity, namely the correlation \\(\\rho\\) is defined by (the \\(\\sigma\\)s are standard deviations): \\[\\rho_{XY} \\equiv Cor(X,Y)=\\frac{Cov(X,Y)}{\\sigma_X \\sigma_Y}\\] It has the property: \\[\\mid \\rho_{XY} \\mid \\le 1\\] 5.2.2 Special case when variables have equal variances Assuming \\(X\\) and \\(Y\\) have the same variance: \\[Var(X)=Var(Y)\\equiv Var\\equiv \\sigma^2\\] A useful theorem applicable to the OR single-reader multiple-treatment model is: \\[\\begin{equation} Var(X-Y)=Var(X)+Var(Y)-2Cov(X,Y)=2(Var-Cov) \\tag{5.7} \\end{equation}\\] The right hand side specializes to the OR single-reader multiple-treatment model where the variances (for different treatments) are equal and likewise the covariances in Eqn. (5.5) are equal) The correlation \\(\\rho_1\\) is defined by (the reason for the subscript 1 on \\(\\rho\\) is the same as the reason for the subscript 1 on \\(Cov_1\\), which will be explained later): \\[\\rho_1=\\frac{Cov_1}{Var}\\] The I x I covariance matrix \\(\\Sigma\\) can be written alternatively as (shown below is the matrix for I = 5; as the matrix is symmetric, only elements at and above the diagonal are shown): \\[\\begin{equation} \\Sigma = \\begin{bmatrix} \\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2\\\\ &amp; \\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2\\\\ &amp; &amp; \\sigma^2 &amp; \\rho_1\\sigma^2 &amp; \\rho_1\\sigma^2\\\\ &amp; &amp; &amp; \\sigma^2 &amp; \\rho_1\\sigma^2\\\\ &amp; &amp; &amp; &amp; \\sigma^2 \\end{bmatrix} \\tag{5.8} \\end{equation}\\] 5.2.3 Estimating the variance-covariance matrix An unbiased estimate of the covariance matrix Eqn. (5.4) follows from: \\[\\begin{equation} \\Sigma_{ii&#39;}\\mid_{ps}=\\frac{1}{C-1}\\sum_{c=1}^{C} \\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\left ( \\theta_{i&#39;\\{c\\}} - \\theta_{i&#39;\\{\\bullet\\}} \\right) \\tag{5.9} \\end{equation}\\] The subscript \\(ps\\) denotes population sampling. As a special case, when \\(i = i&#39;\\), this equation yields the population sampling based variance. \\[\\begin{equation} \\text{Var}_{i}\\mid_{ps}=\\frac{1}{C-1}\\sum_{c=1}^{C} \\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right)^2 \\tag{5.10} \\end{equation}\\] The I-values when averaged yield the population sampling based estimate of \\(\\text{Var}\\). Sampling different case-sets, as required by Eqn. (5.9), is unrealistic. In reality one has \\(C\\) = 1, i.e., a single dataset. Therefore, direct application of this formula is impossible. However, as seen when this situation was encountered before in (book) Chapter 07, one uses resampling methods to realize, for example, different bootstrap samples, which are resampling-based “stand-ins” for actual case-sets. If \\(B\\) is the total number of bootstraps, then the estimation formula is: \\[\\begin{equation} \\Sigma_{ii&#39;}\\mid_{bs} =\\frac{1}{B-1}\\sum_{b=1}^{B} \\left ( \\theta_{i\\{b\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\left ( \\theta_{i&#39;\\{b\\}} - \\theta_{i&#39;\\{\\bullet\\}} \\right) \\tag{5.11} \\end{equation}\\] Eqn. (5.11), the bootstrap method of estimating the covariance matrix, is a direct translation of Eqn. (5.9). Alternatively, one could have used the jackknife FOM values \\(\\theta_{i(k)}\\), i.e., the figure of merit with a case \\(k\\) removed, repeated for all \\(k\\), to estimate the covariance matrix: \\[\\begin{equation} \\Sigma_{ii&#39;}\\mid_{jk} =\\frac{(K-1)^2}{K} \\left [ \\frac{1}{K-1}\\sum_{k=1}^{K} \\left ( \\theta_{i(k)} - \\theta_{i(\\bullet)} \\right) \\left ( \\theta_{i&#39;(k)} - \\theta_{i&#39;(\\bullet)} \\right) \\right ] \\tag{5.12} \\end{equation}\\] [For either bootstrap or jackknife, if \\(i = i&#39;\\), the equations yield the corresponding variance estimates.] Note the subtle difference in usage of ellipses and parentheses between Eqn. (5.9) and Eqn. (5.12). In the former, the subscript \\(\\{c\\}\\) denotes a set of \\(K\\) cases while in the latter, \\((k)\\) denotes the original case set with case \\(k\\) removed, leaving \\(K-1\\) cases. There is a similar subtle difference in usage of ellipses and parentheses between Eqn. (5.11) and Eqn. (5.12). The subscript enclosed in parenthesis, i.e., \\((k)\\), denotes the FOM with case \\(k\\) removed, while in the bootstrap equation one uses the ellipses (curly brackets) \\(\\{b\\}\\) to denote the \\(b^{th}\\) bootstrap case-set, i.e., a whole set of \\(K_1\\) non-diseased and \\(K_2\\) diseased cases, sampled with replacement from the original dataset. The index \\(k\\) ranges from 1 to \\(K\\), where the first \\(K_1\\) values represent non-diseased cases and the following \\(K_2\\) values represent diseased cases. Jackknife figure of merit values, such as \\(\\theta_{i(k)}\\), are not to be confused with jackknife pseudovalues used in the DBM chapters. The jackknife FOM corresponding to a particular case is the FOM with the particular case removed while the pseudovalue is \\(K\\) times the FOM with all cases include minus \\((K-1)\\) times the jackknife FOM. Unlike pseudovalues, jackknife FOM values cannot be regarded as independent and identically distributed, even when using the empirical AUC as FOM. 5.2.4 The variance inflation factor In Eqn. (5.12), the expression for the jackknife covariance estimate contains a variance inflation factor: \\[\\begin{equation} \\frac{(K-1)^2}{K} \\tag{5.13} \\end{equation}\\] This factor multiplies the traditional expression for the covariance, shown in square brackets in Eqn. (5.12). It is only needed for the jackknife estimate. The bootstrap and the DeLong estimate, see next, do not require this factor. A third method of estimating the covariance (DeLong, DeLong, and Clarke-Pearson 1988), only applicable to the empirical AUC, is not discussed here; however, it is implemented in the software. 5.2.5 Meaning of the covariance matrix in Eqn. (5.5) Suppose one has the luxury of repeatedly sampling case-sets, each consisting of \\(K\\) cases from the population. A single radiologist interprets these cases in \\(I\\) treatments. Therefore, each case-set \\(\\{c\\}\\) yields \\(I\\) figures of merit. The final numbers at ones disposal are \\(\\theta_{i\\{c\\}}\\), where \\(i\\) = 1,2,…,\\(I\\) and \\(c\\) = 1,2,…,\\(C\\). Considering treatment \\(i\\), the variance of the FOM-values for the different case-sets \\(c\\) = 1,2,…,\\(C\\), is an estimate of \\(Var_i\\) for this treatment: \\[\\begin{equation} \\sigma_i^2 \\equiv Var_i = \\frac{1}{C-1}\\sum_{c=1}^{C}\\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\tag{5.14} \\end{equation}\\] The process is repeated for all treatments and the \\(I\\)-variance values are averaged. This is the final estimate of \\(Var\\) appearing in Eqn. (5.3). To estimate the covariance matrix one considers pairs of FOM values for the same case-set \\(\\{c\\}\\) but different treatments, i.e., \\(\\theta_{i\\{c\\}}\\) and \\(\\theta_{i&#39;\\{c\\}}\\); by definition primed and un-primed indices are different. The process is repeated for different case-sets. The covariance is calculated as follows: \\[\\begin{equation} \\text{Cov}_{1;ii&#39;} = \\frac{1}{C-1}\\sum_{c=1}^{C} \\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\left ( \\theta_{i&#39;\\{c\\}} - \\theta_{i&#39;\\{\\bullet\\}} \\right) \\tag{5.15} \\end{equation}\\] The process is repeated for all combinations of different-treatment pairings and the resulting \\(I(I-1)/2\\) values are averaged yielding the final estimate of \\(\\text{Cov}_1\\). [Recall that the Obuchowski-Rockette model does not allow treatment-dependent parameters in the covariance matrix - hence the need to average over all treatment pairings.] Since they are derived from the same case-set, one expects the \\(\\theta_{i\\{c\\}}\\) and \\(\\theta_{i&#39;\\{c\\}}\\) values to be correlated. As an example, for a particularly easy case-set one expects \\(\\theta_{i\\{c\\}}\\) and \\(\\theta_{i&#39;\\{c\\}}\\) to be both higher than usual. The correlation \\(\\rho_{1;ii&#39;}\\) is defined by: \\[\\begin{equation} \\rho_{1;ii&#39;} = \\frac{1}{C-1}\\sum_{c=1}^{C} \\frac {\\left ( \\theta_{i\\{c\\}} - \\theta_{i\\{\\bullet\\}} \\right) \\left ( \\theta_{i&#39;\\{c\\}} - \\theta_{i&#39;\\{\\bullet\\}} \\right)}{\\sigma_i \\sigma_{i&#39;} } \\tag{5.16} \\end{equation}\\] Averaging over all different-treatment pairings yields the final estimate of the correlation \\(\\rho_1\\). Since the covariance is smaller than the variance, the magnitude of the correlation is smaller than 1. In most situations one expects \\(\\rho_1\\) to be positive. There is a scenario that could lead to negative correlation. With “complementary” treatments, e.g., CT vs. MRI, where one treatment is good for bone imaging and the other for soft-tissue imaging, an easy case-set in one treatment could correspond to a difficult case-set in the other treatment, leading to negative correlation. To summarize, the covariance matrix can be estimated using the jackknife or the bootstrap, or, in the special case of the empirical AUC figure of merit, the DeLong method can be used. In (book) Chapter 07, these three methods were described in the context of estimating the variance of AUC. Eqn. (5.11) and Eqn. (5.12) extend the jackknife and the bootstrap methods, respectively, to estimating the covariance of AUC (whose diagonal elements are the variances estimated in the earlier chapter). 5.2.6 Code illustrating the covariance matrix To minimize clutter, the R functions (for estimating Var and Cov1 using bootstrap, jackknife, and the DeLong methods) are not shown, but they are compiled. To display them clone or ‘fork’ the book repository and look at the Rmd file corresponding to this output and the sourced R files listed below: source(here(&quot;R/CH10-OR/Wilcoxon.R&quot;)) source(here(&quot;R/CH10-OR/VarCov1Bs.R&quot;)) source(here(&quot;R/CH10-OR/VarCov1Bs.R&quot;)) source(here(&quot;R/CH10-OR/VarCov1Jk.R&quot;)) source(here(&quot;R/CH10-OR/VarCovMtrxDLStr.R&quot;)) source(here(&quot;R/CH10-OR/VarCovs.R&quot;)) The following code chunk extracts (using the DfExtractDataset function) a single-reader multiple-treatment ROC dataset corresponding to the first reader from dataset02, which is the Van Dyke dataset. rocData1R &lt;- DfExtractDataset(dataset02, rdrs = 1) #select the 1st reader to be analyzed zik1 &lt;- rocData1R$ratings$NL[,1,,1];K &lt;- dim(zik1)[2];I &lt;- dim(zik1)[1] zik2 &lt;- rocData1R$ratings$LL[,1,,1];K2 &lt;- dim(zik2)[2];K1 &lt;- K-K2;zik1 &lt;- zik1[,1:K1] The following notation is used in the code below: jk = jackknife method bs = bootstrap method, with B = number of bootstraps and seed = value. dl = DeLong method rj_jk = RJafroc, covEstMethod = “jackknife” rj_bs = RJafroc, covEstMethod = “bootstrap” For example, Cov1_jk is the jackknife estimate of Cov1. Shown below are the results of the jackknife method, first using the code in this repository and next, as a cross-check, using RJafroc function UtilORVarComponentsFactorial: ret1 &lt;- VarCov1_Jk(zik1, zik2) Var &lt;- ret1$Var Cov1 &lt;- ret1$Cov1 # use these (i.e., jackknife) as default values in subsequent code data.frame (&quot;Cov1_jk&quot; = Cov1, &quot;Var_jk&quot; = Var) #&gt; Cov1_jk Var_jk #&gt; 1 0.0003734661 0.0006989006 ret4 &lt;- UtilORVarComponentsFactorial( rocData1R, FOM = &quot;Wilcoxon&quot;) # the functions default `covEstMethod` is jackknife data.frame (&quot;Cov1_rj_jk&quot; = ret4$VarCom[&quot;Cov1&quot;, &quot;Estimates&quot;], &quot;Var_rj_jk&quot; = ret4$VarCom[&quot;Var&quot;, &quot;Estimates&quot;]) #&gt; Cov1_rj_jk Var_rj_jk #&gt; 1 0.0003734661 0.0006989006 Note that the estimates are identical and that the \\(Cov_1\\) estimate is smaller than the \\(Var\\) estimate (their ratio is the correlation \\(\\rho_1 = Cov_1/Var\\) = 0.5343623). Shown next are bootstrap method estimates with increasing number of bootstraps (200, 2000 and 20,000): ret2 &lt;- VarCov1_Bs(zik1, zik2, 200, seed = 100) data.frame (&quot;Cov_bs&quot; = ret2$Cov1, &quot;Var_bs&quot; = ret2$Var) #&gt; Cov_bs Var_bs #&gt; 1 0.000283905 0.0005845354 ret2 &lt;- VarCov1_Bs(zik1, zik2, 2000, seed = 100) data.frame (&quot;Cov_bs&quot; = ret2$Cov1, &quot;Var_bs&quot; = ret2$Var) #&gt; Cov_bs Var_bs #&gt; 1 0.0003466804 0.0006738506 ret2 &lt;- VarCov1_Bs(zik1, zik2, 20000, seed = 100) data.frame (&quot;Cov_bs&quot; = ret2$Cov1, &quot;Var_bs&quot; = ret2$Var) #&gt; Cov_bs Var_bs #&gt; 1 0.0003680714 0.0006862668 With increasing number of bootstraps the values approach the jackknife estimates. Following, as a cross check, are results of bootstrap method as calculated by the RJafroc function UtilORVarComponentsFactorial: ret5 &lt;- UtilORVarComponentsFactorial( rocData1R, FOM = &quot;Wilcoxon&quot;, covEstMethod = &quot;bootstrap&quot;, nBoots = 2000, seed = 100) data.frame (&quot;Cov_rj_bs&quot; = ret5$VarCom[&quot;Cov1&quot;, &quot;Estimates&quot;], &quot;Var_rj_bs&quot; = ret5$VarCom[&quot;Var&quot;, &quot;Estimates&quot;]) #&gt; Cov_rj_bs Var_rj_bs #&gt; 1 0.0003466804 0.0006738506 Note that the two estimates shown above for \\(B = 2000\\) are identical. This is because the seeds are identical. With different seeds on expect sampling related fluctuations. Following are results of the DeLong covariance estimation method, the first output is using this repository code and the second using the RJafroc function UtilORVarComponentsFactorial with appropriate arguments: mtrxDLStr &lt;- VarCovMtrxDLStr(rocData1R) ret3 &lt;- VarCovs(mtrxDLStr) data.frame (&quot;Cov_dl&quot; = ret3$cov1, &quot;Var_dl&quot; = ret3$var) #&gt; Cov_dl Var_dl #&gt; 1 0.0003684357 0.0006900766 ret5 &lt;- UtilORVarComponentsFactorial( rocData1R, FOM = &quot;Wilcoxon&quot;, covEstMethod = &quot;DeLong&quot;) data.frame (&quot;Cov_rj_dl&quot; = ret5$VarCom[&quot;Cov1&quot;, &quot;Estimates&quot;], &quot;Var_rj_dl&quot; = ret5$VarCom[&quot;Var&quot;, &quot;Estimates&quot;]) #&gt; Cov_rj_dl Var_rj_dl #&gt; 1 0.0003684357 0.0006900766 Note that the two estimates are identical and that the DeLong estimate are close to the bootstrap estimates using 20,000 bootstraps. The just demonstrated close correspondence is only expected when using the Wilcoxon figure of merit, i.e., the empirical AUC. 5.2.7 Significance testing The covariance matrix is needed for significance testing. Define the mean square corresponding to the treatment effect, denoted \\(MS(T)\\), by: \\[\\begin{equation} MS(T)=\\frac{1}{I-1}\\sum_{i=1}^{I}(\\theta_i-\\theta_\\bullet)^2 \\tag{5.17} \\end{equation}\\] Unlike the previous DBM related chapters, all mean square quantities in this chapter are based on FOMs, not pseudovalues. It can be shown that under the null hypothesis that all treatments have identical performances, the test statistic \\(\\chi_{1R}\\) defined below (the \\(1R\\) subscript denotes single-reader analysis) is distributed approximately as a \\(\\chi^2\\) distribution with \\(I-1\\) degrees of freedom, i.e., \\[\\begin{equation} \\chi_{\\text{1R}} \\equiv \\frac{(I-1)MS(T)}{Var-Cov_1} \\sim \\chi_{I-1}^{2} \\tag{5.18} \\end{equation}\\] Eqn. (5.18) is from §5.4 in (Hillis 2007) with two covariance terms “zeroed out” because they are multiplied by \\(J-1 = 0\\) (since we are restricting to \\(J=1\\)). Or equivalently, in terms of the F-distribution (Hillis et al. 2005): \\[\\begin{equation} F_{\\text{1R}} \\equiv \\frac{MS(T)}{Var-Cov_1} \\sim F_{I-1, \\infty} \\tag{5.19} \\end{equation}\\] 5.2.7.1 An aside on the relation between the chisquare and the F-distribution with infinite ddf Since my background is physics, and I am more familiar with statistics like Maxwell-Boltzmann, Fermi-Dirac and Bose-Einstein, I always like to add a little more explanation than required for statisticians. Define \\(D_{1-\\alpha}\\), the \\((1-\\alpha)\\) quantile of distribution \\(D\\), such that the probability of observing a random sample \\(d\\) less than or equal to \\(D_{1-\\alpha}\\) is \\((1-\\alpha)\\): \\[\\begin{equation} \\Pr(d\\leq D_{1-\\alpha} \\mid d \\sim D)=1-\\alpha \\tag{5.20} \\end{equation}\\] With definition Eqn. (5.20), the \\((1-\\alpha)\\) quantile of the \\(\\chi_{I-1}^2\\) distribution, i.e., \\(\\chi_{1-\\alpha,I-1}^2\\), is related to the \\((1-\\alpha)\\) quantile of the \\(F_{I-1,\\infty}\\) distribution, i.e., \\(F_{1-\\alpha,I-1,\\infty}\\), as follows (see Hillis et al. 2005, Eq. 22): \\[\\begin{equation} \\frac{\\chi_{1-\\alpha,I-1}^{2}}{I-1} = F_{1-\\alpha,I-1,\\infty} \\tag{5.21} \\end{equation}\\] Eqn. (5.21) implies that the \\((1-\\alpha)\\) quantile of the F-distribution with \\(ndf=(I-1)\\) and \\(ddf =\\infty\\) equals the \\((1-\\alpha)\\) quantile of the \\(\\chi_{I-1}^2\\) distribution divided by \\((I-1)\\). Here is an R illustration of this theorem for \\(I-1 = 4\\) and \\(\\alpha = 0.05\\): qf(0.05, 4, Inf) #&gt; [1] 0.1776808 qchisq(0.05,4)/4 #&gt; [1] 0.1776808 5.2.8 p-value and confidence interval The p-value is the probability that a sample from the \\(F_{I-1,\\infty}\\) distribution is greater than the observed value of the test statistic, namely: \\[\\begin{equation} p\\equiv \\Pr(f&gt;F_{1R} \\mid f \\sim F_{I-1,\\infty}) \\tag{5.22} \\end{equation}\\] The \\((1-\\alpha)\\) confidence interval for the inter-treatment FOM difference is given by: \\[\\begin{equation} CI_{1-\\alpha,1RMT} = (\\theta_{i\\bullet} - \\theta_{i&#39;\\bullet}) \\pm t_{\\alpha/2,\\infty} \\sqrt{2(Var-Cov_1)} \\tag{5.23} \\end{equation}\\] Comparing Eqn. (5.23) to Eqn. (5.7) shows that the term \\(\\sqrt{2(Var-Cov_1)}\\) is the standard error of the inter-treatment FOM difference, whose square root is the standard deviation. The term \\(t_{\\alpha/2,\\infty}\\) is -1.96. Therefore, the confidence interval is constructed by adding and subtracting 1.96 times the standard deviation of the difference from the central value. [One has probably encountered the rule that a 95% confidence interval is plus or minus two standard deviations from the central value. The “2” comes from rounding up 1.96.] 5.2.9 Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments We have shown two methods for analyzing a single reader in multiple treatments: the DBM method, involving jackknife derived pseudovalues and the Obuchowski and Rockette method that does not have to use the jackknife, since it could use the bootstrap, or the DeLong method, if one restricts to the Wilcoxon statistic for the figure of merit, to get the covariance matrix. Since one is dealing with a single reader in multiple treatments, for DBM one needs the fixed-reader random-case analysis described in TBA §9.8 of the previous chapter (it should be obvious that with one reader the conclusions apply to the specific reader only, so reader must be regarded as a fixed factor). Shown below are results obtained using RJafroc function StSignificanceTesting with analysisOption = \"FRRC\" for method = “DBM” (which uses the jackknife), and for OR using 3 different ways of estimating the covariance matrix for the one-reader analysis (i.e., \\(Cov_1\\) and \\(Var\\)). ret1 &lt;- StSignificanceTesting( rocData1R,FOM = &quot;Wilcoxon&quot;, method = &quot;DBM&quot;, analysisOption = &quot;FRRC&quot;) data.frame(&quot;DBM:F&quot; = ret1$FRRC$FTests[&quot;Treatment&quot;, &quot;FStat&quot;], &quot;DBM:ddf&quot; = ret1$FRRC$FTests[&quot;Treatment&quot;, &quot;DF&quot;], &quot;DBM:P-val&quot; = ret1$FRRC$FTests[&quot;Treatment&quot;, &quot;p&quot;]) #&gt; DBM.F DBM.ddf DBM.P.val #&gt; 1 1.2201111 1 0.27168532 ret2 &lt;- StSignificanceTesting( rocData1R,FOM = &quot;Wilcoxon&quot;, method = &quot;OR&quot;, analysisOption = &quot;FRRC&quot;) data.frame(&quot;ORJack:Chisq&quot; = ret2$FRRC$FTests[&quot;Treatment&quot;, &quot;Chisq&quot;], &quot;ORJack:ddf&quot; = ret2$FRRC$FTests[&quot;Treatment&quot;, &quot;DF&quot;], &quot;ORJack:P-val&quot; = ret2$FRRC$FTests[&quot;Treatment&quot;, &quot;p&quot;]) #&gt; ORJack.Chisq ORJack.ddf ORJack.P.val #&gt; 1 1.2201111 1 0.26933885 ret3 &lt;- StSignificanceTesting( rocData1R,FOM = &quot;Wilcoxon&quot;, method = &quot;OR&quot;, analysisOption = &quot;FRRC&quot;, covEstMethod = &quot;DeLong&quot;) data.frame(&quot;ORDeLong:Chisq&quot; = ret3$FRRC$FTests[&quot;Treatment&quot;, &quot;Chisq&quot;], &quot;ORDeLong:ddf&quot; = ret3$FRRC$FTests[&quot;Treatment&quot;, &quot;DF&quot;], &quot;ORDeLong:P-val&quot; = ret3$FRRC$FTests[&quot;Treatment&quot;, &quot;p&quot;]) #&gt; ORDeLong.Chisq ORDeLong.ddf ORDeLong.P.val #&gt; 1 1.2345017 1 0.26653335 ret4 &lt;- StSignificanceTesting( rocData1R,FOM = &quot;Wilcoxon&quot;, method = &quot;OR&quot;, analysisOption = &quot;FRRC&quot;, covEstMethod = &quot;bootstrap&quot;) data.frame(&quot;ORBoot:Chisq&quot; = ret4$FRRC$FTests[&quot;Treatment&quot;, &quot;Chisq&quot;], &quot;ORBoot:ddf&quot; = ret4$FRRC$FTests[&quot;Treatment&quot;, &quot;DF&quot;], &quot;ORBoot:P-val&quot; = ret4$FRRC$FTests[&quot;Treatment&quot;, &quot;p&quot;]) #&gt; ORBoot.Chisq ORBoot.ddf ORBoot.P.val #&gt; 1 1.02674 1 0.31092558 The DBM and OR-jackknife methods yield identical F-statistics, but the denominator degrees of freedom are different, \\((I-1)(K-1)\\) = 113 for DBM and \\(\\infty\\) for OR. The F-statistics for OR-bootstrap and OR-DeLong are different. Shown below is a first-principles implementation of OR significance testing for the one-reader case. alpha &lt;- 0.05 theta_i &lt;- c(0,0);for (i in 1:I) theta_i[i] &lt;- Wilcoxon(zik1[i,], zik2[i,]) MS_T &lt;- 0 for (i in 1:I) { MS_T &lt;- MS_T + (theta_i[i]-mean(theta_i))^2 } MS_T &lt;- MS_T/(I-1) F_1R &lt;- MS_T/(Var - Cov1) pValue &lt;- 1 - pf(F_1R, I-1, Inf) trtDiff &lt;- array(dim = c(I,I)) for (i1 in 1:(I-1)) { for (i2 in (i1+1):I) { trtDiff[i1,i2] &lt;- theta_i[i1]- theta_i[i2] } } trtDiff &lt;- trtDiff[!is.na(trtDiff)] nDiffs &lt;- I*(I-1)/2 CI_DIFF_FOM_1RMT &lt;- array(dim = c(nDiffs, 3)) for (i in 1 : nDiffs) { CI_DIFF_FOM_1RMT[i,1] &lt;- trtDiff[i] + qt(alpha/2, df = Inf)*sqrt(2*(Var - Cov1)) CI_DIFF_FOM_1RMT[i,2] &lt;- trtDiff[i] CI_DIFF_FOM_1RMT[i,3] &lt;- trtDiff[i] + qt(1-alpha/2,df = Inf)*sqrt(2*(Var - Cov1)) print(data.frame(&quot;theta_1&quot; = theta_i[1], &quot;theta_2&quot; = theta_i[2], &quot;Var&quot; = Var, &quot;Cov1&quot; = Cov1, &quot;MS_T&quot; = MS_T, &quot;F_1R&quot; = F_1R, &quot;pValue&quot; = pValue, &quot;Lower&quot; = CI_DIFF_FOM_1RMT[i,1], &quot;Mid&quot; = CI_DIFF_FOM_1RMT[i,2], &quot;Upper&quot; = CI_DIFF_FOM_1RMT[i,3])) } #&gt; theta_1 theta_2 Var Cov1 MS_T F_1R #&gt; 1 0.91964573 0.94782609 0.00069890056 0.0003734661 0.00039706618 1.2201111 #&gt; pValue Lower Mid Upper #&gt; 1 0.26933885 -0.078183215 -0.028180354 0.021822507 The following shows the corresponding output of RJafroc. ret_rj &lt;- StSignificanceTesting( rocData1R, FOM = &quot;Wilcoxon&quot;, method = &quot;OR&quot;, analysisOption = &quot;FRRC&quot;) print(data.frame(&quot;theta_1&quot; = ret_rj$FOMs$foms[1,1], &quot;theta_2&quot; = ret_rj$FOMs$foms[2,1], &quot;Var&quot; = ret_rj$ANOVA$VarCom[&quot;Var&quot;, &quot;Estimates&quot;], &quot;Cov1&quot; = ret_rj$ANOVA$VarCom[&quot;Cov1&quot;, &quot;Estimates&quot;], &quot;MS_T&quot; = ret_rj$ANOVA$TRanova[1,3], &quot;Chisq_1R&quot; = ret_rj$FRRC$FTests[&quot;Treatment&quot;,&quot;Chisq&quot;], &quot;pValue&quot; = ret_rj$FRRC$FTests[&quot;Treatment&quot;,&quot;p&quot;], &quot;Lower&quot; = ret_rj$FRRC$ciDiffTrt[1,&quot;CILower&quot;], &quot;Mid&quot; = ret_rj$FRRC$ciDiffTrt[1,&quot;Estimate&quot;], &quot;Upper&quot; = ret_rj$FRRC$ciDiffTrt[1,&quot;CIUpper&quot;])) #&gt; theta_1 theta_2 Var Cov1 MS_T Chisq_1R #&gt; 1 0.91964573 0.94782609 0.00069890056 0.0003734661 0.00039706618 1.2201111 #&gt; pValue Lower Mid Upper #&gt; 1 0.26933885 -0.078183215 -0.028180354 0.021822507 The first-principles and the RJafroc values agree exactly with each other [for \\(I = 2\\), the F and chisquare statistics are identical]. This above code also shows how to extract the different estimates (\\(Var\\), \\(Cov_1\\), etc.) from the object ret_rj returned by RJafroc. Specifically, Var: ret_rj$ANOVA$VarCom[“Var”, “Estimates”] Cov1: ret_rj$ANOVA$VarCom[“Cov1”, “Estimates”] Chisquare-statistic: ret_rj$FRRC$FTests[“Treatment”,“Chisq”] df: ret_rj$FRRC$FTests[1,“DF”] p-value: ret_rj$FRRC$FTests[“Treatment”,“p”] CI Lower: ret_rj$FRRC$ciDiffTrt[1,“CILower”] Mid Value: ret_rj$FRRC$ciDiffTrt[1,“Estimate”] CI Upper: ret_rj$FRRC$ciDiffTrt[1,“CIUpper”] 5.2.9.1 Jumping ahead If RRRC analysis were conducted, the values are [one needs to analyze a dataset like dataset02 having more than one treatments and readers and use analysisOption = “RRRC”]: msR: ret_rj$ANOVA$TRanova[“R”, “MS”] msT: ret_rj$ANOVA$TRanova[“T”, “MS”] msTR: ret_rj$ANOVA$TRanova[“TR”, “MS”] Var: ret_rj$ANOVA$VarCom[“Var”, “Estimates”] Cov1: ret_rj$ANOVA$VarCom[“Cov1”, “Estimates”] Cov2: ret_rj$ANOVA$VarCom[“Cov2”, “Estimates”] Cov3: ret_rj$ANOVA$VarCom[“Cov3”, “Estimates”] varR: ret_rj$ANOVA$VarCom[“VarR”, “Estimates”] varTR: ret_rj$ANOVA$VarCom[“VarTR”, “Estimates”] F-statistic: ret_rj$RRRC$FTests[“Treatment”, “FStat”] ddf: ret_rj$RRRC$FTests[“Error”, “DF”] p-value: ret_rj$RRRC$FTests[“Treatment”, “p”] CI Lower: ret_rj$RRRC$ciDiffTrt[“trt0-trt1”,“CILower”] Mid Value: ret_rj$RRRC$ciDiffTrt[“trt0-trt1”,“Estimate”] CI Upper: ret_rj$RRRC$ciDiffTrt[“trt0-trt1”,“CIUpper”] For RRFC analysis, one replaces RRRC with RRFC, etc. I should note that the auto-prompt feature of RStudio makes it unnecessary to enter the complex string names shown above - RStudio will suggest them. 5.3 Multiple-reader multiple-treatment OR model The previous sections served as a gentle introduction to the single-reader multiple-treatment Obuchowski and Rockette method. This section extends it to multiple-readers interpreting a common case-set in multiple-treatments (MRMC). The extension is, in principle, fairly straightforward. Compared to Eqn. (5.1), one needs an additional \\(j\\) index to denote reader dependence of the figure of merit, and additional terms to model reader and treatment-reader variability, and the error term needs to be modified to account for the additional random (i.e., reader) factor. The general Obuchowski and Rockette model for fully paired multiple-reader multiple-treatment interpretations is: \\[\\begin{equation} \\theta_{ij\\{c\\}}=\\mu+\\tau_i+R_j+(\\tau R)_{ij}+\\epsilon_{ij\\{c\\}} \\tag{5.24} \\end{equation}\\] The fixed treatment effect \\(\\tau_i\\) is subject to the usual constraint, Eqn. (5.2). The first two terms on the right hand side of Eqn. (5.24) have their usual meanings: a constant term \\(\\mu\\) representing performance averaged over treatments and readers, and a treatment effect \\(\\tau_i\\) (\\(i\\) = 1,2, …, \\(I\\)). The next two terms are, by assumption, mutually independent random samples specified as follows: \\(R_j\\) denotes the random treatment-independent figure-of-merit contribution of reader \\(j\\) (\\(j\\) = 1,2, …, \\(J\\)), modeled by a zero-mean normal distribution with variance \\(\\sigma_R^2\\); \\((\\tau R)_{ij}\\) denotes the treatment-dependent random contribution of reader \\(j\\) in treatment \\(i\\), modeled as a sample from a zero-mean normal distribution with variance \\(\\sigma_{\\tau R}^2\\). There could be a perceived notational clash with similar variance component terms defined for the DBM model – except in that case they applied to pseudovalues. The meaning should be clear from the context. Summarizing: \\[\\begin{equation} \\left\\{\\begin{matrix} R_j \\sim N(0,\\sigma_R^2)\\\\ {\\tau R} \\sim N(0,\\sigma_{\\tau R}^2) \\end{matrix}\\right. \\tag{5.25} \\end{equation}\\] For a single dataset \\(c\\) = 1. An estimate of \\(\\mu\\) follows from averaging over the \\(i\\) and \\(j\\) indices (the averages over the random terms are zeroes): \\[\\begin{equation} \\mu = \\theta_{\\bullet \\bullet \\{1\\}} \\tag{5.26} \\end{equation}\\] Averaging over the j index and performing a subtraction yields an estimate of \\(\\tau_i\\): \\[\\begin{equation} \\tau_i = \\theta_{i \\bullet \\{1\\}} - \\theta_{\\bullet \\bullet \\{1\\}} \\tag{5.27} \\end{equation}\\] The \\(\\tau_i\\) estimates obey the constraint Eqn. (5.2). For example, with two treatments, the values of \\(\\tau_i\\) must be the negatives of each other: \\(\\tau_1=-\\tau_2\\). The error term on the right hand side of Eqn. (5.24) is more complex than the corresponding DBM model error term. Obuchowski and Rockette model this term with a multivariate normal distribution with a length \\((IJ)\\) zero-mean vector and a \\((IJ \\times IJ)\\) dimensional covariance matrix \\(\\Sigma\\). In other words, \\[\\begin{equation} \\epsilon_{ij\\{c\\}} \\sim N_{IJ}(\\vec{0},\\Sigma) \\tag{5.28} \\end{equation}\\] Here \\(N_{IJ}\\) is the \\(IJ\\)-variate normal distribution, \\(\\vec{0}\\) is the zero-vector with length \\(IJ\\), denoting the vector-mean of the distribution. The counterpart of the variance, namely the covariance matrix \\(\\Sigma\\) of the distribution, is defined by 4 parameters, \\(Var, Cov_1, Cov_2, Cov_3\\), defined as follows: \\[\\begin{equation} Cov(\\epsilon_{ij\\{c\\}},\\epsilon_{i&#39;j&#39;\\{c\\}}) = \\left\\{\\begin{matrix} Var \\; (i=i&#39;,j=j&#39;) \\\\ Cov1 \\; (i\\ne i&#39;,j=j&#39;)\\\\ Cov2 \\; (i = i&#39;,j \\ne j&#39;)\\\\ Cov3 \\; (i\\ne i&#39;,j \\ne j&#39;) \\end{matrix}\\right\\} \\tag{5.29} \\end{equation}\\] Apart from fixed effects, the model implied by Eqn. (5.24) and Eqn. (5.29) contains 6 parameters: \\[\\sigma_R^2,\\sigma_{\\tau R}^2,Var,Cov_1,Cov_2,Cov_3\\] This is the same number of variance component parameters as in the DBM model, which should not be a surprise since one is modeling the data with equivalent models. The Obuchowski and Rockette model Eqn. (5.24) “looks” simpler because four covariance terms are encapsulated in the \\(\\epsilon\\) term. As with the singe-reader multiple-treatment model, the covariance matrix is assumed to be independent of treatment or reader. It is implicit in the Obuchowski-Rockette model that the \\(Var\\), \\(Cov_1\\), \\(Cov_2\\), and \\(Cov_3\\) estimates need to be averaged over all applicable treatment-reader combinations. 5.3.1 Structure of the covariance matrix To understand the structure of this matrix, recall that the diagonal elements of a square covariance matrix are the variances and the off-diagonal elements are covariances. With two indices \\(ij\\) one can still imagine a square matrix where each dimension is labeled by a pair of indices \\(ij\\). One \\(ij\\) pair corresponds to the horizontal direction, and the other \\(ij\\) pair corresponds to the vertical direction. To visualize this let consider the simpler situation of two treatments (\\(I = 2\\)) and three readers (\\(J = 3\\)). The resulting \\(6 \\times 6\\) covariance matrix would look like this: \\[ \\Sigma= \\begin{bmatrix} (11,11) &amp; (12,11) &amp; (13,11) &amp; (21,11) &amp; (22,11) &amp; (23,11) \\\\ &amp; (12,12) &amp; (13,12) &amp; (21,12) &amp; (22,12) &amp; (23,12) \\\\ &amp; &amp; (13,13) &amp; (21,13) &amp; (22,13) &amp; (23,13) \\\\ &amp; &amp; &amp; (21,21) &amp; (22,21) &amp; (23,21) \\\\ &amp; &amp; &amp; &amp; (22,22) &amp; (23,22) \\\\ &amp; &amp; &amp; &amp; &amp; (23,23) \\end{bmatrix} \\] Shown in each cell of the matrix is a pair of ij-values, serving as column indices, followed by a pair of ij-values serving as row indices, and a comma separates the pairs. For example, the first column is labeled by (11,xx), where xx depends on the row. The second column is labeled (12,xx), the third column is labeled (13,xx), and the remaining columns are successively labeled (21,xx), (22,xx) and (23,xx). Likewise, the first row is labeled by (yy,11), where yy depends on the column. The following rows are labeled (yy,12), (yy,13), (yy,21), (yy,22)and (yy,23). Note that the reader index increments faster than the treatment index. The diagonal elements are evidently those cells where the row and column index-pairs are equal. These are (11,11), (12,12), (13,13), (21,21), (22,22) and (23,23). According to Eqn. (5.29) these cells represent \\(Var\\). \\[ \\Sigma= \\begin{bmatrix} Var &amp; (12,11) &amp; (13,11) &amp; (21,11) &amp; (22,11) &amp; (23,11) \\\\ &amp; Var &amp; (13,12) &amp; (21,12) &amp; (22,12) &amp; (23,12) \\\\ &amp; &amp; Var &amp; (21,13) &amp; (22,13) &amp; (23,13) \\\\ &amp; &amp; &amp; Var &amp; (22,21) &amp; (23,21) \\\\ &amp; &amp; &amp; &amp; Var &amp; (23,22) \\\\ &amp; &amp; &amp; &amp; &amp; Var \\end{bmatrix} \\] According to Eqn. (5.29) cells with different treatment indices but identical reader indices represent \\(Cov_1\\). As an example, cell (21,11) has the same reader indices, namely reader 1, but different treatment indices, namely 2 and 1, so it is \\(Cov_1\\): \\[ \\Sigma= \\begin{bmatrix} Var &amp; (12,11) &amp; (13,11) &amp; Cov_1 &amp; (22,11) &amp; (23,11) \\\\ &amp; Var &amp; (13,12) &amp; (21,12) &amp; Cov_1 &amp; (23,12) \\\\ &amp; &amp; Var &amp; (21,13) &amp; (22,13) &amp; Cov_1 \\\\ &amp; &amp; &amp; Var &amp; (22,21) &amp; (23,21) \\\\ &amp; &amp; &amp; &amp; Var &amp; (23,22) \\\\ &amp; &amp; &amp; &amp; &amp; Var \\end{bmatrix} \\] Similarly, cells with identical treatment indices but different reader indices represent \\(Cov_2\\): \\[ \\Sigma= \\begin{bmatrix} Var &amp; Cov_2 &amp; Cov_2 &amp; Cov_1 &amp; (22,11) &amp; (23,11) \\\\ &amp; Var &amp; Cov_2 &amp; (21,12) &amp; Cov_1 &amp; (23,12) \\\\ &amp; &amp; Var &amp; (21,13) &amp; (22,13) &amp; Cov_1 \\\\ &amp; &amp; &amp; Var &amp; Cov_2 &amp; Cov_2 \\\\ &amp; &amp; &amp; &amp; Var &amp; Cov_2 \\\\ &amp; &amp; &amp; &amp; &amp; Var \\end{bmatrix} \\] Finally, cells with different treatment indices and different reader indices represent \\(Cov_3\\): \\[ \\Sigma= \\begin{bmatrix} Var &amp; Cov_2 &amp; Cov_2 &amp; Cov_1 &amp; Cov_3 &amp; Cov_3 \\\\ &amp; Var &amp; Cov_2 &amp; Cov_3 &amp; Cov_1 &amp; Cov_3 \\\\ &amp; &amp; Var &amp; Cov_3 &amp; Cov_3 &amp; Cov_1 \\\\ &amp; &amp; &amp; Var &amp; Cov_2 &amp; Cov_2 \\\\ &amp; &amp; &amp; &amp; Var &amp; Cov_2 \\\\ &amp; &amp; &amp; &amp; &amp; Var \\end{bmatrix} \\] To understand these terms consider how they might be estimated. Suppose one had the luxury of repeating the study with different case-sets, c = 1, 2, …, C. Then the variance \\(Var\\) is estimated as follows: \\[\\begin{equation} Var= \\left \\langle \\frac{1}{C-1}\\sum_{c=1}^{C} (\\theta_{ij\\{c\\}}-\\theta_{ij\\{\\bullet\\}})^2 \\right \\rangle_{ij} \\epsilon_{ij\\{c\\}} \\sim N_{IJ}(\\vec{0},\\Sigma) \\tag{5.30} \\end{equation}\\] Of course, in practice one would use the bootstrap or the jackknife as a stand-in for the c-index. Notice that the left-hand-side of Eqn. (5.30) lacks treatment or reader indices. This is because implicit in the notation is averaging the observed variances over all treatments and readers, as implied by \\(\\left \\langle \\right \\rangle _{ij}\\). Likewise, the covariance terms are estimated as follows: \\[\\begin{equation} Cov=\\left\\{\\begin{matrix} Cov_1=\\left \\langle \\frac{1}{C-1}\\sum_{c=1}^{C} (\\theta_{ij\\{c\\}}-\\theta_{ij\\{\\bullet\\}}) (\\theta_{i&#39;j\\{c\\}}-\\theta_{i&#39;j\\{\\bullet\\}}) \\right \\rangle_{ii&#39;,jj}\\\\ Cov_2=\\left \\langle \\frac{1}{C-1}\\sum_{c=1}^{C} (\\theta_{ij\\{c\\}}-\\theta_{ij\\{\\bullet\\}}) (\\theta_{ij&#39;\\{c\\}}-\\theta_{ij&#39;\\{\\bullet\\}}) \\right \\rangle_{ii,jj&#39;}\\\\ Cov_3=\\left \\langle \\frac{1}{C-1}\\sum_{c=1}^{C} (\\theta_{ij\\{c\\}}-\\theta_{ij\\{\\bullet\\}}) (\\theta_{i&#39;j&#39;\\{c\\}}-\\theta_{i&#39;j&#39;\\{\\bullet\\}}) \\right \\rangle_{ii&#39;,jj&#39;} \\end{matrix}\\right. \\tag{5.31} \\end{equation}\\] In Eqn. (5.31) the convention is that primed and unprimed variables are always different. Since there are no treatment and reader dependencies on the left-hand-sides of the above equations, one averages the estimates as follows: For \\(Cov_1\\) one averages over all combinations of different treatments and same readers, as denoted by \\(\\left \\langle \\right \\rangle_{ii&#39;,jj}\\). For \\(Cov_2\\) one averages over all combinations of same treatment and different readers, as denoted by \\(\\left \\langle \\right \\rangle_{ii,jj&#39;}\\). For \\(Cov_3\\) one averages over all combinations of different treatments and different readers, as denoted by \\(\\left \\langle \\right \\rangle_{ii&#39;,jj&#39;}\\). 5.3.2 Physical meanings of the covariance terms The meanings of the different terms follow a similar description to that given in Eqn. 5.3.1. The diagonal term \\(Var\\) is the variance of the figures-of-merit when reader \\(j\\) interprets different case-sets \\(\\{c\\}\\) in treatment \\(i\\). Each case-set yields a number \\(\\theta_{ij\\{c\\}}\\) and the variance of the \\(C\\) numbers, averaged over the \\(I \\times J\\) treatments and readers, is \\(Var\\). It captures the total variability due to varying difficulty levels of the case-sets, inter-reader and within-reader variability. It is easier to see the physical meanings of \\(Cov_1, Cov_2, Cov_3\\) if one starts with the correlations. \\(\\rho_{1;ii&#39;jj}\\) is the correlation of the figures-of-merit when reader \\(j\\) interprets case-sets in different treatments \\(i,i&#39;\\). Each case-set, starting with \\(c = 1\\), yields two numbers \\(\\theta_{ij\\{1\\}}\\) and \\(\\theta_{i&#39;j\\{1\\}}\\). The correlation of the two pairs of C-length arrays, averaged over all pairings of different treatments and same readers, is \\(\\rho_1\\). The correlation exists due to the common contribution of the shared reader. When the common variation is large, the two arrays become more correlated and \\(\\rho_1\\) approaches unity. If there is no common variation, the two arrays become independent, and \\(\\rho_1\\) equals zero. Converting from correlation to covariance, see Eqn. (5.8), one has \\(Cov_1 &lt; Var\\). \\(\\rho_{2;iijj&#39;}\\) is the correlation of the figures-of-merit values when different readers \\(j,j&#39;\\) interpret the same case-sets in the same treatment \\(i\\). As before this yields two C-length arrays, whose correlation, upon averaging over all distinct treatment pairings and same readers, yields \\(\\rho_2\\). If one assumes that common variation between different-reader same-treatment FOMs is smaller than the common variation between same-reader different-treatment FOMs, then \\(\\rho_2\\) will be smaller than \\(\\rho_1\\). This is equivalent to stating that readers agree more with themselves in different treatments than they do with other readers in the same treatment. Translating to covariances, one has \\(Cov_2 &lt; Cov_1 &lt; Var\\). \\(\\rho_{3;ii&#39;jj&#39;}\\) is the correlation of the figure-of-merit values when different readers \\(j,j&#39;\\) interpret the same case set in different treatments \\(i,i&#39;\\), etc., yielding \\(\\rho_3\\). This is expected to yield the least correlation. Summarizing, one expects the following ordering for the terms in the covariance matrix: \\[\\begin{equation} Cov_3 &lt; Cov_2 &lt; Cov_1 &lt; VarCov_3 \\leq Cov_2 \\leq Cov_1 \\leq Var \\tag{5.32} \\end{equation}\\] 5.3.3 OR random-reader random-case analysis A model such as Eqn. (5.24) cannot be analyzed by standard analysis of variance (ANOVA) techniques. Because of the correlated structure of the error term a customized ANOVA is needed (in standard ANOVA models, such as used in DBM, the covariance matrix of the error term is diagonal with all diagonal elements equal to a common variance, represented by the epsilon term in the DBM model). The null hypothesis (NH) is that the true figures-of-merit of all treatments are identical, i.e., \\[\\begin{equation} NH:\\tau_i=0\\;\\; (i=1,2,...,I) \\tag{5.33} \\end{equation}\\] The analysis described next considers both readers and cases as random effects. A modified F-statistic is needed, denoted \\(F_{OR_H}\\), and defined by: \\[\\begin{equation} F_{OR_H}=\\frac{MS(T)}{MS(TR)+J\\max(Cov_2-Cov_3,0)} \\tag{5.34} \\end{equation}\\] Eqn. (5.34) incorporates Hillis’ modification, which ensures that the constraint Eqn. (5.32) is always obeyed and also avoids a possibly negative (hence illegal) F-statistic. The mean square (MS) terms are defined by (these are calculated using FOM values, not pseudovalues): \\[\\begin{equation} \\left.\\begin{matrix} MS(T)=\\frac{J}{I-1}\\sum_{i=1}^{I}(\\theta_{i\\bullet}-\\theta_{\\bullet\\bullet})^2\\\\ \\\\ MS(R)=\\frac{I}{J-1}\\sum_{j=1}^{J}(\\theta_{\\bullet j}-\\theta_{\\bullet\\bullet})^2\\\\ \\\\ MS(TR)=\\frac{1}{(I-1)(J-1)}\\sum_{i=1}^{I}\\sum_{j=1}^{J}(\\theta_{ij}-\\theta_{i\\bullet}-\\theta_{\\bullet j}+\\theta_{\\bullet\\bullet}) \\end{matrix}\\right\\} \\tag{5.35} \\end{equation}\\] In their original paper (Obuchowski and Rockette 1995) Obuchowski and Rockette state that their proposed test statistic F (basically, Eqn. (5.34) without the constraint implied by the \\(\\text{max}\\) function) is distributed as an F-statistic with numerator degree of freedom \\(\\text{ndf}=I-1\\) and denominator degree of freedom ddf = \\((I-1)(J-1)\\). Their test turns out to be very conservative, meaning it is highly biased against rejecting the null hypothesis. 5.4 Two anecdotes The author has two anecdotes. The late Dr. Robert F. Wagner once stated to the author (ca. 2001) that the sample-size tables published by Obuchowski (Obuchowski 1998, 2000), using the version of Eqn. (5.34) with the ddf as originally suggested by Obuchowski and Rockette, predicted such high number of readers and cases that he was doubtful about the chances of anyone conducting a practical ROC study! The second story is that the author once conducted NH simulations using a Roe-Metz simulator and the significance testing as described in the Obuchowski-Rockette paper: the method did not reject the null hypothesis even once in 2000 trials! Recall that with \\(\\alpha = 0.05\\) a valid test should reject the null hypothesis about \\(100\\pm20\\) times in 2000 trials. The author recalls (ca. 2004) telling Dr. Steve Hillis about this issue, and he suggested a different value for the denominator degrees of freedom ddf, substitution of which magically solved the problem, i.e., the simulations rejected the null hypothesis 5% of the time. 5.5 Back to the main story Hillis’ proposed new ddf is shown below (ndf is unchanged), with the subscript \\(H\\) denoting the Hillis modification: \\[\\begin{equation} \\text{ndf}=I-1 \\tag{5.36} \\end{equation}\\] \\[\\begin{equation} \\text{ddf_H}=\\frac{\\left [ MS(TR) + J \\max(Cov_2-Cov_3,0)\\right ]^2}{\\frac{\\left [ MS(TR) \\right ]^2}{(I-1)(J-1)}} \\tag{5.37} \\end{equation}\\] If \\(Cov_2 &lt; Cov_3\\) (which is the exact opposite of the expected ordering, Eqn. (5.32)) this reduces to \\((I-1)\\times(J-1)\\), the value originally proposed by Obuchowski and Rockette. With Hillis’ proposed changes, under the null hypothesis the observed statistic \\(F_{OR_H}\\), defined in Eqn. (5.34), is distributed as an F-statistic with \\(\\text{ndf} = I-1\\) and ddf \\(= ddf_H\\) degrees of freedom (Hillis et al. 2005; Hillis 2007; Hillis, Berbaum, and Metz 2008): \\[\\begin{equation} F_{OR_H}\\sim F_{ndf,ddf_H} \\tag{5.38} \\end{equation}\\] If the expected ordering is true, i.e., \\(Cov_2 &gt; Cov_3\\) , which is the more likely situation, then \\(ddf_H\\) is larger than \\((I-1)\\times(J-1)\\), i.e., that stated in Obuchowski-Rockette’s original paper, and the p-value decreases, i.e., there is a larger probability of rejecting the NH. With the new degrees of freedom the OR method is more likely to have the correct NH behavior, i.e, it will reject the NH 5% of the time when alpha is set to 0.05 (statisticians refer to this as “the 5% test”). This has been confirmed in simulation testing (Hillis, Berbaum, and Metz (2008)). 5.5.0.1 Decision rule, p-value and confidence interval The critical value of the F-statistic for rejection of the null hypothesis is \\(F_{1-\\alpha,ndf,ddf_H}\\), i.e., that value such that fraction \\((1-\\alpha)\\) of the area under the distribution lies to the left of the critical value. From definition Eqn. (5.34): Rejection of the NH is more likely if \\(MS(T)\\) increases, meaning the treatment effect is larger; \\(MS(TR)\\) is smaller meaning there is less contamination of the treatment effect by treatment-reader variability; The greater of \\(Cov2\\) or \\(Cov3\\), which is usually \\(Cov2\\), decreases, meaning there is less “noise” in the measurement due to between-reader variability. Recall that \\(Cov_2\\) involves different-reader same-treatment pairings. \\(\\alpha\\) increases, meaning one is allowing a greater probability of Type I errors; \\(ndf\\) increases, meaning that with more treatment pairings, the chance that at least one pair will reject the NH is larger; \\(ddf_H\\) increases, as this lowers the critical value of the F-statistic. The p-value of the test is the probability, under the NH, that an equal or larger value of the F-statistic than \\(F_{OR}\\) could be observed by chance. In other words, it is the area under the F-distribution \\(F_{ndf,ddf_H}\\) that lies above the observed value \\(F_{OR}\\): \\[\\begin{equation} p=\\Pr(F&gt;F_{OR} \\mid F\\sim F_{ndf,ddf_H}) \\tag{5.39} \\end{equation}\\] The \\((1-\\alpha)\\) confidence interval for \\(\\theta_{i \\bullet} - \\theta_{i&#39; \\bullet}\\) is given by (the average is over the reader index; the case-set index \\(\\{1\\}\\) is suppressed): \\[\\begin{equation} CI_{1-\\alpha,RRRC}=(\\theta_{i \\bullet} - \\theta_{i&#39; \\bullet}) \\pm t_{\\alpha/2, (ddf_H}\\sqrt{\\frac{2}{J}(MS(TR)+J\\max(Cov_2-Cov_3,0))} \\tag{5.40} \\end{equation}\\] 5.5.1 Fixed-reader random-case (FRRC) analysis Using the vertical bar notation \\(\\mid R\\) to denote that reader is regarded as a fixed effect (Roe and Metz 1997), the appropriate F -statistic for testing the null hypothesis \\(NH: \\tau_i = 0 \\; (i=1,1,2,...I)\\) is (Hillis 2007): \\[\\begin{equation} F_{OR \\mid R}=\\frac{MS(T)}{Var-Cov_1+(J-1)\\max(Cov_2-Cov_3,0)} \\tag{5.41} \\end{equation}\\] \\(F_{OR \\mid R}\\), a realization (i.e., observation) of a random variable, is distributed as an F-statistic with: \\[\\begin{equation} \\left.\\begin{matrix} ndf=I-1\\\\ ddf=\\infty\\\\ F_{OR \\mid R} \\sim F_{ndf,ddf} \\end{matrix}\\right\\} \\tag{5.42} \\end{equation}\\] Alternatively, as with Eqn. (5.18), \\[(I-1)F_{OR \\mid R} \\sim t_{I-1}\\] For \\(J\\) = 1, Eqn. (5.41) reduces to Eqn. (5.19). The critical value of the statistic is \\(F_{1-\\alpha,I-1,\\infty}\\) which is that value such that fraction \\((1-\\alpha)\\) of the area under the distribution lies to the left of the critical value. The null hypothesis is rejected if the observed value of the F- statistic exceeds the critical value, i.e.,: \\[F_{OR \\mid R}&gt;F_{1-\\alpha,I-1,\\infty}\\] The p-value of the test is the probability that a random sample from the distribution \\(F_{I-1,\\infty}\\) exceeds the observed value of the F statistic defined in Eqn. (5.41): \\[\\begin{equation} p=\\Pr(F&gt;F_{OR \\mid R} \\mid F \\sim F_{I-1,\\infty}) \\tag{5.43} \\end{equation}\\] The \\((1-\\alpha)\\) (symmetric) confidence interval for the difference figure of merit is given by: \\[\\begin{equation} CI_{1-\\alpha,FRRC}=(\\theta_{i \\bullet} - \\theta_{i&#39; \\bullet}) \\pm t_{\\alpha/2, \\infty}\\sqrt{\\frac{2}{J}(Var-Cov_1+(J-1)\\max(Cov_2-Cov_3,0))} \\tag{5.44} \\end{equation}\\] One can think of the numerator terms on the right hand side of Eqn. (5.44) as the variance of the inter-treatment FOM difference per reader, and the division by \\(J\\) is needed as the readers, as a group, have smaller variance in inverse proportion to their numbers. The NH is rejected if any of the following equivalent conditions is met: The observed value of the F-statistic exceeds the critical value \\(F_{1-\\alpha,I-1,\\infty}\\). The p-value defined by Eqn. (5.43) is less than \\(\\alpha\\). The \\((1-\\alpha)\\) confidence interval does not include zero. Notice that for J = 1, Eqn. (5.44) reduces to Eqn. (5.23). 5.5.2 Random-reader fixed-case (RRFC) analysis When case is treated as a fixed factor, the appropriate F-statistic for testing the null hypothesis \\(NH: \\tau_i = 0 \\; (i=1,1,2,...I)\\) is: \\[\\begin{equation} F_{OR \\mid C}=\\frac{MS(T)}{MS(TR)} \\tag{5.45} \\end{equation}\\] \\(F_{OR \\mid C}\\) is distributed as an F-statistic with: \\[\\begin{equation} \\left.\\begin{matrix} ndf=I-1\\\\ ddf=(I-1)(J-1)\\\\ F_{OR \\mid C} \\sim F_{ndf,ddf} \\end{matrix}\\right\\} \\tag{5.46} \\end{equation}\\] The critical value of the statistic is \\(F_{1-\\alpha,I-1,(I-1)(J-1)}\\), which is that value such that fraction \\((1-\\alpha)\\) of the distribution lies to the left of the critical value. The null hypothesis is rejected if the observed value of the F statistic exceeds the critical value: \\[F_{OR \\mid C}&gt;F_{1-\\alpha,I-1,(I-1)(J-1)}\\] The p-value of the test is the probability that a random sample from the distribution exceeds the observed value: \\[p=\\Pr(F&gt;F_{OR \\mid C} \\mid F \\sim F_{1-\\alpha,I-1,(I-1)(J-1)})\\] The \\((1-\\alpha)\\) confidence interval is given by: \\[\\begin{equation} CI_{1-\\alpha,RRFC}=(\\theta_{i \\bullet} - \\theta_{i&#39; \\bullet}) \\pm t_{\\alpha/2, (I-1)(J-1)}\\sqrt{\\frac{2}{J}MS(TR)} \\tag{5.47} \\end{equation}\\] It is time to reinforce the formulae with examples. 5.5.3 Single-treatment multiple-reader analysis Suppose one has data in a single treatment \\(i\\) and multiple readers are involved. One wishes to determine if the performance of the readers as a group equals some specified value. Since only a single treatment is involved, an implicit \\(i\\) dependence, in subsequent formulae, is ignored. In Eqn. 5.2 single-reader multiple-treatment analysis was described. It is not identical to single-treatment multiple-reader analysis. Treatment is a fixed factor while reader is a random factor. Therefore, one cannot simply use the previous analysis with reader and treatment interchanged (a graduate student tried to do just that, and he is quite smart, hence the reason for this warning). In the analysis described in this section reader is regarded as a random effect. The average performance of the readers is estimated and compared to a specified value. Hillis has described the appropriate modifications. [TBA Two approaches are described, one using the DBM pseudovalue based model and the other based on the OR model with appropriate modification. The second approach is summarized below. TBA] For single-treatment multiple-reader OR analysis, the figure of merit model is (contrast the following equation to Eqn. (5.1) noting the absence of an \\(i\\) index. If multiple modalities are present the current analysis is applicable to data in each treatment analyzed one at a time): \\[\\begin{equation} \\theta_{j\\{c\\}}=\\mu+R_j+\\epsilon_{j\\{c\\}} \\tag{5.48} \\end{equation}\\] One wishes to test the NH: \\(\\mu=\\mu_0\\) where \\(\\mu_0\\) is some pre-specified value. (since \\(C\\) = 1, in the interest of brevity one can suppress the \\(c\\) index): \\[\\begin{equation} \\mu=\\theta_{\\bullet} \\tag{5.49} \\end{equation}\\] The variance of the reader-averaged FOM can be shown (Obuchowski and Rockette 1995) to be given by (the reference is to the original OR publication, specifically Eqn. 2.3): \\[\\begin{equation} \\sigma_{\\theta_{\\bullet}}^{2}=\\frac{1}{J}(\\sigma_{R}^{2}+Var+(J-1)Cov_2) \\tag{5.50} \\end{equation}\\] 5.5.4 Connection to existing literature Rather than attempt to derive the preceding equation, it is shown how it follows from the existing literature (Obuchowski and Rockette 1995). For convenience Eqn. 2.3 in cited reference is reproduced below. \\[\\begin{equation} Var(\\theta_{i \\bullet \\bullet}) =\\frac{1}{J}(\\sigma_{b}^{2}+\\sigma_{ab}^{2}+(\\sigma_{w}^{2}/K) + \\sigma_{c}^{2}(1+J(J-1)r_2)) \\tag{5.51} \\end{equation}\\] In the OR notation, the FOM has three indices, \\(\\theta_{ijk}\\). One deletes the \\(i\\) index as one is dealing with a single treatment and one can drop the average over the \\(k\\) index, as one is dealing with a single dataset; \\(\\sigma_{b}^{2}\\) in the OR notation is what we are calling \\(\\sigma_{R}^{2}\\); for single treatment the treatment-reader interaction term \\(\\sigma_{ab}^{2}\\) is absent; and for single “replication” the term \\(\\sigma_{w}^{2}/K\\) (in OR notation \\(K\\) is the number of replications) is absent, or, more accurately, the within-reader variance \\(\\sigma_{w}^{2}\\) is absorbed into the case sampling variance \\(\\sigma_{c}^{2}\\) as the two are inseparable); the term \\(\\sigma_{\\epsilon}^{2}\\) is what we are calling \\(Var\\); and \\(\\sigma_{c}^{2}r_2\\) in OR paper is what we are calling \\(Cov_2\\). One needs to replace \\(\\sigma_{R}^{2}\\) in Eqn. (5.52) with an expected value. Again, rather than attempt to derive the following equation, it is shown how it follows from the existing literature (Hillis 2014). We start with Table I ibid: this is a table of expected means squares for the OR model, analogous to the expected mean squares table in Chapter 09, for the DBM model. For a single treatment (in the notation of the cited reference, \\(t\\) = 1 and the treatment-reader variance component goes away and the term \\(\\sigma_{\\epsilon}^{2}\\) is what we are calling \\(Var\\)), it follows that: \\[E(MS(R))=\\sigma_{R}^{2}+Var=Cov_2\\] Substituting this equation in Eqn. (5.52) yields, \\[\\begin{equation} \\sigma_{\\theta_{\\bullet}}^{2}=\\frac{1}{J}(E(MS(R))+JCov_2) \\tag{5.52} \\end{equation}\\] An estimate of \\(MS(R)\\) is given by (from here on it is understood that \\(MSR\\) is an estimate defined by: \\[\\begin{equation} MS(R)=\\frac{1}{J-1}\\sum_{j=1}^{J}(\\theta_j - \\theta_{\\bullet})^2 \\tag{5.53} \\end{equation}\\] Replacing the expected mean-square value with the estimate and avoiding negative covariance, which could lead to a negative variance estimate, one has: \\[\\begin{equation} \\sigma_{\\theta_{\\bullet}}^{2}=\\frac{1}{J}(MS(R)+J\\max(Cov_2,0)) \\tag{5.54} \\end{equation}\\] The observed value of the t-statistic for testing the NH is \\(t_{1T}\\) (the supbscript means that this statistic applies to single treatment analysis): \\[\\begin{equation} t_{1T}=\\frac{\\mu-\\mu_0}{\\sigma_{\\theta_{\\bullet}}}=(\\theta_{\\bullet}-\\mu_0)\\sqrt{\\frac{J}{(MS(R)+J\\max(Cov_2,0)}} \\tag{5.55} \\end{equation}\\] This is distributed as a t-statistic with \\(df_{H}^{I=1}\\) degrees of freedom: \\[\\begin{equation} t_{1T} \\sim t_{df_{H}^{1T}} \\tag{5.56} \\end{equation}\\] In the above equation, Hillis single-treatment degree of freedom \\(t_{df_{H}^{1T}}\\) is defined by (Hillis 2014): \\[\\begin{equation} df_{H}^{1T}=(J-1)\\left [\\frac{MS(R)+J \\max(Cov_2,0)}{MS(R)} \\right ]^2 \\tag{5.57} \\end{equation}\\] The p-value of the test is the probability that the a random sample from the specified t-distribution exceeds the magnitude of the observed value: \\[\\begin{equation} p=\\Pr(t&gt;\\left | t \\right |\\mid t \\sim t_{df_{H}^{1T}}) \\tag{5.58} \\end{equation}\\] Therefore, a \\(100 \\times (1-\\alpha)\\) percent confidence interval for \\(\\theta_{\\bullet}-\\mu_0\\) is: \\[\\begin{equation} \\theta_{\\bullet}-\\mu_0 \\pm t_{\\alpha/2,df_{H}^{1T}} \\sqrt{ \\frac{MS(R)+\\max(Cov_2,0)}{J}} \\tag{5.59} \\end{equation}\\] The single treatment method is implemented in mainSingleTreatment.R. The relevant code is listed in Online Appendix 10.F. Source the code to get the following output. 5.6 Discussion/Summary 5.7 References REFERENCES "]
]
