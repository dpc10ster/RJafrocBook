[["froc-paradigm-froc-vs-afroc.html", "Chapter 19 FROC vs. wAFROC 19.1 Introduction 19.2 FROC vs. wAFROC 19.3 Two other examples are given. 19.4 Discussion 19.5 References", " Chapter 19 FROC vs. wAFROC 19.1 Introduction TBA This chapter needs a major rewrite; 10/6/20 One plot is being repeated Need to add comparisons to ROC Don’t need columns 1 and 3 in table The FROC curve was introduced in (Bunch et al. 1977) and ever since it has been widely used for evaluating performance in the free-response paradigm, particularly in CAD algorithm development. Typically CAD researchers report “sensitivity was observed to be xx at yy false positives per image.” Occasionally, using less ambiguous terminology, they report an observed operating point on the FROC, as in “LLF was observed to be xx at NLF = yy.” The lessons learned from ROC analysis, see Section 3.12, that a scalar FOM is preferable to sensitivity-specificity pairs, has apparently been forgotten. This chapter recommends adoption of the wAFROC as the preferred operating characteristic in assessing performance in the free-response paradigm, and details simulation-based studies supporting this recommendation. 19.2 FROC vs. wAFROC source(here(&quot;R/CH13-GenerateCadVsRadPlots/GenerateCadVsRadPlots.R&quot;)) nu &lt;- 1 lambda &lt;- 1 K1 &lt;- 500 K2 &lt;- 700 muCad &lt;- 1.0 muRad &lt;- 1.5 zeta1Cad &lt;- -1 zeta1Rad &lt;- 1.5 Lmax &lt;- 2 seed &lt;- 1 set.seed(seed) Lk2 &lt;- floor(runif(K2, 1, Lmax + 1)) ret &lt;- GenerateCadVsRadPlots (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed) froc1A &lt;- ret$froc$Plot + labs(tag = &quot;A&quot;) wafroc1B &lt;- ret$wafroc$Plot + labs(tag = &quot;B&quot;) fomCad1B &lt;- ret$fomCad fomRad1B &lt;- ret$fomRad zeta1Cad &lt;- -Inf zeta1Rad &lt;- -Inf ret &lt;- GenerateCadVsRadPlots (muCad, muRad, zeta1Cad, zeta1Rad, K1, K2, Lk2, seed) froc1C &lt;- ret$froc$Plot + labs(tag = &quot;C&quot;) wafroc1D &lt;- ret$wafroc$Plot + labs(tag = &quot;D&quot;) fomCad1D &lt;- ret$fomCad fomRad1D &lt;- ret$fomRad This section examines RSM-predicted FROC and wAFROC plots for a simulated CAD (algorithmic) and RAD (radiologist) observers. Recall, from Section 16.11, that the RSM is defined by 3 parameters \\(\\mu, \\lambda, \\nu\\) and the lowest reporting threshold parameter \\(\\zeta_1\\) which determines if latent localizations are actually marked. Both CAD and RAD observers share the same \\(\\lambda, \\nu\\). These are defined at lines 3 and 4 of the preceding code: \\(\\lambda = \\nu = 1\\). The number of simulated cases is defined, lines 5-6, by \\(K_1 = 500\\) and \\(K_2 = 700\\). The simulated CAD observer is defined at line 7 by by \\(\\mu_{CAD} = 1\\) and the simulated RAD observer is defined at line 8 by \\(\\mu_{RAD} = 1.5\\). The corresponding threshold parameters are (lines 9 -10) \\(\\zeta_{1} = -1\\) for CAD and \\(\\zeta_{1} = 1.5\\) for RAD. The maximum number of lesions per case is defined at line 11 by Lmax = 2. The actual number of lesions per case Lk2 is determined at line 14 (Lk2 is a \\(K_2\\) length array consisting of random integers 1 or 2). Line 16 calls the helper function GenerateCadVsRadPlots() (the file containing this function is sourced at line 1), which calculates the FROC and wAFROC plots and other statistics. The FROC is extracted at line 18 and labeled A, while the wAFROC is extracted at line 19 and labeled B. The following code extracts the coordinates of the end-points of the respective curves. # extract coordinates of end-point nlfCad1A &lt;- max(froc1A$data$genAbscissa[froc1A$data$Reader == &quot;R: CAD&quot;]) llfCad1A &lt;- max(froc1A$data$genOrdinate[froc1A$data$Reader == &quot;R: CAD&quot;]) nlfRad1A &lt;- max(froc1A$data$genAbscissa[froc1A$data$Reader == &quot;R: RAD&quot;]) llfRad1A &lt;- max(froc1A$data$genOrdinate[froc1A$data$Reader == &quot;R: RAD&quot;]) nlfCad1C &lt;- max(froc1C$data$genAbscissa[froc1C$data$Reader == &quot;R: CAD&quot;]) llfCad1C &lt;- max(froc1C$data$genOrdinate[froc1C$data$Reader == &quot;R: CAD&quot;]) nlfRad1C &lt;- max(froc1C$data$genAbscissa[froc1C$data$Reader == &quot;R: RAD&quot;]) llfRad1C &lt;- max(froc1C$data$genOrdinate[froc1C$data$Reader == &quot;R: RAD&quot;]) FIGURE 19.1: Plots A and B are for CAD \\(\\zeta_1 = -1\\) and RAD \\(\\zeta_1 = 1.5\\) and plots C and D are plots for CAD \\(\\zeta_1 = -\\infty\\) and RAD \\(\\zeta_1 = -\\infty\\). Plots A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves. The coordinates of the end-point of the CAD FROC in plot A are (0.8258333, 0.5903846). Those of the RAD FROC plot in A are (0.0491667, 0.3980769). The FROC for the CAD observer extends to much larger NLF values while that for the RAD observer is relatively short and steeper, as in Fig. 19.1, plot A. One suspects the RAD observer is performing better than CAD. He is better at finding lesions and producing fewer NLs, both of which are desirable characteristics. One suspects that if he could be induced to relax the threshold and report more NLs, his LLF would exceed that of the CAD observer while still maintaining a lower \\(\\text{NLF}_{\\text{max}}\\). However, lacking the ability to induce the radiologist to relax his threshold, it is not possible to quantify this suspicion from the observed FROC curves.1 CAD algorithm developers typically quote LLF at a specified NLF. According to the two plots in A, the RAD observer is better if the NLF value is chosen to less than 0.0491667 (this is the maximum NLF value for the RAD plot in A) while there is no basis for comparison for larger values of NLF (because the RAD observer does not provide any data beyond the observed end-point). A similar problem was encountered in ROC analysis when comparing a pair of sensitivity-specificity values, where, given differing choices of thresholds, ambiguous results can be obtained, see Section 3.12. Indeed, this was the rationale for using AUC under the ROC curve as an unambiguous measure of performance. wAFROC curves, for the same datasets, whose FROC curves are shown in plot A, are shown in plot B. Like the ROC, the wAFROC is contained within the unit square, a highly desirable characteristic, which solves the lack of a common NLF range problem with the FROC. The wAFROC AUC under the RAD observer is visibly greater than that for the CAD observer, even though – due to his higher threshold – his AUC estimate is actually biased downward against him.2 AUCs under the two wAFROC plots in B are 0.5730971 for CAD and 0.67371 for RAD, consistent with the visual impression of RAD &gt; CAD. Since plots A and B are based on different choices of lowest reporting threshold, it is pertinent to ask what happens for identical thresholds. Lines 23-24 set the two threshold parameters to \\(-\\infty\\) and line 25 calls the function GenerateCadVsRadPlots() with these new values. The FROC is extracted at line 28 and labeled C, while the wAFROC is extracted at line 29 and labeled D. The coordinates of the end-point of the CAD FROC in plot C are (1.0025, 0.6048077). Those of the RAD FROC plot in C are (0.6391667, 0.775). The RAD observer has higher LLF at lower NLF, and there is no doubt that he is better. Plot C confirms that RAD is actually the better observer over the entire NLF range. Plot D shows the corresponding wAFROC curves. The AUCs are 0.5604857 for CAD and 0.7779929 for RAD, confirming that the RAD observer is indeed better. Moreover, this comparison, based on comparing two scalars, is unambiguous.3 19.3 Two other examples are given. In Fig. 19.2 (A), which exaggerates the difference between CAD and RAD, the CAD parameters are the same as in Fig. 19.1, but the RAD parameters are \\(\\mu = 2\\) and \\(\\zeta_1 = +2\\). Doubling the separation parameter over that of CAD has a huge effect on performance. The end-point coordinates of the FROC for RAD are (0.015, 0.4211538). This time AUC under the common region defined by NLF = 0 to NLF = 0.015 would exclude almost all of the NL and LL marks made by CAD. The wAFROCs in plot B show the markedly greater performance of RAD compared to CAD (the AUCs are 0.5730971 for CAD and 0.7075193 for RAD). The difference is larger, in spite of the downward bias working against the wAFROC RAD AUC, Fig. 19.1 (D). FIGURE 19.2: Plots A and B are for CAD \\(\\zeta_1 = -1\\) and RAD \\(\\zeta_1 = 2\\) and plots C and D are plots for CAD \\(\\zeta_1 = -\\infty\\) and RAD \\(\\zeta_1 = -\\infty\\). A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves. Fig. 19.2 (A) FROC curves for CAD observer and the RAD observer. The CAD observer is identical to that shown in Fig. 19.1. The RAD observer is characterized by \\(\\mu = 2\\) and \\(\\zeta_1 = 2\\). This time it is impossible to compare the two FROC curves, as the common range is very small. However, wAFROC, plot B, clearly shows the expected superiority of the RAD observer, in spite of the severe underestimate of the corresponding AUC. AUCs under the two wAFROC plots are 0.608 for CAD and 0.708 for RAD. Plots C and D correspond to A and B, respectively, with \\(\\zeta_1\\) = \\(-\\infty\\) for both readers. AUCs under the two wAFROC plots are 0.5730971 for CAD and 0.7075193 for RAD. 19.3.1 An example where the FROC can be used for comparisons The final example, Fig. 19.3 shows that when there is a small difference in performance, there is less ambiguity in using the FROC as a basis for measuring performance. The CAD parameters are the same as in Fig. 19.1 but the RAD parameters are \\(\\mu = 1.1\\) and \\(\\zeta_1= -1\\). This time there is much more common overlap in plot (A) and the area measure is counting most of the marks for both readers (but still not accounting for unmarked non-diseased cases). The superior wAFROC-based performance of RAD is also apparent in (B). FIGURE 19.3: Plots A and B are for CAD \\(\\zeta_1 = -1\\) and RAD \\(\\zeta_1 = -1\\) and plots C and D are plots for CAD \\(\\zeta_1 = -\\infty\\) and RAD \\(\\zeta_1 = -\\infty\\). A and C: FROC curves for the CAD and RAD observers. B and D: corresponding wAFROC curves. TABLE 19.1: TBA Representative counts table. CAD-FROC RAD-FROC CAD-FROC1 RAD-FROC1 CAD-wAFROC RAD-wAFROC CAD-wAFROC1 RAD-wAFROC1 (0.826, 0.59) (0.0492, 0.398) (1, 0.605) (0.639, 0.775) 0.573 0.674 0.56 0.778 (0.826, 0.59) (0.015, 0.421) (1, 0.605) (0.5, 0.865) 0.573 0.708 0.56 0.872 (0.826, 0.59) (0.746, 0.664) (1, 0.605) (0.901, 0.678) 0.573 0.708 0.56 0.872 A misconception exists that using the rating of only one NL mark, as in wAFROC, must sacrifice statistical power. In fact, the chosen mark is a special one, namely the highest rated NL mark on a non-diseased case, which carries more information than a randomly chosen NL mark. If the sampling distribution of the z-sample were uniform, then the highest sample is a sufficient statistic, meaning that it carries all the information in the samples. The highest rated z-sampler from a normal distribution is not a sufficient statistic, so there is some loss of information, but not as much as would occur with a randomly picked z-sample. Fig. 19.3: (A, B) FROC/wAFROC curves for CAD and RAD observers. The CAD observer is identical to that shown in Fig. 19.2 (A, B). The RAD observer is characterized by mu = 1.1 and \\(\\zeta_1\\) = -1. This time it is possible to compare the two FROC curves, as the common NLF range is large. Both FROC and wAFROC show the expected slight superiority of the RAD observer. AUCs under the two wAFROC plots are 0.608 for CAD and 0.634 for RAD. Plots C and D correspond to A and B, respectively, with \\(\\zeta_1\\) = \\(-\\infty\\) for both observers. Since \\(\\zeta_1\\) in A and B is already quite small, lowering it to \\(-\\infty\\) does not pick up too many marks. AUCs under the two wAFROC plots in D are 0.601 for CAD and 0.624 for RAD. 13.16.4: Other issues with the FROC Loss of statistical power is not the only issue with the FROC. Because it counts NLs on both diseased and non-diseased cases, the curve depends on disease-prevalence in the dataset. Because the numbers of LLs per case is variable, the curve gives undue importance to those diseased cases with unusually large numbers of lesions. As noted in 13.16.2, the clinical importance of a NL on a non-diseased case differs from that on a diseased case. The FROC curve ignores this distinction. 19.4 Discussion 19.5 References The basic issue is the lack of a common NLF range for the two plots. If a common NLF range is “forced,” for example defined as the common NLF range 0 to 0.0491667 where both curves contribute, it would ignore most NLs from the CAD observer.↩︎ Because the RAD observer is adopting a high threshold \\(\\zeta_1 = 1.5\\), his \\(\\text{LLF}_{\\text{max}}\\) is smaller than it would have been with a lower threshold, and consequently the area under the large straight line segment from the uppermost non-trivial operating point to (1,1) is smaller than would have been the case with a lower threshold.↩︎ The differences from the previous values (corresponding to plot B) namely 0.5730971 for CAD and 0.67371 for RAD, is much larger – and visually striking – for the RAD observer than for the CAD observer. This is because the CAD observer was already adopting a low threshold \\(\\zeta_1 = -1\\) in plot B, so lowering it to \\(-\\infty\\) in plot D has a smaller effect.↩︎ "]]
