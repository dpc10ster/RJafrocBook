<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 Ratings Paradigm | Standalone CAD vs. Radiologists {#standalone-cad-radiologists} cases</title>
  <meta name="description" content="Updated observer-performance book based on RJafroc." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 Ratings Paradigm | Standalone CAD vs. Radiologists {#standalone-cad-radiologists} cases" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Updated observer-performance book based on RJafroc." />
  <meta name="github-repo" content="dpc10ster/RJafrocBook" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 Ratings Paradigm | Standalone CAD vs. Radiologists {#standalone-cad-radiologists} cases" />
  
  <meta name="twitter:description" content="Updated observer-performance book based on RJafroc." />
  

<meta name="author" content="DPC" />


<meta name="date" content="2020-11-21" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="binary-task.html"/>
<link rel="next" href="empirical-auc.html"/>
<script src="libs/header-attrs-2.5/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">RJafroc documentation</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#a-note-on-the-online-distribution-mechanism-of-the-book"><i class="fa fa-check"></i>A note on the online distribution mechanism of the book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#contributing-to-this-book"><i class="fa fa-check"></i>Contributing to this book</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#is-this-book-relevant-to-you-and-what-are-the-alternatives"><i class="fa fa-check"></i>Is this book relevant to you and what are the alternatives?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#todos"><i class="fa fa-check"></i>ToDos</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#chapters-needing-heavy-edits"><i class="fa fa-check"></i>Chapters needing heavy edits</a></li>
</ul></li>
<li class="part"><span><b>ROC paradigm</b></span></li>
<li class="chapter" data-level="1" data-path="preliminaries.html"><a href="preliminaries.html"><i class="fa fa-check"></i><b>1</b> Preliminaries</a>
<ul>
<li class="chapter" data-level="1.1" data-path="preliminaries.html"><a href="preliminaries.html#preliminariesIntro"><i class="fa fa-check"></i><b>1.1</b> Introduction</a></li>
<li class="chapter" data-level="1.2" data-path="preliminaries.html"><a href="preliminaries.html#clinical-tasks"><i class="fa fa-check"></i><b>1.2</b> Clinical tasks</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="preliminaries.html"><a href="preliminaries.html#workflow-in-an-imaging-study"><i class="fa fa-check"></i><b>1.2.1</b> Workflow in an imaging study</a></li>
<li class="chapter" data-level="1.2.2" data-path="preliminaries.html"><a href="preliminaries.html#the-screening-and-diagnostic-workup-tasks"><i class="fa fa-check"></i><b>1.2.2</b> The screening and diagnostic workup tasks</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="preliminaries.html"><a href="preliminaries.html#imaging-device-development-and-its-clinical-deployment"><i class="fa fa-check"></i><b>1.3</b> Imaging device development and its clinical deployment</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="preliminaries.html"><a href="preliminaries.html#physical-measurements"><i class="fa fa-check"></i><b>1.3.1</b> Physical measurements</a></li>
<li class="chapter" data-level="1.3.2" data-path="preliminaries.html"><a href="preliminaries.html#quality-control-and-image-quality-optimization"><i class="fa fa-check"></i><b>1.3.2</b> Quality Control and Image quality optimization</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="preliminaries.html"><a href="preliminaries.html#image-quality-vs.-task-performance"><i class="fa fa-check"></i><b>1.4</b> Image quality vs. task performance</a></li>
<li class="chapter" data-level="1.5" data-path="preliminaries.html"><a href="preliminaries.html#why-physical-measures-of-image-quality-are-not-enough"><i class="fa fa-check"></i><b>1.5</b> Why physical measures of image quality are not enough</a></li>
<li class="chapter" data-level="1.6" data-path="preliminaries.html"><a href="preliminaries.html#model-observers"><i class="fa fa-check"></i><b>1.6</b> Model observers</a></li>
<li class="chapter" data-level="1.7" data-path="preliminaries.html"><a href="preliminaries.html#measuring-observer-performance-four-paradigms"><i class="fa fa-check"></i><b>1.7</b> Measuring observer performance: four paradigms</a>
<ul>
<li class="chapter" data-level="1.7.1" data-path="preliminaries.html"><a href="preliminaries.html#basic-approach-to-the-analysis"><i class="fa fa-check"></i><b>1.7.1</b> Basic approach to the analysis</a></li>
<li class="chapter" data-level="1.7.2" data-path="preliminaries.html"><a href="preliminaries.html#historical-notes"><i class="fa fa-check"></i><b>1.7.2</b> Historical notes</a></li>
</ul></li>
<li class="chapter" data-level="1.8" data-path="preliminaries.html"><a href="preliminaries.html#hierarchy-of-assessment-methods"><i class="fa fa-check"></i><b>1.8</b> Hierarchy of assessment methods</a></li>
<li class="chapter" data-level="1.9" data-path="preliminaries.html"><a href="preliminaries.html#overview-of-the-book-and-how-to-use-it"><i class="fa fa-check"></i><b>1.9</b> Overview of the book and how to use it</a>
<ul>
<li class="chapter" data-level="1.9.1" data-path="preliminaries.html"><a href="preliminaries.html#overview-of-the-book"><i class="fa fa-check"></i><b>1.9.1</b> Overview of the book</a></li>
<li class="chapter" data-level="1.9.2" data-path="preliminaries.html"><a href="preliminaries.html#how-to-use-the-book"><i class="fa fa-check"></i><b>1.9.2</b> How to use the book</a></li>
</ul></li>
<li class="chapter" data-level="1.10" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-Summary"><i class="fa fa-check"></i><b>1.10</b> Summary</a></li>
<li class="chapter" data-level="1.11" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-Discussion"><i class="fa fa-check"></i><b>1.11</b> Discussion</a></li>
<li class="chapter" data-level="1.12" data-path="preliminaries.html"><a href="preliminaries.html#preliminaries-references"><i class="fa fa-check"></i><b>1.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="binary-task0.html"><a href="binary-task0.html"><i class="fa fa-check"></i><b>2</b> The Binary Task</a>
<ul>
<li class="chapter" data-level="2.1" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0Intro"><i class="fa fa-check"></i><b>2.1</b> Introduction</a></li>
<li class="chapter" data-level="2.2" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0Truth"><i class="fa fa-check"></i><b>2.2</b> The fundamental 2x2 table</a></li>
<li class="chapter" data-level="2.3" data-path="binary-task0.html"><a href="binary-task0.html#sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3</b> Sensitivity and specificity</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="binary-task0.html"><a href="binary-task0.html#reasons-for-the-names-sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3.1</b> Reasons for the names sensitivity and specificity</a></li>
<li class="chapter" data-level="2.3.2" data-path="binary-task0.html"><a href="binary-task0.html#estimating-sensitivity-and-specificity"><i class="fa fa-check"></i><b>2.3.2</b> Estimating sensitivity and specificity</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="binary-task0.html"><a href="binary-task0.html#disease-prevalence"><i class="fa fa-check"></i><b>2.4</b> Disease prevalence</a></li>
<li class="chapter" data-level="2.5" data-path="binary-task0.html"><a href="binary-task0.html#accuracy"><i class="fa fa-check"></i><b>2.5</b> Accuracy</a></li>
<li class="chapter" data-level="2.6" data-path="binary-task0.html"><a href="binary-task0.html#negative-and-positive-predictive-values"><i class="fa fa-check"></i><b>2.6</b> Negative and positive predictive values</a>
<ul>
<li class="chapter" data-level="2.6.1" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0NpvPpvCode"><i class="fa fa-check"></i><b>2.6.1</b> Example calculation of PPV, NPV and accuracy</a></li>
<li class="chapter" data-level="2.6.2" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0NpvPpvComments"><i class="fa fa-check"></i><b>2.6.2</b> Comments</a></li>
<li class="chapter" data-level="2.6.3" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0NpvPpvIrrel2LabTasks"><i class="fa fa-check"></i><b>2.6.3</b> PPV and NPV are irrelevant to laboratory tasks</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0-Summary"><i class="fa fa-check"></i><b>2.7</b> Summary</a></li>
<li class="chapter" data-level="2.8" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0-Discussion"><i class="fa fa-check"></i><b>2.8</b> Discussion</a></li>
<li class="chapter" data-level="2.9" data-path="binary-task0.html"><a href="binary-task0.html#binary-task0-references"><i class="fa fa-check"></i><b>2.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="binary-task.html"><a href="binary-task.html"><i class="fa fa-check"></i><b>3</b> Modeling the Binary Task</a>
<ul>
<li class="chapter" data-level="3.1" data-path="binary-task.html"><a href="binary-task.html#binary-task-intro"><i class="fa fa-check"></i><b>3.1</b> Introduction</a></li>
<li class="chapter" data-level="3.2" data-path="binary-task.html"><a href="binary-task.html#binary-task-z-sample-model"><i class="fa fa-check"></i><b>3.2</b> Decision variable and decision threshold</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="binary-task.html"><a href="binary-task.html#existence-of-a-decision-variable"><i class="fa fa-check"></i><b>3.2.1</b> Existence of a decision variable</a></li>
<li class="chapter" data-level="3.2.2" data-path="binary-task.html"><a href="binary-task.html#existence-of-a-decision-threshold"><i class="fa fa-check"></i><b>3.2.2</b> Existence of a decision threshold</a></li>
<li class="chapter" data-level="3.2.3" data-path="binary-task.html"><a href="binary-task.html#adequacy-of-the-training-session"><i class="fa fa-check"></i><b>3.2.3</b> Adequacy of the training session</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="binary-task.html"><a href="binary-task.html#changing-the-decision-threshold-example-i"><i class="fa fa-check"></i><b>3.3</b> Changing the decision threshold: Example I</a></li>
<li class="chapter" data-level="3.4" data-path="binary-task.html"><a href="binary-task.html#changing-the-decision-threshold-example-ii"><i class="fa fa-check"></i><b>3.4</b> Changing the decision threshold: Example II</a></li>
<li class="chapter" data-level="3.5" data-path="binary-task.html"><a href="binary-task.html#binary-task-equal-variance-binormal-model"><i class="fa fa-check"></i><b>3.5</b> The equal-variance binormal model</a></li>
<li class="chapter" data-level="3.6" data-path="binary-task.html"><a href="binary-task.html#binary-task-normal-distribution"><i class="fa fa-check"></i><b>3.6</b> The normal distribution</a></li>
<li class="chapter" data-level="3.7" data-path="binary-task.html"><a href="binary-task.html#binary-task-sensitivity-specificity"><i class="fa fa-check"></i><b>3.7</b> Analytic expressions for specificity and sensitivity</a></li>
<li class="chapter" data-level="3.8" data-path="binary-task.html"><a href="binary-task.html#binary-task-sensitivity-specificity-demo"><i class="fa fa-check"></i><b>3.8</b> Demonstration of the concepts of sensitivity and specificity</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="binary-task.html"><a href="binary-task.html#estimating-mu-from-a-finite-sample"><i class="fa fa-check"></i><b>3.8.1</b> Estimating mu from a finite sample</a></li>
<li class="chapter" data-level="3.8.2" data-path="binary-task.html"><a href="binary-task.html#changing-the-seed-variable-case-sampling-variability"><i class="fa fa-check"></i><b>3.8.2</b> Changing the seed variable: case-sampling variability</a></li>
<li class="chapter" data-level="3.8.3" data-path="binary-task.html"><a href="binary-task.html#increasing-the-numbers-of-cases"><i class="fa fa-check"></i><b>3.8.3</b> Increasing the numbers of cases</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="binary-task.html"><a href="binary-task.html#binary-task-sensitivity-specificity-inverse-variation"><i class="fa fa-check"></i><b>3.9</b> Inverse variation of sensitivity and specificity and the need for a single FOM</a></li>
<li class="chapter" data-level="3.10" data-path="binary-task.html"><a href="binary-task.html#binary-task-roc-curve"><i class="fa fa-check"></i><b>3.10</b> The ROC curve</a>
<ul>
<li class="chapter" data-level="3.10.1" data-path="binary-task.html"><a href="binary-task.html#the-chance-diagonal"><i class="fa fa-check"></i><b>3.10.1</b> The chance diagonal</a></li>
<li class="chapter" data-level="3.10.2" data-path="binary-task.html"><a href="binary-task.html#the-guessing-observer"><i class="fa fa-check"></i><b>3.10.2</b> The guessing observer</a></li>
<li class="chapter" data-level="3.10.3" data-path="binary-task.html"><a href="binary-task.html#symmetry-with-respect-to-negative-diagonal"><i class="fa fa-check"></i><b>3.10.3</b> Symmetry with respect to negative diagonal</a></li>
<li class="chapter" data-level="3.10.4" data-path="binary-task.html"><a href="binary-task.html#area-under-the-roc-curve"><i class="fa fa-check"></i><b>3.10.4</b> Area under the ROC curve</a></li>
<li class="chapter" data-level="3.10.5" data-path="binary-task.html"><a href="binary-task.html#properties-of-the-equal-variance-binormal-model-roc-curve"><i class="fa fa-check"></i><b>3.10.5</b> Properties of the equal-variance binormal model ROC curve</a></li>
<li class="chapter" data-level="3.10.6" data-path="binary-task.html"><a href="binary-task.html#comments"><i class="fa fa-check"></i><b>3.10.6</b> Comments</a></li>
<li class="chapter" data-level="3.10.7" data-path="binary-task.html"><a href="binary-task.html#physical-interpretation-of-the-mu-parameter"><i class="fa fa-check"></i><b>3.10.7</b> Physical interpretation of the mu-parameter</a></li>
</ul></li>
<li class="chapter" data-level="3.11" data-path="binary-task.html"><a href="binary-task.html#binary-task-confidence-intervals"><i class="fa fa-check"></i><b>3.11</b> Assigning confidence intervals to an operating point</a></li>
<li class="chapter" data-level="3.12" data-path="binary-task.html"><a href="binary-task.html#binary-task-beam-study"><i class="fa fa-check"></i><b>3.12</b> Variability in sensitivity and specificity: the Beam et al study</a></li>
<li class="chapter" data-level="3.13" data-path="binary-task.html"><a href="binary-task.html#binary-task-summary"><i class="fa fa-check"></i><b>3.13</b> Summary</a></li>
<li class="chapter" data-level="3.14" data-path="binary-task.html"><a href="binary-task.html#binary-task-references"><i class="fa fa-check"></i><b>3.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html"><i class="fa fa-check"></i><b>4</b> Ratings Paradigm</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#introduction"><i class="fa fa-check"></i><b>4.1</b> Introduction</a></li>
<li class="chapter" data-level="4.2" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-roc-counts-table"><i class="fa fa-check"></i><b>4.2</b> The ROC counts table</a></li>
<li class="chapter" data-level="4.3" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#operating-points-from-counts-table"><i class="fa fa-check"></i><b>4.3</b> Operating points from counts table</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#labeling-the-points"><i class="fa fa-check"></i><b>4.3.1</b> Labeling the points</a></li>
<li class="chapter" data-level="4.3.2" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#examples"><i class="fa fa-check"></i><b>4.3.2</b> Examples</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#automating-all-this"><i class="fa fa-check"></i><b>4.4</b> Automating all this</a></li>
<li class="chapter" data-level="4.5" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#relation-between-ratings-paradigm-and-the-binary-paradigm"><i class="fa fa-check"></i><b>4.5</b> Relation between ratings paradigm and the binary paradigm</a></li>
<li class="chapter" data-level="4.6" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratings-are-not-numerical-values"><i class="fa fa-check"></i><b>4.6</b> Ratings are not numerical values</a></li>
<li class="chapter" data-level="4.7" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#a-single-clinical-operating-point-from-ratings-data"><i class="fa fa-check"></i><b>4.7</b> A single “clinical” operating point from ratings data</a></li>
<li class="chapter" data-level="4.8" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-forced-choice-paradigm"><i class="fa fa-check"></i><b>4.8</b> The forced choice paradigm</a></li>
<li class="chapter" data-level="4.9" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#observer-performance-studies-as-laboratory-simulations-of-clinical-tasks"><i class="fa fa-check"></i><b>4.9</b> Observer performance studies as laboratory simulations of clinical tasks</a></li>
<li class="chapter" data-level="4.10" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#discrete-vs.-continuous-ratings-the-miller-study"><i class="fa fa-check"></i><b>4.10</b> Discrete vs. continuous ratings: the Miller study</a></li>
<li class="chapter" data-level="4.11" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-bi-rads-ratings-scale-and-roc-studies"><i class="fa fa-check"></i><b>4.11</b> The BI-RADS ratings scale and ROC studies</a></li>
<li class="chapter" data-level="4.12" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#the-controversy"><i class="fa fa-check"></i><b>4.12</b> The controversy</a></li>
<li class="chapter" data-level="4.13" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratingsParadigm-discussion"><i class="fa fa-check"></i><b>4.13</b> Discussion</a></li>
<li class="chapter" data-level="4.14" data-path="ratingsParadigm.html"><a href="ratingsParadigm.html#ratingsParadigm-references"><i class="fa fa-check"></i><b>4.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="empirical-auc.html"><a href="empirical-auc.html"><i class="fa fa-check"></i><b>5</b> Empirical AUC</a>
<ul>
<li class="chapter" data-level="5.1" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-intro"><i class="fa fa-check"></i><b>5.1</b> Introduction</a></li>
<li class="chapter" data-level="5.2" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-roc-plot"><i class="fa fa-check"></i><b>5.2</b> The empirical ROC plot</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="empirical-auc.html"><a href="empirical-auc.html#notation-for-cases"><i class="fa fa-check"></i><b>5.2.1</b> Notation for cases</a></li>
<li class="chapter" data-level="5.2.2" data-path="empirical-auc.html"><a href="empirical-auc.html#an-empirical-operating-point"><i class="fa fa-check"></i><b>5.2.2</b> An empirical operating point</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-operating-points"><i class="fa fa-check"></i><b>5.3</b> Empirical operating points from ratings data</a></li>
<li class="chapter" data-level="5.4" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-area-under"><i class="fa fa-check"></i><b>5.4</b> AUC under the empirical ROC plot</a></li>
<li class="chapter" data-level="5.5" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-wilcoxon"><i class="fa fa-check"></i><b>5.5</b> The Wilcoxon statistic</a></li>
<li class="chapter" data-level="5.6" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-wilcoxon-bamber-theorem"><i class="fa fa-check"></i><b>5.6</b> Bamber’s Equivalence theorem</a></li>
<li class="chapter" data-level="5.7" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-wilcoxon-bamber-theorem-importance"><i class="fa fa-check"></i><b>5.7</b> Importance of Bamber’s theorem</a></li>
<li class="chapter" data-level="5.8" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-discussion-summary"><i class="fa fa-check"></i><b>5.8</b> Discussion / Summary</a></li>
<li class="chapter" data-level="5.9" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-appendix-details-bamber-theorem"><i class="fa fa-check"></i><b>5.9</b> Appendix 5.A: Details of Wilcoxon theorem</a>
<ul>
<li class="chapter" data-level="5.9.1" data-path="empirical-auc.html"><a href="empirical-auc.html#upper-triangle"><i class="fa fa-check"></i><b>5.9.1</b> Upper triangle</a></li>
<li class="chapter" data-level="5.9.2" data-path="empirical-auc.html"><a href="empirical-auc.html#lowest-trapezoid"><i class="fa fa-check"></i><b>5.9.2</b> Lowest trapezoid</a></li>
</ul></li>
<li class="chapter" data-level="5.10" data-path="empirical-auc.html"><a href="empirical-auc.html#empirical-auc-references"><i class="fa fa-check"></i><b>5.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="BinormalModel.html"><a href="BinormalModel.html"><i class="fa fa-check"></i><b>6</b> Binormal model</a>
<ul>
<li class="chapter" data-level="6.1" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModelIntro"><i class="fa fa-check"></i><b>6.1</b> Introduction</a></li>
<li class="chapter" data-level="6.2" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModelTheModel"><i class="fa fa-check"></i><b>6.2</b> The binormal model</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="BinormalModel.html"><a href="BinormalModel.html#binning-the-data"><i class="fa fa-check"></i><b>6.2.1</b> Binning the data</a></li>
<li class="chapter" data-level="6.2.2" data-path="BinormalModel.html"><a href="BinormalModel.html#invariance-of-the-binormal-model-to-arbitrary-monotone-transformations"><i class="fa fa-check"></i><b>6.2.2</b> Invariance of the binormal model to arbitrary monotone transformations</a></li>
<li class="chapter" data-level="6.2.3" data-path="BinormalModel.html"><a href="BinormalModel.html#expressions-for-sensitivity-and-specificity"><i class="fa fa-check"></i><b>6.2.3</b> Expressions for sensitivity and specificity</a></li>
<li class="chapter" data-level="6.2.4" data-path="BinormalModel.html"><a href="BinormalModel.html#binormal-model-in-standard-notation"><i class="fa fa-check"></i><b>6.2.4</b> Binormal model in standard notation</a></li>
<li class="chapter" data-level="6.2.5" data-path="BinormalModel.html"><a href="BinormalModel.html#properties-of-the-binormal-model-roc-curve"><i class="fa fa-check"></i><b>6.2.5</b> Properties of the binormal model ROC curve</a></li>
<li class="chapter" data-level="6.2.6" data-path="BinormalModel.html"><a href="BinormalModel.html#density-functions-pdfs-of-the-binormal-model"><i class="fa fa-check"></i><b>6.2.6</b> Density functions (pdfs) of the binormal model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="BinormalModel.html"><a href="BinormalModel.html#fitting-an-roc-curve-to-data-points"><i class="fa fa-check"></i><b>6.3</b> Fitting an ROC curve to data points</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="BinormalModel.html"><a href="BinormalModel.html#a-java-fitted-roc-curve"><i class="fa fa-check"></i><b>6.3.1</b> A JAVA fitted ROC curve</a></li>
<li class="chapter" data-level="6.3.2" data-path="BinormalModel.html"><a href="BinormalModel.html#a-simplistic-straight-line-fit-to-the-roc-curve"><i class="fa fa-check"></i><b>6.3.2</b> A simplistic straight line fit to the ROC curve</a></li>
<li class="chapter" data-level="6.3.3" data-path="BinormalModel.html"><a href="BinormalModel.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>6.3.3</b> Maximum likelihood estimation (MLE)</a></li>
<li class="chapter" data-level="6.3.4" data-path="BinormalModel.html"><a href="BinormalModel.html#code-implementing-mle"><i class="fa fa-check"></i><b>6.3.4</b> Code implementing MLE</a></li>
<li class="chapter" data-level="6.3.5" data-path="BinormalModel.html"><a href="BinormalModel.html#validating-the-fitting-model"><i class="fa fa-check"></i><b>6.3.5</b> Validating the fitting model</a></li>
<li class="chapter" data-level="6.3.6" data-path="BinormalModel.html"><a href="BinormalModel.html#estimating-the-covariance-matrix"><i class="fa fa-check"></i><b>6.3.6</b> Estimating the covariance matrix</a></li>
<li class="chapter" data-level="6.3.7" data-path="BinormalModel.html"><a href="BinormalModel.html#estimating-the-variance-of-az"><i class="fa fa-check"></i><b>6.3.7</b> Estimating the variance of Az</a></li>
<li class="chapter" data-level="6.3.8" data-path="BinormalModel.html"><a href="BinormalModel.html#single-fom-derived-from-roc-curve"><i class="fa fa-check"></i><b>6.3.8</b> Single FOM derived from ROC curve</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModel-Discussion"><i class="fa fa-check"></i><b>6.4</b> Discussion</a></li>
<li class="chapter" data-level="6.5" data-path="BinormalModel.html"><a href="BinormalModel.html#BinormalModel-references"><i class="fa fa-check"></i><b>6.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="sourcesVariability.html"><a href="sourcesVariability.html"><i class="fa fa-check"></i><b>7</b> Sources of AUC variability</a>
<ul>
<li class="chapter" data-level="7.1" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariabilityIntro"><i class="fa fa-check"></i><b>7.1</b> Introduction</a></li>
<li class="chapter" data-level="7.2" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariability3sources"><i class="fa fa-check"></i><b>7.2</b> Three sources of variability</a></li>
<li class="chapter" data-level="7.3" data-path="sourcesVariability.html"><a href="sourcesVariability.html#dependence-of-auc-on-the-case-sample"><i class="fa fa-check"></i><b>7.3</b> Dependence of AUC on the case sample</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="sourcesVariability.html"><a href="sourcesVariability.html#case-sampling-variability-of-auc"><i class="fa fa-check"></i><b>7.3.1</b> Case sampling variability of AUC</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariabilityDeLong"><i class="fa fa-check"></i><b>7.4</b> DeLong method</a></li>
<li class="chapter" data-level="7.5" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariabilityBootstrap"><i class="fa fa-check"></i><b>7.5</b> Bootstrap method</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="sourcesVariability.html"><a href="sourcesVariability.html#demonstration-of-the-bootstrap-method"><i class="fa fa-check"></i><b>7.5.1</b> Demonstration of the bootstrap method</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariabilityJackknife"><i class="fa fa-check"></i><b>7.6</b> Jackknife method</a></li>
<li class="chapter" data-level="7.7" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariabilityCalSimulator"><i class="fa fa-check"></i><b>7.7</b> Calibrated simulator</a>
<ul>
<li class="chapter" data-level="7.7.1" data-path="sourcesVariability.html"><a href="sourcesVariability.html#the-need-for-a-calibrated-simulator"><i class="fa fa-check"></i><b>7.7.1</b> The need for a calibrated simulator</a></li>
<li class="chapter" data-level="7.7.2" data-path="sourcesVariability.html"><a href="sourcesVariability.html#implementation-of-a-simple-calibrated-simulator"><i class="fa fa-check"></i><b>7.7.2</b> Implementation of a simple calibrated simulator</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariability-Discussion"><i class="fa fa-check"></i><b>7.8</b> Discussion</a></li>
<li class="chapter" data-level="7.9" data-path="sourcesVariability.html"><a href="sourcesVariability.html#sourcesVariability-references"><i class="fa fa-check"></i><b>7.9</b> References</a></li>
</ul></li>
<li class="part"><span><b>Significance Testing</b></span></li>
<li class="chapter" data-level="8" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html"><i class="fa fa-check"></i><b>8</b> Hypothesis Testing</a>
<ul>
<li class="chapter" data-level="8.1" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTesting-introduction"><i class="fa fa-check"></i><b>8.1</b> Introduction</a></li>
<li class="chapter" data-level="8.2" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#single-modality-single-reader-roc-study"><i class="fa fa-check"></i><b>8.2</b> Single-modality single-reader ROC study</a></li>
<li class="chapter" data-level="8.3" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#type-i-errors"><i class="fa fa-check"></i><b>8.3</b> Type-I errors</a></li>
<li class="chapter" data-level="8.4" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#one-vs.-two-sided-tests"><i class="fa fa-check"></i><b>8.4</b> One vs. two sided tests</a></li>
<li class="chapter" data-level="8.5" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#statistical-power"><i class="fa fa-check"></i><b>8.5</b> Statistical power</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#factors-affecting-statistical-power"><i class="fa fa-check"></i><b>8.5.1</b> Factors affecting statistical power</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTestingComments"><i class="fa fa-check"></i><b>8.6</b> Comments</a></li>
<li class="chapter" data-level="8.7" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#why-alpha-is-chosen-as-5"><i class="fa fa-check"></i><b>8.7</b> Why alpha is chosen as 5%</a></li>
<li class="chapter" data-level="8.8" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTestingDiscussion"><i class="fa fa-check"></i><b>8.8</b> Discussion</a></li>
<li class="chapter" data-level="8.9" data-path="HypothesisTesting.html"><a href="HypothesisTesting.html#HypothesisTesting-references"><i class="fa fa-check"></i><b>8.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html"><i class="fa fa-check"></i><b>9</b> DBM method background</a>
<ul>
<li class="chapter" data-level="9.1" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-introduction"><i class="fa fa-check"></i><b>9.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#historical-background"><i class="fa fa-check"></i><b>9.1.1</b> Historical background</a></li>
<li class="chapter" data-level="9.1.2" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#the-wagner-analogy"><i class="fa fa-check"></i><b>9.1.2</b> The Wagner analogy</a></li>
<li class="chapter" data-level="9.1.3" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#the-shortage-of-numbers-to-analyze-and-a-pivotal-breakthrough"><i class="fa fa-check"></i><b>9.1.3</b> The shortage of numbers to analyze and a pivotal breakthrough</a></li>
<li class="chapter" data-level="9.1.4" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#organization-of-chapter"><i class="fa fa-check"></i><b>9.1.4</b> Organization of chapter</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-random-fixed-factors"><i class="fa fa-check"></i><b>9.2</b> Random and fixed factors</a></li>
<li class="chapter" data-level="9.3" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-reader-case-populations"><i class="fa fa-check"></i><b>9.3</b> Reader and case populations</a></li>
<li class="chapter" data-level="9.4" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-threeAnalyses"><i class="fa fa-check"></i><b>9.4</b> Three types of analyses</a></li>
<li class="chapter" data-level="9.5" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-approach"><i class="fa fa-check"></i><b>9.5</b> General approach</a></li>
<li class="chapter" data-level="9.6" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-summary"><i class="fa fa-check"></i><b>9.6</b> Summary TBA</a></li>
<li class="chapter" data-level="9.7" data-path="DBMAnalysisBkgrnd.html"><a href="DBMAnalysisBkgrnd.html#DBMAnalysisBkgrnd-references"><i class="fa fa-check"></i><b>9.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html"><i class="fa fa-check"></i><b>10</b> Significance Testing using the DBM Method</a>
<ul>
<li class="chapter" data-level="10.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-dbm-sampling-model"><i class="fa fa-check"></i><b>10.1</b> The DBM sampling model</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#explanation-of-terms-in-the-model"><i class="fa fa-check"></i><b>10.1.1</b> Explanation of terms in the model</a></li>
<li class="chapter" data-level="10.1.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#meanings-of-variance-components-in-the-dbm-model-tba-this-section-can-be-improved"><i class="fa fa-check"></i><b>10.1.2</b> Meanings of variance components in the DBM model (<strong>TBA this section can be improved</strong>)</a></li>
<li class="chapter" data-level="10.1.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#definitions-of-mean-squares"><i class="fa fa-check"></i><b>10.1.3</b> Definitions of mean-squares</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#expected-values-of-mean-squares"><i class="fa fa-check"></i><b>10.2</b> Expected values of mean squares</a></li>
<li class="chapter" data-level="10.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-RRRC-analysis"><i class="fa fa-check"></i><b>10.3</b> Random-reader random-case (RRRC) analysis</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#calculation-of-mean-squares-an-example"><i class="fa fa-check"></i><b>10.3.1</b> Calculation of mean squares: an example</a></li>
<li class="chapter" data-level="10.3.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-sig-testing"><i class="fa fa-check"></i><b>10.3.2</b> Significance testing</a></li>
<li class="chapter" data-level="10.3.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-satterthwaite-approximation"><i class="fa fa-check"></i><b>10.3.3</b> The Satterthwaite approximation</a></li>
<li class="chapter" data-level="10.3.4" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#decision-rules-p-value-and-confidence-intervals"><i class="fa fa-check"></i><b>10.3.4</b> Decision rules, p-value and confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#sample-size-estimation-for-random-reader-random-case-generalization"><i class="fa fa-check"></i><b>10.4</b> Sample size estimation for random-reader random-case generalization</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-non-centrality-parameter"><i class="fa fa-check"></i><b>10.4.1</b> The non-centrality parameter</a></li>
<li class="chapter" data-level="10.4.2" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#the-denominator-degrees-of-freedom"><i class="fa fa-check"></i><b>10.4.2</b> The denominator degrees of freedom</a></li>
<li class="chapter" data-level="10.4.3" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#example-of-sample-size-estimation-rrrc-generalization"><i class="fa fa-check"></i><b>10.4.3</b> Example of sample size estimation, RRRC generalization</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#significance-testing-and-sample-size-estimation-for-fixed-reader-random-case-generalization"><i class="fa fa-check"></i><b>10.5</b> Significance testing and sample size estimation for fixed-reader random-case generalization</a></li>
<li class="chapter" data-level="10.6" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#significance-testing-and-sample-size-estimation-for-random-reader-fixed-case-generalization"><i class="fa fa-check"></i><b>10.6</b> Significance testing and sample size estimation for random-reader fixed-case generalization</a></li>
<li class="chapter" data-level="10.7" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-summary"><i class="fa fa-check"></i><b>10.7</b> Summary TBA</a></li>
<li class="chapter" data-level="10.8" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#things-for-me-to-think-about"><i class="fa fa-check"></i><b>10.8</b> Things for me to think about</a>
<ul>
<li class="chapter" data-level="10.8.1" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#expected-values-of-mean-squares-1"><i class="fa fa-check"></i><b>10.8.1</b> Expected values of mean squares</a></li>
</ul></li>
<li class="chapter" data-level="10.9" data-path="DBMAnalysisSigtesting.html"><a href="DBMAnalysisSigtesting.html#DBMAnalysisSigtesting-references"><i class="fa fa-check"></i><b>10.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html"><i class="fa fa-check"></i><b>11</b> DBM method special cases</a>
<ul>
<li class="chapter" data-level="11.1" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#FRRCDBMAnalysis"><i class="fa fa-check"></i><b>11.1</b> Fixed-reader random-case (FRRC) analysis</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#FRRCSingleReaderDBMAnalysis"><i class="fa fa-check"></i><b>11.1.1</b> Single-reader multiple-treatment analysis</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#DBMSpecialCases-RRFCAnalysis"><i class="fa fa-check"></i><b>11.2</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="11.3" data-path="DBMSpecialCases.html"><a href="DBMSpecialCases.html#DBMSpecialCases-references"><i class="fa fa-check"></i><b>11.3</b> References</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html"><i class="fa fa-check"></i><b>12</b> Introduction to the Obuchowski-Rockette method</a>
<ul>
<li class="chapter" data-level="12.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-introduction"><i class="fa fa-check"></i><b>12.1</b> Introduction</a></li>
<li class="chapter" data-level="12.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#OR1RMTModel"><i class="fa fa-check"></i><b>12.2</b> Single-reader multiple-treatment</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#definitions-of-covariance-and-correlation"><i class="fa fa-check"></i><b>12.2.1</b> Definitions of covariance and correlation</a></li>
<li class="chapter" data-level="12.2.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#special-case-when-variables-have-equal-variances"><i class="fa fa-check"></i><b>12.2.2</b> Special case when variables have equal variances</a></li>
<li class="chapter" data-level="12.2.3" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#estimating-the-variance-covariance-matrix"><i class="fa fa-check"></i><b>12.2.3</b> Estimating the variance-covariance matrix</a></li>
<li class="chapter" data-level="12.2.4" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#the-variance-inflation-factor"><i class="fa fa-check"></i><b>12.2.4</b> The variance inflation factor</a></li>
<li class="chapter" data-level="12.2.5" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#meaning-of-the-covariance-matrix-in-eqn.-refeqexamplesigma"><i class="fa fa-check"></i><b>12.2.5</b> Meaning of the covariance matrix in Eqn. @ref(eq:ExampleSigma)</a></li>
<li class="chapter" data-level="12.2.6" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#code-illustrating-the-covariance-matrix"><i class="fa fa-check"></i><b>12.2.6</b> Code illustrating the covariance matrix</a></li>
<li class="chapter" data-level="12.2.7" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#SignificanceTesting1ROR"><i class="fa fa-check"></i><b>12.2.7</b> Significance testing</a></li>
<li class="chapter" data-level="12.2.8" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-pvalue-ci"><i class="fa fa-check"></i><b>12.2.8</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="12.2.9" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-CompareDBM2OR41R"><i class="fa fa-check"></i><b>12.2.9</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#SignificanceTestingORMRMC"><i class="fa fa-check"></i><b>12.3</b> Multiple-reader multiple-treatment</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#StrCovMatrix"><i class="fa fa-check"></i><b>12.3.1</b> Structure of the covariance matrix</a></li>
<li class="chapter" data-level="12.3.2" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#PhysicalMeaningsOfCovMatrix"><i class="fa fa-check"></i><b>12.3.2</b> Physical meanings of the covariance terms</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-Summary"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
<li class="chapter" data-level="12.5" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-Discussion"><i class="fa fa-check"></i><b>12.5</b> Discussion</a></li>
<li class="chapter" data-level="12.6" data-path="ORMethodIntro.html"><a href="ORMethodIntro.html#ORMethodIntro-references"><i class="fa fa-check"></i><b>12.6</b> References</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html"><i class="fa fa-check"></i><b>13</b> Obuchowski Rockette (OR) Analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-introduction"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#OR_RRRC"><i class="fa fa-check"></i><b>13.2</b> Random-reader random-case</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#TwoAnecdotes"><i class="fa fa-check"></i><b>13.2.1</b> Two anecdotes</a></li>
<li class="chapter" data-level="13.2.2" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#Hills-ddf"><i class="fa fa-check"></i><b>13.2.2</b> Hillis ddf</a></li>
<li class="chapter" data-level="13.2.3" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#decision-rule-p-value-and-confidence-interval"><i class="fa fa-check"></i><b>13.2.3</b> Decision rule, p-value and confidence interval</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#OR-FRRC"><i class="fa fa-check"></i><b>13.3</b> Fixed-reader random-case</a></li>
<li class="chapter" data-level="13.4" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-RRFCAnalysis"><i class="fa fa-check"></i><b>13.4</b> Random-reader fixed-case</a></li>
<li class="chapter" data-level="13.5" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-Summary"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
<li class="chapter" data-level="13.6" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-Discussion"><i class="fa fa-check"></i><b>13.6</b> Discussion</a></li>
<li class="chapter" data-level="13.7" data-path="ORAnalysisSigTesting.html"><a href="ORAnalysisSigTesting.html#ORAnalysisSigTesting-references"><i class="fa fa-check"></i><b>13.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="ORApplications.html"><a href="ORApplications.html"><i class="fa fa-check"></i><b>14</b> Obuchowski Rockette Applications</a>
<ul>
<li class="chapter" data-level="14.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-introduction"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset02-hand"><i class="fa fa-check"></i><b>14.2</b> Hand calculation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.2.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.2.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset02-hand"><i class="fa fa-check"></i><b>14.2.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3</b> RJafroc: dataset02</a>
<ul>
<li class="chapter" data-level="14.3.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.3.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.3.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset02-RJafroc"><i class="fa fa-check"></i><b>14.3.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.4" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-RJafroc"><i class="fa fa-check"></i><b>14.4</b> RJafroc: dataset04</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04"><i class="fa fa-check"></i><b>14.4.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.4.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04"><i class="fa fa-check"></i><b>14.4.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.4.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04"><i class="fa fa-check"></i><b>14.4.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-FROC-RJafroc"><i class="fa fa-check"></i><b>14.5</b> RJafroc: dataset04, FROC</a>
<ul>
<li class="chapter" data-level="14.5.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.5.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.5.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04-FROC"><i class="fa fa-check"></i><b>14.5.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.6" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-dataset04-FROC-DBM-RJafroc"><i class="fa fa-check"></i><b>14.6</b> RJafroc: dataset04, FROC/DBM</a>
<ul>
<li class="chapter" data-level="14.6.1" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRRC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.1</b> Random-Reader Random-Case (RRRC) analysis</a></li>
<li class="chapter" data-level="14.6.2" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-FRRC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.2</b> Fixed-Reader Random-Case (FRRC) analysis</a></li>
<li class="chapter" data-level="14.6.3" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-RRFC-dataset04-FROC-DBM"><i class="fa fa-check"></i><b>14.6.3</b> Random-Reader Fixed-Case (RRFC) analysis</a></li>
</ul></li>
<li class="chapter" data-level="14.7" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-Summary"><i class="fa fa-check"></i><b>14.7</b> Summary</a></li>
<li class="chapter" data-level="14.8" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-Discussion"><i class="fa fa-check"></i><b>14.8</b> Discussion</a></li>
<li class="chapter" data-level="14.9" data-path="ORApplications.html"><a href="ORApplications.html#ToMullOver1-tentative"><i class="fa fa-check"></i><b>14.9</b> Tentative</a></li>
<li class="chapter" data-level="14.10" data-path="ORApplications.html"><a href="ORApplications.html#ORApplications-references"><i class="fa fa-check"></i><b>14.10</b> References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html"><i class="fa fa-check"></i><b>15</b> Sample size estimation for ROC studies DBM method</a>
<ul>
<li class="chapter" data-level="15.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-introduction"><i class="fa fa-check"></i><b>15.1</b> Introduction</a></li>
<li class="chapter" data-level="15.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#StatPower1"><i class="fa fa-check"></i><b>15.2</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#observed-vs.-anticipated-effect-size"><i class="fa fa-check"></i><b>15.2.1</b> Observed vs. anticipated effect-size</a></li>
<li class="chapter" data-level="15.2.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-dependence-of-stats-power"><i class="fa fa-check"></i><b>15.2.2</b> Dependence of statistical power on estimates of model parameters</a></li>
<li class="chapter" data-level="15.2.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRRC-sample-size-estimation"><i class="fa fa-check"></i><b>15.2.3</b> Formulae for random-reader random-case (RRRC) sample size estimation</a></li>
<li class="chapter" data-level="15.2.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-sig-testing"><i class="fa fa-check"></i><b>15.2.4</b> Significance testing</a></li>
<li class="chapter" data-level="15.2.5" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-pvalue-ci"><i class="fa fa-check"></i><b>15.2.5</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="15.2.6" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-CompareDBM2OR"><i class="fa fa-check"></i><b>15.2.6</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-FRRC-sample-size-estimation"><i class="fa fa-check"></i><b>15.3</b> Formulae for fixed-reader random-case (FRRC) sample size estimation</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRFC-sample-size-estimation"><i class="fa fa-check"></i><b>15.3.1</b> Formulae for random-reader fixed-case (RRFC) sample size estimation</a></li>
<li class="chapter" data-level="15.3.2" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-FRRCAnalysis"><i class="fa fa-check"></i><b>15.3.2</b> Fixed-reader random-case (FRRC) analysis TBA</a></li>
<li class="chapter" data-level="15.3.3" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-RRFCAnalysis"><i class="fa fa-check"></i><b>15.3.3</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="15.3.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-STMRAnalysis"><i class="fa fa-check"></i><b>15.3.4</b> Single-treatment multiple-reader analysis</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#discussionsummary2"><i class="fa fa-check"></i><b>15.4</b> Discussion/Summary/2</a></li>
<li class="chapter" data-level="15.5" data-path="RocSampleSizeDBM.html"><a href="RocSampleSizeDBM.html#RocSampleSizeDBM-references"><i class="fa fa-check"></i><b>15.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html"><i class="fa fa-check"></i><b>16</b> Sample size estimation for ROC studies OR method</a>
<ul>
<li class="chapter" data-level="16.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-introduction"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#StatPower2"><i class="fa fa-check"></i><b>16.2</b> Statistical Power</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#sample-size-estimation-for-random-reader-random-cases"><i class="fa fa-check"></i><b>16.2.1</b> Sample size estimation for random-reader random-cases</a></li>
<li class="chapter" data-level="16.2.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-dependence-of-stats-power"><i class="fa fa-check"></i><b>16.2.2</b> Dependence of statistical power on estimates of model parameters</a></li>
<li class="chapter" data-level="16.2.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRRC-sample-size-estimation"><i class="fa fa-check"></i><b>16.2.3</b> Formulae for random-reader random-case (RRRC) sample size estimation</a></li>
<li class="chapter" data-level="16.2.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-sig-testing"><i class="fa fa-check"></i><b>16.2.4</b> Significance testing</a></li>
<li class="chapter" data-level="16.2.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-pvalue-ci"><i class="fa fa-check"></i><b>16.2.5</b> p-value and confidence interval</a></li>
<li class="chapter" data-level="16.2.6" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-CompareDBM2OR"><i class="fa fa-check"></i><b>16.2.6</b> Comparing DBM to Obuchowski and Rockette for single-reader multiple-treatments</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-FRRC-sample-size-estimation"><i class="fa fa-check"></i><b>16.3</b> Formulae for fixed-reader random-case (FRRC) sample size estimation</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRFC-sample-size-estimation"><i class="fa fa-check"></i><b>16.3.1</b> Formulae for random-reader fixed-case (RRFC) sample size estimation</a></li>
<li class="chapter" data-level="16.3.2" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#example-1"><i class="fa fa-check"></i><b>16.3.2</b> Example 1</a></li>
<li class="chapter" data-level="16.3.3" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-FRRCAnalysis"><i class="fa fa-check"></i><b>16.3.3</b> Fixed-reader random-case (FRRC) analysis</a></li>
<li class="chapter" data-level="16.3.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-RRFCAnalysis"><i class="fa fa-check"></i><b>16.3.4</b> Random-reader fixed-case (RRFC) analysis</a></li>
<li class="chapter" data-level="16.3.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-STMRAnalysis"><i class="fa fa-check"></i><b>16.3.5</b> Single-treatment multiple-reader analysis</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#discussionsummary3"><i class="fa fa-check"></i><b>16.4</b> Discussion/Summary/3</a></li>
<li class="chapter" data-level="16.5" data-path="RocSampleSizeOR.html"><a href="RocSampleSizeOR.html#RocSampleSizeOR-references"><i class="fa fa-check"></i><b>16.5</b> References</a></li>
</ul></li>
<li class="part"><span><b>FROC paradigm</b></span></li>
<li class="chapter" data-level="17" data-path="froc-paradigm.html"><a href="froc-paradigm.html"><i class="fa fa-check"></i><b>17</b> The FROC paradigm</a>
<ul>
<li class="chapter" data-level="17.1" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-intro"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="froc-paradigm.html"><a href="froc-paradigm.html#location-specific-paradigms"><i class="fa fa-check"></i><b>17.2</b> Location specific paradigms</a></li>
<li class="chapter" data-level="17.3" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-vis-search"><i class="fa fa-check"></i><b>17.3</b> Visual search</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-scoring-the-data"><i class="fa fa-check"></i><b>17.3.1</b> Proximity criterion and scoring the data</a></li>
<li class="chapter" data-level="17.3.2" data-path="froc-paradigm.html"><a href="froc-paradigm.html#multiple-marks-in-the-same-vicinity"><i class="fa fa-check"></i><b>17.3.2</b> Multiple marks in the same vicinity</a></li>
<li class="chapter" data-level="17.3.3" data-path="froc-paradigm.html"><a href="froc-paradigm.html#historical-context"><i class="fa fa-check"></i><b>17.3.3</b> Historical context</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="froc-paradigm.html"><a href="froc-paradigm.html#a-pioneering-froc-study-in-medical-imaging"><i class="fa fa-check"></i><b>17.4</b> A pioneering FROC study in medical imaging</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="froc-paradigm.html"><a href="froc-paradigm.html#image-preparation"><i class="fa fa-check"></i><b>17.4.1</b> Image preparation</a></li>
<li class="chapter" data-level="17.4.2" data-path="froc-paradigm.html"><a href="froc-paradigm.html#image-interpretation-and-the-1-rating"><i class="fa fa-check"></i><b>17.4.2</b> Image Interpretation and the 1-rating</a></li>
<li class="chapter" data-level="17.4.3" data-path="froc-paradigm.html"><a href="froc-paradigm.html#scoring-the-data"><i class="fa fa-check"></i><b>17.4.3</b> Scoring the data</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-froc-plot"><i class="fa fa-check"></i><b>17.5</b> The free-response receiver operating characteristic (FROC) plot</a></li>
<li class="chapter" data-level="17.6" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-preview-rsm"><i class="fa fa-check"></i><b>17.6</b> Preview of the RSM data simulator</a></li>
<li class="chapter" data-level="17.7" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-pop-binned-plots"><i class="fa fa-check"></i><b>17.7</b> Population and binned FROC plots</a></li>
<li class="chapter" data-level="17.8" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-perceptual-snr"><i class="fa fa-check"></i><b>17.8</b> Perceptual SNR</a></li>
<li class="chapter" data-level="17.9" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-solar-analogy"><i class="fa fa-check"></i><b>17.9</b> The “solar” analogy: search vs. classification performance</a></li>
<li class="chapter" data-level="17.10" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-discussion"><i class="fa fa-check"></i><b>17.10</b> Discussion and suggestions</a></li>
<li class="chapter" data-level="17.11" data-path="froc-paradigm.html"><a href="froc-paradigm.html#froc-paradigm-references"><i class="fa fa-check"></i><b>17.11</b> References</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="froc-empirical.html"><a href="froc-empirical.html"><i class="fa fa-check"></i><b>18</b> Empirical plots</a>
<ul>
<li class="chapter" data-level="18.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-intro"><i class="fa fa-check"></i><b>18.1</b> Introduction</a></li>
<li class="chapter" data-level="18.2" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-mark-rating-pairs"><i class="fa fa-check"></i><b>18.2</b> Mark rating pairs</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="froc-empirical.html"><a href="froc-empirical.html#latent-vs.-actual-marks"><i class="fa fa-check"></i><b>18.2.1</b> Latent vs. actual marks</a></li>
<li class="chapter" data-level="18.2.2" data-path="froc-empirical.html"><a href="froc-empirical.html#binning-rule"><i class="fa fa-check"></i><b>18.2.2</b> Binning rule</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-notation"><i class="fa fa-check"></i><b>18.3</b> FROC notation</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="froc-empirical.html"><a href="froc-empirical.html#comments-on-table-reftabfroc-empirical-notation"><i class="fa fa-check"></i><b>18.3.1</b> Comments on Table @ref(tab:froc-empirical-notation)</a></li>
<li class="chapter" data-level="18.3.2" data-path="froc-empirical.html"><a href="froc-empirical.html#discussion-cases-with-zero-latent-nl-marks"><i class="fa fa-check"></i><b>18.3.2</b> Discussion: cases with zero latent NL marks</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-froc-plot"><i class="fa fa-check"></i><b>18.4</b> The empirical FROC</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-FROC"><i class="fa fa-check"></i><b>18.4.1</b> Definition</a></li>
<li class="chapter" data-level="18.4.2" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-origin-trivial-point"><i class="fa fa-check"></i><b>18.4.2</b> The origin, a trivial point</a></li>
<li class="chapter" data-level="18.4.3" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-end-point"><i class="fa fa-check"></i><b>18.4.3</b> The observed end-point and its semi-constrained property</a></li>
<li class="chapter" data-level="18.4.4" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-froc-plot-futility-extrapolation"><i class="fa fa-check"></i><b>18.4.4</b> Futility of extrapolation outside the observed end-point</a></li>
</ul></li>
<li class="chapter" data-level="18.5" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-ROC"><i class="fa fa-check"></i><b>18.5</b> The inferred ROC plot</a>
<ul>
<li class="chapter" data-level="18.5.1" data-path="froc-empirical.html"><a href="froc-empirical.html#inferred-roc-rating"><i class="fa fa-check"></i><b>18.5.1</b> Inferred-ROC rating</a></li>
<li class="chapter" data-level="18.5.2" data-path="froc-empirical.html"><a href="froc-empirical.html#inferred-fpf"><i class="fa fa-check"></i><b>18.5.2</b> Inferred FPF</a></li>
<li class="chapter" data-level="18.5.3" data-path="froc-empirical.html"><a href="froc-empirical.html#inferred-tpf"><i class="fa fa-check"></i><b>18.5.3</b> Inferred TPF</a></li>
<li class="chapter" data-level="18.5.4" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-ROC"><i class="fa fa-check"></i><b>18.5.4</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18.6" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-AFROC"><i class="fa fa-check"></i><b>18.6</b> The alternative FROC (AFROC) plot</a>
<ul>
<li class="chapter" data-level="18.6.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-AFROC"><i class="fa fa-check"></i><b>18.6.1</b> Definition</a></li>
<li class="chapter" data-level="18.6.2" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-AFROC-constrained"><i class="fa fa-check"></i><b>18.6.2</b> The constrained observed end-point of the AFROC</a></li>
</ul></li>
<li class="chapter" data-level="18.7" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-wAFROC"><i class="fa fa-check"></i><b>18.7</b> The weighted-AFROC (wAFROC) plot</a>
<ul>
<li class="chapter" data-level="18.7.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-wAFROC"><i class="fa fa-check"></i><b>18.7.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18.8" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-AFROC1"><i class="fa fa-check"></i><b>18.8</b> The AFROC1 plot</a>
<ul>
<li class="chapter" data-level="18.8.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-AFROC1"><i class="fa fa-check"></i><b>18.8.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18.9" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-wAFROC1"><i class="fa fa-check"></i><b>18.9</b> The weighted-AFROC1 (wAFROC1) plot</a>
<ul>
<li class="chapter" data-level="18.9.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-wAFROC1"><i class="fa fa-check"></i><b>18.9.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18.10" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-EFROC"><i class="fa fa-check"></i><b>18.10</b> The EFROC plot</a>
<ul>
<li class="chapter" data-level="18.10.1" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-definition-auc-EFROC"><i class="fa fa-check"></i><b>18.10.1</b> Definition</a></li>
</ul></li>
<li class="chapter" data-level="18.11" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-Discussion"><i class="fa fa-check"></i><b>18.11</b> Discussion</a></li>
<li class="chapter" data-level="18.12" data-path="froc-empirical.html"><a href="froc-empirical.html#froc-empirical-references"><i class="fa fa-check"></i><b>18.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html"><i class="fa fa-check"></i><b>19</b> Empirical plot examples</a>
<ul>
<li class="chapter" data-level="19.1" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-intro"><i class="fa fa-check"></i><b>19.1</b> Introduction</a></li>
<li class="chapter" data-level="19.2" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#raw-frocafrocroc-plots"><i class="fa fa-check"></i><b>19.2</b> Raw FROC/AFROC/ROC plots</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-raw-plots-code1"><i class="fa fa-check"></i><b>19.2.1</b> Code for raw plots</a></li>
<li class="chapter" data-level="19.2.2" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#explanation-of-the-code"><i class="fa fa-check"></i><b>19.2.2</b> Explanation of the code</a></li>
<li class="chapter" data-level="19.2.3" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#key-differences-from-the-roc-paradigm"><i class="fa fa-check"></i><b>19.2.3</b> Key differences from the ROC paradigm:</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#the-chance-level-froc-and-afroc"><i class="fa fa-check"></i><b>19.3</b> The chance level FROC and AFROC</a></li>
<li class="chapter" data-level="19.4" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#location-level-true-negatives"><i class="fa fa-check"></i><b>19.4</b> Location-level “true-negatives”</a></li>
<li class="chapter" data-level="19.5" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#binned-frocafrocroc-plots"><i class="fa fa-check"></i><b>19.5</b> Binned FROC/AFROC/ROC plots</a>
<ul>
<li class="chapter" data-level="19.5.1" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#binned-plots-code1"><i class="fa fa-check"></i><b>19.5.1</b> Code for binned plots</a></li>
<li class="chapter" data-level="19.5.2" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#effect-of-seed-on-binned-plots"><i class="fa fa-check"></i><b>19.5.2</b> Effect of <code>seed</code> on binned plots</a></li>
</ul></li>
<li class="chapter" data-level="19.6" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-str-binned-data"><i class="fa fa-check"></i><b>19.6</b> Structure of the binned data</a></li>
<li class="chapter" data-level="19.7" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-summary"><i class="fa fa-check"></i><b>19.7</b> Summary</a></li>
<li class="chapter" data-level="19.8" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-Discussion"><i class="fa fa-check"></i><b>19.8</b> Discussion</a></li>
<li class="chapter" data-level="19.9" data-path="froc-empirical-examples.html"><a href="froc-empirical-examples.html#froc-empirical-examples-references"><i class="fa fa-check"></i><b>19.9</b> References</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html"><i class="fa fa-check"></i><b>20</b> FROC vs. wAFROC</a>
<ul>
<li class="chapter" data-level="20.1" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-wafroc-intro"><i class="fa fa-check"></i><b>20.1</b> Introduction</a></li>
<li class="chapter" data-level="20.2" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs.-wafroc"><i class="fa fa-check"></i><b>20.2</b> FROC vs. wAFROC</a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#moderate-difference-in-performance"><i class="fa fa-check"></i><b>20.2.1</b> Moderate difference in performance</a></li>
<li class="chapter" data-level="20.2.2" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#large-difference-in-performance"><i class="fa fa-check"></i><b>20.2.2</b> Large difference in performance</a></li>
<li class="chapter" data-level="20.2.3" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#small-difference-in-performance-and-identical-thresholds"><i class="fa fa-check"></i><b>20.2.3</b> Small difference in performance and identical thresholds</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#summary-of-simulations"><i class="fa fa-check"></i><b>20.3</b> Summary of simulations</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#summary-of-rad-1-simulations"><i class="fa fa-check"></i><b>20.3.1</b> Summary of RAD-1 simulations</a></li>
<li class="chapter" data-level="20.3.2" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#summary-of-rad-2-simulations"><i class="fa fa-check"></i><b>20.3.2</b> Summary of RAD-2 simulations</a></li>
<li class="chapter" data-level="20.3.3" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-wafroc-comments"><i class="fa fa-check"></i><b>20.3.3</b> Comments</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-afroc-effect-sizes"><i class="fa fa-check"></i><b>20.4</b> Effect size comparison</a></li>
<li class="chapter" data-level="20.5" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-wafroc-peformance-depends-on-zeta1"><i class="fa fa-check"></i><b>20.5</b> Performance depends on <span class="math inline">\(\zeta_1\)</span></a></li>
<li class="chapter" data-level="20.6" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-wafroc-Discussion"><i class="fa fa-check"></i><b>20.6</b> Discussion</a></li>
<li class="chapter" data-level="20.7" data-path="froc-vs-afroc.html"><a href="froc-vs-afroc.html#froc-vs-wafroc-references"><i class="fa fa-check"></i><b>20.7</b> References</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="optim-op-point.html"><a href="optim-op-point.html"><i class="fa fa-check"></i><b>21</b> Optimal operating point on FROC</a>
<ul>
<li class="chapter" data-level="21.1" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-methods"><i class="fa fa-check"></i><b>21.2</b> Methods</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="optim-op-point.html"><a href="optim-op-point.html#zeta_1-optimization-for-lambda-10"><i class="fa fa-check"></i><b>21.2.1</b> <span class="math inline">\(\zeta_1\)</span> optimization for <span class="math inline">\(\lambda = 10\)</span></a></li>
<li class="chapter" data-level="21.2.2" data-path="optim-op-point.html"><a href="optim-op-point.html#zeta_1-optimization-for-lambda-1"><i class="fa fa-check"></i><b>21.2.2</b> <span class="math inline">\(\zeta_1\)</span> optimization for <span class="math inline">\(\lambda = 1\)</span></a></li>
<li class="chapter" data-level="21.2.3" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-comments-threshold-optimization"><i class="fa fa-check"></i><b>21.2.3</b> Summary of simulations and comments</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-how-to-use-method"><i class="fa fa-check"></i><b>21.3</b> How to use the method</a></li>
<li class="chapter" data-level="21.4" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-Discussion"><i class="fa fa-check"></i><b>21.4</b> Discussion</a></li>
<li class="chapter" data-level="21.5" data-path="optim-op-point.html"><a href="optim-op-point.html#optim-op-point-references"><i class="fa fa-check"></i><b>21.5</b> References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="froc-meanings.html"><a href="froc-meanings.html"><i class="fa fa-check"></i><b>22</b> Meanings of FROC figures of merit</a>
<ul>
<li class="chapter" data-level="22.1" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-intro"><i class="fa fa-check"></i><b>22.1</b> Introduction</a></li>
<li class="chapter" data-level="22.2" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-afroc"><i class="fa fa-check"></i><b>22.2</b> Empirical AFROC FOM-statistic</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="froc-meanings.html"><a href="froc-meanings.html#upper-limit-for-afroc-fom-statistic"><i class="fa fa-check"></i><b>22.2.1</b> Upper limit for AFROC FOM-statistic</a></li>
<li class="chapter" data-level="22.2.2" data-path="froc-meanings.html"><a href="froc-meanings.html#range-of-afroc-fom-statistic"><i class="fa fa-check"></i><b>22.2.2</b> Range of AFROC FOM-statistic</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-wafroc"><i class="fa fa-check"></i><b>22.3</b> Empirical weighted-AFROC FOM-statistic</a></li>
<li class="chapter" data-level="22.4" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-two-theorems"><i class="fa fa-check"></i><b>22.4</b> Two Theorems</a>
<ul>
<li class="chapter" data-level="22.4.1" data-path="froc-meanings.html"><a href="froc-meanings.html#theorem-1"><i class="fa fa-check"></i><b>22.4.1</b> Theorem 1</a></li>
<li class="chapter" data-level="22.4.2" data-path="froc-meanings.html"><a href="froc-meanings.html#theorem-2"><i class="fa fa-check"></i><b>22.4.2</b> Theorem 2</a></li>
</ul></li>
<li class="chapter" data-level="22.5" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-numerical-illustrations"><i class="fa fa-check"></i><b>22.5</b> Numerical illustrations</a></li>
<li class="chapter" data-level="22.6" data-path="froc-meanings.html"><a href="froc-meanings.html#summary-tables-of-ratings"><i class="fa fa-check"></i><b>22.6</b> Summary tables of ratings</a></li>
<li class="chapter" data-level="22.7" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-AFROC-plot-first-principles"><i class="fa fa-check"></i><b>22.7</b> AFROC plot from first principles</a></li>
<li class="chapter" data-level="22.8" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-wAFROC-plot-first-principles"><i class="fa fa-check"></i><b>22.8</b> wAFROC plot from first principles</a></li>
<li class="chapter" data-level="22.9" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-physical-interpretions"><i class="fa fa-check"></i><b>22.9</b> Physical interpretations</a>
<ul>
<li class="chapter" data-level="22.9.1" data-path="froc-meanings.html"><a href="froc-meanings.html#physical-interpretation-of-area-under-afroc"><i class="fa fa-check"></i><b>22.9.1</b> Physical interpretation of area under AFROC</a></li>
<li class="chapter" data-level="22.9.2" data-path="froc-meanings.html"><a href="froc-meanings.html#physical-interpretation-of-area-under-wafroc"><i class="fa fa-check"></i><b>22.9.2</b> Physical interpretation of area under wAFROC</a></li>
</ul></li>
<li class="chapter" data-level="22.10" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-Discussion"><i class="fa fa-check"></i><b>22.10</b> Discussion</a></li>
<li class="chapter" data-level="22.11" data-path="froc-meanings.html"><a href="froc-meanings.html#froc-meanings-references"><i class="fa fa-check"></i><b>22.11</b> References</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>REFERENCES</a></li>
<li class="part"><span><b>APPENDICES</b></span></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="chapter" data-level="A" data-path="rocdataformat.html"><a href="rocdataformat.html"><i class="fa fa-check"></i><b>A</b> ROC DATA FORMAT</a>
<ul>
<li class="chapter" data-level="A.1" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformatIntro"><i class="fa fa-check"></i><b>A.1</b> Introduction</a></li>
<li class="chapter" data-level="A.2" data-path="rocdataformat.html"><a href="rocdataformat.html#note-to-existing-users"><i class="fa fa-check"></i><b>A.2</b> Note to existing users</a></li>
<li class="chapter" data-level="A.3" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExceldataformat"><i class="fa fa-check"></i><b>A.3</b> The Excel data format</a></li>
<li class="chapter" data-level="A.4" data-path="rocdataformat.html"><a href="rocdataformat.html#illustrative-toy-file"><i class="fa fa-check"></i><b>A.4</b> Illustrative toy file</a></li>
<li class="chapter" data-level="A.5" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelTruthdataformat"><i class="fa fa-check"></i><b>A.5</b> The <code>Truth</code> worksheet</a></li>
<li class="chapter" data-level="A.6" data-path="rocdataformat.html"><a href="rocdataformat.html#the-structure-of-an-roc-dataset"><i class="fa fa-check"></i><b>A.6</b> The structure of an ROC dataset</a></li>
<li class="chapter" data-level="A.7" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelFPdataformat"><i class="fa fa-check"></i><b>A.7</b> The false positive (FP) ratings</a></li>
<li class="chapter" data-level="A.8" data-path="rocdataformat.html"><a href="rocdataformat.html#rocExcelTPdataformat"><i class="fa fa-check"></i><b>A.8</b> The true positive (TP) ratings</a></li>
<li class="chapter" data-level="A.9" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-between-nl-member-of-dataset-and-the-fp-worksheet"><i class="fa fa-check"></i><b>A.9</b> Correspondence between <code>NL</code> member of dataset and the <code>FP</code> worksheet</a></li>
<li class="chapter" data-level="A.10" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-between-ll-member-of-dataset-and-the-tp-worksheet"><i class="fa fa-check"></i><b>A.10</b> Correspondence between <code>LL</code> member of dataset and the <code>TP</code> worksheet</a></li>
<li class="chapter" data-level="A.11" data-path="rocdataformat.html"><a href="rocdataformat.html#correspondence-using-the-which-function"><i class="fa fa-check"></i><b>A.11</b> Correspondence using the <code>which</code> function</a></li>
<li class="chapter" data-level="A.12" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-Summary"><i class="fa fa-check"></i><b>A.12</b> Summary</a></li>
<li class="chapter" data-level="A.13" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-Discussion"><i class="fa fa-check"></i><b>A.13</b> Discussion</a></li>
<li class="chapter" data-level="A.14" data-path="rocdataformat.html"><a href="rocdataformat.html#rocdataformat-references"><i class="fa fa-check"></i><b>A.14</b> References</a></li>
</ul></li>
<li class="chapter" data-level="B" data-path="frocdataformat.html"><a href="frocdataformat.html"><i class="fa fa-check"></i><b>B</b> FROC data format</a>
<ul>
<li class="chapter" data-level="B.1" data-path="frocdataformat.html"><a href="frocdataformat.html#purpose"><i class="fa fa-check"></i><b>B.1</b> Purpose</a></li>
<li class="chapter" data-level="B.2" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformatIntro"><i class="fa fa-check"></i><b>B.2</b> Introduction</a></li>
<li class="chapter" data-level="B.3" data-path="frocdataformat.html"><a href="frocdataformat.html#frocExceldataformat"><i class="fa fa-check"></i><b>B.3</b> The Excel data format</a></li>
<li class="chapter" data-level="B.4" data-path="frocdataformat.html"><a href="frocdataformat.html#frocExcelTruthdataformat"><i class="fa fa-check"></i><b>B.4</b> The <code>Truth</code> worksheet</a></li>
<li class="chapter" data-level="B.5" data-path="frocdataformat.html"><a href="frocdataformat.html#the-structure-of-an-froc-dataset"><i class="fa fa-check"></i><b>B.5</b> The structure of an FROC dataset</a></li>
<li class="chapter" data-level="B.6" data-path="frocdataformat.html"><a href="frocdataformat.html#the-false-positive-fp-ratings"><i class="fa fa-check"></i><b>B.6</b> The false positive (FP) ratings</a></li>
<li class="chapter" data-level="B.7" data-path="frocdataformat.html"><a href="frocdataformat.html#the-true-positive-tp-ratings"><i class="fa fa-check"></i><b>B.7</b> The true positive (TP) ratings</a></li>
<li class="chapter" data-level="B.8" data-path="frocdataformat.html"><a href="frocdataformat.html#on-the-distribution-of-numbers-of-lesions-in-abnormal-cases"><i class="fa fa-check"></i><b>B.8</b> On the distribution of numbers of lesions in abnormal cases</a>
<ul>
<li class="chapter" data-level="B.8.1" data-path="frocdataformat.html"><a href="frocdataformat.html#definition-of-lesdistr-array"><i class="fa fa-check"></i><b>B.8.1</b> Definition of <code>lesDistr</code> array</a></li>
</ul></li>
<li class="chapter" data-level="B.9" data-path="frocdataformat.html"><a href="frocdataformat.html#definition-of-leswghtdistr-array"><i class="fa fa-check"></i><b>B.9</b> Definition of <code>lesWghtDistr</code> array</a></li>
<li class="chapter" data-level="B.10" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-Summary"><i class="fa fa-check"></i><b>B.10</b> Summary</a></li>
<li class="chapter" data-level="B.11" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-Discussion"><i class="fa fa-check"></i><b>B.11</b> Discussion</a></li>
<li class="chapter" data-level="B.12" data-path="frocdataformat.html"><a href="frocdataformat.html#frocdataformat-references"><i class="fa fa-check"></i><b>B.12</b> References</a></li>
</ul></li>
<li class="chapter" data-level="C" data-path="classification-tasks.html"><a href="classification-tasks.html"><i class="fa fa-check"></i><b>C</b> Localization - classification tasks</a>
<ul>
<li class="chapter" data-level="C.1" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-intro"><i class="fa fa-check"></i><b>C.1</b> Introduction</a></li>
<li class="chapter" data-level="C.2" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-abbreviations"><i class="fa fa-check"></i><b>C.2</b> Abbreviations</a></li>
<li class="chapter" data-level="C.3" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-basic-idea"><i class="fa fa-check"></i><b>C.3</b> History and basic idea</a></li>
<li class="chapter" data-level="C.4" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example1"><i class="fa fa-check"></i><b>C.4</b> First example, File1.xlsx</a>
<ul>
<li class="chapter" data-level="C.4.1" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example1-truth"><i class="fa fa-check"></i><b>C.4.1</b> <code>Truth</code> sheet</a></li>
<li class="chapter" data-level="C.4.2" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example1-tp"><i class="fa fa-check"></i><b>C.4.2</b> <code>TP</code> sheet</a></li>
<li class="chapter" data-level="C.4.3" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example1-fp"><i class="fa fa-check"></i><b>C.4.3</b> <code>FP</code> sheet</a></li>
<li class="chapter" data-level="C.4.4" data-path="classification-tasks.html"><a href="classification-tasks.html#the-two-ratings-arrays"><i class="fa fa-check"></i><b>C.4.4</b> The two ratings arrays</a></li>
</ul></li>
<li class="chapter" data-level="C.5" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example2"><i class="fa fa-check"></i><b>C.5</b> Second example, File2.xlsx</a></li>
<li class="chapter" data-level="C.6" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example3"><i class="fa fa-check"></i><b>C.6</b> Third example, File3.xlsx</a></li>
<li class="chapter" data-level="C.7" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example4"><i class="fa fa-check"></i><b>C.7</b> Fourth example, File4.xlsx</a></li>
<li class="chapter" data-level="C.8" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-example5"><i class="fa fa-check"></i><b>C.8</b> Fifth example, File5.xlsx</a></li>
<li class="chapter" data-level="C.9" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-precautions"><i class="fa fa-check"></i><b>C.9</b> Precautions</a></li>
<li class="chapter" data-level="C.10" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks-discussion"><i class="fa fa-check"></i><b>C.10</b> Discussion</a></li>
<li class="chapter" data-level="C.11" data-path="classification-tasks.html"><a href="classification-tasks.html#classification-tasks--references"><i class="fa fa-check"></i><b>C.11</b> References</a></li>
</ul></li>
<li class="chapter" data-level="D" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html"><i class="fa fa-check"></i><b>D</b> Split Plot Study Design</a>
<ul>
<li class="chapter" data-level="D.1" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#mean-square-rt"><i class="fa fa-check"></i><b>D.1</b> Mean Square R(T)</a></li>
<li class="chapter" data-level="D.2" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#SplitPlotChapter-references"><i class="fa fa-check"></i><b>D.2</b> References</a></li>
<li class="chapter" data-level="D.3" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#assessing-standalone-performance-of-cad-vs.-radiologists-interpreting-the-same-cases"><i class="fa fa-check"></i><b>D.3</b> Assessing standalone performance of CAD vs. radiologists interpreting the same cases</a></li>
<li class="chapter" data-level="D.4" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-abstract"><i class="fa fa-check"></i><b>D.4</b> Abstract</a></li>
<li class="chapter" data-level="D.5" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-ker-words"><i class="fa fa-check"></i><b>D.5</b> Keywords</a></li>
<li class="chapter" data-level="D.6" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-introduction"><i class="fa fa-check"></i><b>D.6</b> Introduction</a></li>
<li class="chapter" data-level="D.7" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-methods"><i class="fa fa-check"></i><b>D.7</b> Methods</a>
<ul>
<li class="chapter" data-level="D.7.1" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-two-previous-studies"><i class="fa fa-check"></i><b>D.7.1</b> Studies assessing performance of CAD vs. radiologists</a></li>
<li class="chapter" data-level="D.7.2" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-2TRRRC-anlaysis"><i class="fa fa-check"></i><b>D.7.2</b> The 2T-RRRC analysis model</a></li>
<li class="chapter" data-level="D.7.3" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-1TRRRC-anlaysis"><i class="fa fa-check"></i><b>D.7.3</b> Random-reader random-case (1T-RRRC) analysis</a></li>
<li class="chapter" data-level="D.7.4" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-computational-details"><i class="fa fa-check"></i><b>D.7.4</b> Computational details</a></li>
</ul></li>
<li class="chapter" data-level="D.8" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-results"><i class="fa fa-check"></i><b>D.8</b> Results</a></li>
<li class="chapter" data-level="D.9" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-discussion"><i class="fa fa-check"></i><b>D.9</b> Discussion</a></li>
<li class="chapter" data-level="D.10" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-appendix"><i class="fa fa-check"></i><b>D.10</b> Appendix</a></li>
<li class="chapter" data-level="D.11" data-path="SplitPlotChapter.html"><a href="SplitPlotChapter.html#standalone-cad-radiologists-references"><i class="fa fa-check"></i><b>D.11</b> References</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Standalone CAD vs. Radiologists {#standalone-cad-radiologists} cases</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ratingsParadigm" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> Ratings Paradigm</h1>
<div id="introduction" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Introduction</h2>
<p>In Chapter <a href="binary-task0.html#binary-task0">2</a> the binary paradigm and associated concepts (e.g., sensitivity, specificity) were introduced. Chapter <a href="binary-task.html#binary-task">3</a> introduced the concepts of a random scalar decision variable, or z-sample for each case, which is compared, by the observer to a fixed reporting threshold <span class="math inline">\(\zeta\)</span>, resulting in two types of decisions. It described a statistical model, characterized by two unit-variance normal distributions separated by <span class="math inline">\(\mu\)</span>, for the binary task. The concept of an underlying receiver operating characteristic (ROC) curve with the reporting threshold defining an operating point on the curve was introduced and the advisability of using the area under the curve as a measure of performance, which is independent of reporting threshold, was stressed.</p>
<p>In this chapter the more commonly used ratings method will be described, which yields greater definition to the underlying ROC curve than just one operating point obtained in the binary task, and moreover, is more efficient. In this method, the observer assigns a rating to each case. Described first is a typical ROC counts table and how operating points (i.e., pairs of FPF and TPF values) are calculated from the counts data. A labeling convention for the operating points is introduced. Notation is introduced for the observed integers in the counts table and the rules for calculating operating points are expressed as formulae and implemented in R. The ratings method is contrasted to the binary method, in terms of efficiency and practicality. A theme occurring repeatedly in this book, that the ratings are not numerical values but rather they are ordered labels is illustrated with an example. A method of collecting ROC data on a 6-point scale is described that has the advantage of yielding an unambiguous single operating point. The forced choice paradigm is described. Two controversies are described: one on the utility of discrete (e.g., 1 to 6) vs. quasi-continuous (e.g., 0 to 100) ratings and the other on the applicability of a clinical screening mammography-reporting scale for ROC analyses. Both of these are important issues and it would be a disservice to the readers of the book if the author did not express his position on them.</p>
</div>
<div id="the-roc-counts-table" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> The ROC counts table</h2>
<p>In a positive-directed rating scale with five discrete levels, the ratings could be the ordered labels:</p>
<ul>
<li>“1”: definitely non-diseased,</li>
<li>“2”: probably non-diseased,</li>
<li>“3”: could be non-diseased or diseased,</li>
<li>“4”: probably diseased,</li>
<li>“5”: definitely diseased.</li>
</ul>
<p>At the conclusion of the ROC study an ROC counts table is constructed. This is the generalization to rating studies of the 2 x 2 decision vs. truth table introduced in Chapter <a href="binary-task0.html#binary-task0">2</a>, Table <a href="binary-task0.html#tab:binary-task0truthTable">2.1</a>. This type of data representation is sometimes called a frequency table, but frequency usually means a rate of number of events per some unit, so the author prefers the clearer term “counts.”</p>
<p>Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a> is a representative counts table for a 5-rating study that summarizes the collected data. It is the starting point for analysis. It lists the number of counts in each ratings bin, listed separately for non-diseased and diseased cases, respectively. The data is from an actual clinical study <span class="citation">(<a href="SplitPlotChapter.html#ref-RN4343" role="doc-biblioref">Barnes et al. 1989</a>)</span>.</p>
<table>
<caption>
<span id="tab:ratingsParadigmExampleTable">TABLE 4.1: </span>Representative counts table.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 5\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 4\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 3\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 2\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r = 1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
non-diseased
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
8
</td>
<td style="text-align:right;">
19
</td>
<td style="text-align:right;">
30
</td>
</tr>
<tr>
<td style="text-align:left;">
diseased
</td>
<td style="text-align:right;">
22
</td>
<td style="text-align:right;">
12
</td>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
6
</td>
<td style="text-align:right;">
5
</td>
</tr>
</tbody>
</table>
<p>In this table:</p>
<ul>
<li><span class="math inline">\(r = 5\)</span> means “rating equal to 5”</li>
<li><span class="math inline">\(r = 4\)</span> means “rating equal to 4”</li>
<li>Etc.</li>
</ul>
<p>There are <span class="math inline">\(K_1 = 60\)</span> non-diseased cases and <span class="math inline">\(K_2 = 50\)</span> diseased cases. Of the 60 non-diseased cases:</p>
<ul>
<li>one received the “5” rating,</li>
<li>two the “4” rating,</li>
<li>eight the “3” rating,</li>
<li>19 the “2” rating and</li>
<li>30 the “1” rating.</li>
</ul>
<p>The distribution of counts is tilted towards the “1” rating end. In contrast, the distribution of the diseased cases is tilted towards the “5” rating end. Of the 50 diseased cases:</p>
<ul>
<li>22 received the “5” rating,</li>
<li>12 the “4” rating,</li>
<li>five the “3” rating,</li>
<li>six the “2” rating and</li>
<li>five the “1” rating.</li>
</ul>
<p>A little thought should convince one that the observed tilting of the counts, towards the “1” end for actually non-diseased cases, and towards the “5” end for actually diseased cases, is reasonable.</p>
<p>The spread appears to be more pronounced for the diseased cases, e.g., five of the 50 cases appeared to be definitely non-diseased to the observer. However, one is forewarned not to jump to conclusions about the spread of the data being larger for diseased than for non-diseased cases based on observed rating alone. While it turns out to be true as will be shown later, the <strong>ratings are merely ordered labels</strong>, and modeling is required, see Chapter <a href="BinormalModel.html#BinormalModel">6</a>, that uses only the <em>ordering information</em> implicit in the labels, not the <em>actual values</em>, to reach quantitative conclusions.</p>
</div>
<div id="operating-points-from-counts-table" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Operating points from counts table</h2>
<p>Table <a href="ratingsParadigm.html#tab:ratingsParadigmTable2">4.2</a> illustrates how ROC operating points are calculated from the cell counts. In this table:</p>
<ul>
<li><span class="math inline">\(r\geq 5\)</span> means “counting ratings greater than or equal to 5”</li>
<li><span class="math inline">\(r\geq 4\)</span> means “counting ratings greater than or equal to 4”</li>
<li>Etc.</li>
</ul>
<table>
<caption>
<span id="tab:ratingsParadigmTable2">TABLE 4.2: </span>Computation of operating points from cell counts.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(r\geq 5\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r\geq 4\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r\geq 3\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r\geq 2\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(r\geq 1\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
FPF
</td>
<td style="text-align:right;">
0.0167
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.1833
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:right;">
1
</td>
</tr>
<tr>
<td style="text-align:left;">
TPF
</td>
<td style="text-align:right;">
0.4400
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
0.7800
</td>
<td style="text-align:right;">
0.9
</td>
<td style="text-align:right;">
1
</td>
</tr>
</tbody>
</table>
<p>One starts with non-diseased cases that were rated five or more (in this example, since 5 is the highest allowed rating, the “or more” clause is inconsequential) and divides by the total number of non-diseased cases, <span class="math inline">\(K_1 = 60\)</span>. This yields the abscissa of the lowest non-trivial operating point, namely <span class="math inline">\(FPF_{\ge5}\)</span> = 1/60 = 0.017. The subscript on FPF is intended to make explicit which ratings are being cumulated. The corresponding ordinate is obtained by dividing the number of diseased cases rated “5” or more and dividing by the total number of diseased cases, <span class="math inline">\(K_2 = 50\)</span>, yielding <span class="math inline">\(TPF_{\ge5}\)</span> = 22/50 = 0.440. Therefore, the coordinates of the lowest operating point are (0.017, 0.44). The abscissa of the next higher operating point is obtained by dividing the number of non-diseased cases that were rated “4” or more and dividing by the total number of non-diseased cases, i.e., <span class="math inline">\(TPF_{\ge4}\)</span> = 3/60 = 0.05. Similarly the ordinate of this operating point is obtained by dividing the number of diseased cases that were rated “4” or more and dividing by the total number of diseased cases, i.e., <span class="math inline">\(FPF_{\ge4}\)</span> = 34/50 = 0.680. The procedure, which at each stage cumulates the number of cases equal to or greater (in the sense of increased confidence level for disease presence) than a specified ordered label, is repeated to yield the rest of the operating points listed in Table <a href="ratingsParadigm.html#tab:ratingsParadigmTable2">4.2</a>. Since they are computed directly from the data, without any assumption, they are called empirical or observed operating points.</p>
<p>After doing this once, it would be nice to have a formula implementing the process, one use of which would be to code the procedure. But first one needs appropriate notation for the bin counts.</p>
<p>Let <span class="math inline">\(K_{1r}\)</span> denote the number of non-diseased cases rated <span class="math inline">\(r\)</span>, and <span class="math inline">\(K_{2r}\)</span> denote the number of diseased cases rated <span class="math inline">\(r\)</span>. For convenience, define dummy counts <span class="math inline">\(K_{1{(R+1)}}\)</span> = <span class="math inline">\(K_{2{(R+1)}}\)</span> = 0, where R is the number of ROC bins, <span class="math inline">\(R = 5\)</span> in the current example. This construct allows inclusion of the origin (0,0) in the formulae. The range of <span class="math inline">\(r\)</span> is <span class="math inline">\(r = 1,2,...,(R+1)\)</span>. Within each truth-state, the individual bin counts sum to the total number of non-diseased and diseased cases, respectively. The following equations summarize all this:</p>
<p><span class="math display">\[\begin{equation*} 
K_1=\sum_{r=1}^{R+1}K_{1r}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*} 
K_2=\sum_{r=1}^{R+1}K_{2r}
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*} 
K_{1{(R+1)}} = K_{2{(R+1)}} = 0
\end{equation*}\]</span></p>
<p><span class="math display">\[\begin{equation*} 
r = 1,2,...,(R+1)
\end{equation*}\]</span></p>
<p>The operating points are defined by:</p>
<p><span class="math display" id="eq:ratingsParadigm-FPF-TPF-from-counts">\[\begin{equation}
\left. 
\begin{aligned}
FPF_r=&amp; \frac {1} {K_1} \sum_{s=r}^{R+1}K_{1s}\\
TPF_r=&amp; \frac {1} {K_2} \sum_{s=r}^{R+1}K_{2s}
\end{aligned}
\right \}
\tag{4.1}
\end{equation}\]</span></p>
<div id="labeling-the-points" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Labeling the points</h3>
<p>The labeling <span class="math inline">\(O_n\)</span> of the points follows the following convention: From Eqn. <a href="ratingsParadigm.html#eq:ratingsParadigm-FPF-TPF-from-counts">(4.1)</a>, the point corresponding to <span class="math inline">\(r=1\)</span> would correspond to the upper right corner (1,1) of the ROC plot, a trivial operating point since it is common to all datasets, and is therefore not shown. The labeling starts with the next lower-left point, labeled <span class="math inline">\(O_1\)</span>, which corresponds to <span class="math inline">\(r=2\)</span>; the next lower-left point is labeled <span class="math inline">\(O_2\)</span>, corresponding to <span class="math inline">\(r=3\)</span>, etc., and the point labeled <span class="math inline">\(O_4\)</span> is the lowest non-trivial operating point corresponding to <span class="math inline">\(r=R=5\)</span> and finally <span class="math inline">\(O_R\)</span> corresponding to <span class="math inline">\(r=R+1\)</span> is the origin (0,0) of the ROC plot, which is also a trivial operating point, because it is common to all datasets, and is therefore not shown. <strong>To summarize, the operating points are labeled starting with the upper right corner, labeled <span class="math inline">\(O_1\)</span>, and working down the curve, each time increasing the number by one. The total number of points is <span class="math inline">\(R-1\)</span>.</strong> The relation between <span class="math inline">\(n\)</span> in the label and <span class="math inline">\(r\)</span> in Eqn. <a href="ratingsParadigm.html#eq:ratingsParadigm-FPF-TPF-from-counts">(4.1)</a> is <span class="math inline">\(n=r-1\)</span>. An example of the labeling is shown in the next chapter, Fig. <a href="empirical-auc.html#fig:empirical-auc-EmpiricalPlot">5.1</a>.</p>
</div>
<div id="examples" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Examples</h3>
<p>In the following examples <span class="math inline">\(R = 5\)</span> is the number of ROC bins and <span class="math inline">\(K_{1(R+1)}\)</span> = <span class="math inline">\(K_{2(R+1)}\)</span> = 0. If <span class="math inline">\(r = 1\)</span> one gets the uppermost “trivial” operating point (1,1):</p>
<p><span class="math display">\[\begin{equation*} 
FPF_1=\frac {1} {K_1} \sum_{s=1}^{R+1}K_{1s} = \frac{60}{60} = 1\\
TPF_1=\frac {1} {K_2} \sum_{s=1}^{R+1}K_{2s} = \frac{50}{50} = 1
\end{equation*}\]</span></p>
<p>The uppermost non-trivial operating point is obtained for <span class="math inline">\(r = 2\)</span>, when:</p>
<p><span class="math display">\[\begin{equation*} 
FPF_2=\frac {1} {K_1} \sum_{s=2}^{R+1}K_{1s} = \frac{30}{60} = 0.5\\
TPF_2=\frac {1} {K_2} \sum_{s=2}^{R+1}K_{2s} = \frac{45}{50} = 0.9
\end{equation*}\]</span></p>
<p>The next lower operating point is obtained for <span class="math inline">\(r = 3\)</span>:</p>
<p><span class="math display">\[\begin{equation*} 
FPF_3=\frac {1} {K_1} \sum_{s=3}^{R+1}K_{1s} = \frac{11}{60} = 0.183\\
TPF_3=\frac {1} {K_2} \sum_{s=3}^{R+1}K_{2s} = \frac{39}{50} = 0.780
\end{equation*}\]</span></p>
<p>The next lower operating point is obtained for <span class="math inline">\(r = 4\)</span>:</p>
<p><span class="math display">\[\begin{equation*} 
FPF_4=\frac {1} {K_1} \sum_{s=4}^{R+1}K_{1s} = \frac{3}{60} = 0.05\\
TPF_4=\frac {1} {K_2} \sum_{s=4}^{R+1}K_{2s} = \frac{34}{50} = 0.680
\end{equation*}\]</span></p>
<p>The lowest non-trivial operating point is obtained for <span class="math inline">\(r = 5\)</span>:</p>
<p><span class="math display">\[\begin{equation*} 
FPF_5=\frac {1} {K_1} \sum_{s=5}^{R+1}K_{1s} = \frac{1}{60} = 0.017\\
TPF_5=\frac {1} {K_2} \sum_{s=5}^{R+1}K_{2s} = \frac{22}{50} = 0.440
\end{equation*}\]</span></p>
<p>The next value <span class="math inline">\(r = 6\)</span> yields the trivial operating point (0,0):</p>
<p><span class="math display">\[\begin{equation*} 
FPF_6=\frac {1} {K_1} \sum_{s=6}^{R+1}K_{1s} = \frac{0}{60} = 0\\
TPF_6=\frac {1} {K_2} \sum_{s=6}^{R+1}K_{2s} = \frac{0}{50} = 0
\end{equation*}\]</span></p>
<p>This exercise shows explicitly that an R-rating ROC study can yield, at most, <span class="math inline">\(R + 1\)</span> distinct non-trivial operating points; i.e., those corresponding to <span class="math inline">\(r=2,3,...,R\)</span>.</p>
<p>The modifier “at most” is needed, because if both counts (i.e., non-diseased and diseased) for bin <span class="math inline">\(r&#39;\)</span> are zeroes, then that operating point merges with the one immediately below-left of it:</p>
<p><span class="math display">\[\begin{equation*} 
FPF_{r&#39;}=\frac {1} {K_1} \sum_{s={r&#39;}}^{R+1}K_{1s} = \frac {1} {K_1} \sum_{s={r&#39;+1}}^{R+1}K_{1s} = FPF_{r&#39;+1}\\
\\
TPF_{r&#39;}=\frac {1} {K_2} \sum_{s={r&#39;}}^{R+1}K_{2s} = \frac {1} {K_2} \sum_{s={r&#39;+1}}^{R+1}K_{2s} = TPF_{r&#39;+1}
\end{equation*}\]</span></p>
<p>Since bin <span class="math inline">\(r&#39;\)</span> is unpopulated, one can re-label the bins to exclude the unpopulated bin, and now the total number of bins is effectively <span class="math inline">\(R-1\)</span>.</p>
<p>Since one is cumulating counts, which cannot be negative, the highest non-trivial operating point resulting from cumulating the 2 through 5 ratings has to be to the upper-right of the next adjacent operating point resulting from cumulating the 3 through 5 ratings. This in turn has to be to the upper-right of the operating point resulting from cumulating the 4 through 5 ratings. This in turn has to be to the upper right of the operating point resulting from the 5 ratings. In other words, as one cumulates ratings bins, the operating point must move monotonically up and to the right, or more accurately, the point cannot move down or to the left. If a particular bin has zero counts for non-diseased cases, and non-zero counts for diseased cases, the operating point moves vertically up when this bin is cumulated; if it has zero counts for diseased cases, and non-zero counts for non-diseased cases, the operating point moves horizontally to the right when this bin is cumulated.</p>
</div>
</div>
<div id="automating-all-this" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Automating all this</h2>
<p>It is useful to replace the preceding detailed explanation with a simple algorithm, as in the following code (see first seven lines):</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="ratingsParadigm.html#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">options</span>(<span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb18-2"><a href="ratingsParadigm.html#cb18-2" aria-hidden="true" tabindex="-1"></a>FPF <span class="ot">&lt;-</span> OpPts[<span class="dv">1</span>,]</span>
<span id="cb18-3"><a href="ratingsParadigm.html#cb18-3" aria-hidden="true" tabindex="-1"></a>TPF <span class="ot">&lt;-</span> OpPts[<span class="dv">2</span>,]</span>
<span id="cb18-4"><a href="ratingsParadigm.html#cb18-4" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">FPF =</span> FPF, <span class="at">TPF =</span> TPF)</span>
<span id="cb18-5"><a href="ratingsParadigm.html#cb18-5" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">t</span>(df)</span>
<span id="cb18-6"><a href="ratingsParadigm.html#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="fu">print</span>(df)</span>
<span id="cb18-7"><a href="ratingsParadigm.html#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       [,1] [,2]  [,3] [,4] [,5]</span></span>
<span id="cb18-8"><a href="ratingsParadigm.html#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; FPF 0.0167 0.05 0.183  0.5    1</span></span>
<span id="cb18-9"><a href="ratingsParadigm.html#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; TPF 0.4400 0.68 0.780  0.9    1</span></span>
<span id="cb18-10"><a href="ratingsParadigm.html#cb18-10" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(.<span class="dv">5</span>)<span class="sc">+</span><span class="fu">qnorm</span>(.<span class="dv">9</span>);sigma <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb18-11"><a href="ratingsParadigm.html#cb18-11" aria-hidden="true" tabindex="-1"></a>Az <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(mu<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">2</span>))</span>
<span id="cb18-12"><a href="ratingsParadigm.html#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;uppermost point based estimate of mu = &quot;</span>, mu, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb18-13"><a href="ratingsParadigm.html#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; uppermost point based estimate of mu =  1.28</span></span>
<span id="cb18-14"><a href="ratingsParadigm.html#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;corresponding estimate of Az = &quot;</span>, Az, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb18-15"><a href="ratingsParadigm.html#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; corresponding estimate of Az =  0.818</span></span></code></pre></div>
<p>Notice that the values of the arrays <code>FPF</code> and <code>TPF</code> are identical to those listed in Table <a href="ratingsParadigm.html#tab:ratingsParadigmTable2">4.2</a>. Regarding the last four lines of code, it was shown in Chapter <a href="binary-task.html#binary-task">3</a> that in the equal variance binormal model the operating point determines the parameters <span class="math inline">\(\mu\)</span> = 1.282, Eqn. <a href="binary-task.html#eq:binary-task-SolveForMu">(3.17)</a>, or equivalently <span class="math inline">\(A_{z;\sigma = 1}\)</span> = 0.818, Eqn. <a href="binary-task.html#eq:binary-task-Az-EqVarModel2">(3.23)</a>. The last four lines illustrate the application of these formulae using the coordinates (0.5, 0.9) of the uppermost non-trivial operating point, i.e., one is fitting the equal variance model to the uppermost operating point.</p>
<p>Shown next is the equal-variance model fit to the uppermost non-trivial operating point, left plot, and for comparison, the right plot is the unequal variance model fit to all operating points. The unequal variance model is the subject of an upcoming chapter.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="ratingsParadigm.html#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="co"># equal variance fit to uppermost operating point</span></span>
<span id="cb19-2"><a href="ratingsParadigm.html#cb19-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">plotROC</span> (mu, sigma, FPF, TPF)</span>
<span id="cb19-3"><a href="ratingsParadigm.html#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="co"># the following values are from unequal-variance model fitting</span></span>
<span id="cb19-4"><a href="ratingsParadigm.html#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="co"># to be discussed later</span></span>
<span id="cb19-5"><a href="ratingsParadigm.html#cb19-5" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fl">2.17</span>;sigma <span class="ot">&lt;-</span> <span class="fl">1.65</span></span>
<span id="cb19-6"><a href="ratingsParadigm.html#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># this formula to be discussed later</span></span>
<span id="cb19-7"><a href="ratingsParadigm.html#cb19-7" aria-hidden="true" tabindex="-1"></a>Az <span class="ot">&lt;-</span> <span class="fu">pnorm</span>(mu<span class="sc">/</span><span class="fu">sqrt</span>(<span class="dv">1</span><span class="sc">+</span>sigma<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb19-8"><a href="ratingsParadigm.html#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="fu">cat</span>(<span class="st">&quot;binormal unequal variance model estimate of Az = &quot;</span>, Az, <span class="st">&quot;</span><span class="sc">\n</span><span class="st">&quot;</span>)</span>
<span id="cb19-9"><a href="ratingsParadigm.html#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; binormal unequal variance model estimate of Az =  0.87</span></span>
<span id="cb19-10"><a href="ratingsParadigm.html#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co"># unequal variance fit to all operating points</span></span>
<span id="cb19-11"><a href="ratingsParadigm.html#cb19-11" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">plotROC</span> (mu, sigma, FPF, TPF)</span></code></pre></div>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="ratingsParadigm.html#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.arrange</span>(p1,p2,<span class="at">ncol=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="figure"><span id="fig:ratingsParadigmEqVarFitA"></span>
<img src="04-ratings-task_files/figure-html/ratingsParadigmEqVarFitA-1.png" alt="(A): The left figure is the predicted ROC curve for $\mu=1.282$ superposed on the operating points. (B): The right figure is the same data fitted with a two-parameter model described later." width="672" />
<p class="caption">
FIGURE 4.1: (A): The left figure is the predicted ROC curve for <span class="math inline">\(\mu=1.282\)</span> superposed on the operating points. (B): The right figure is the same data fitted with a two-parameter model described later.
</p>
</div>
<p>It should come as no surprise that the uppermost operating point is <em>exactly</em> on the predicted curve: after all, this point was used to calculate <span class="math inline">\(\mu\)</span> = 2.17. The corresponding value of <span class="math inline">\(\zeta\)</span> can be calculated from Eqn. (3.17), namely:</p>
<p><span class="math display" id="eq:ratingsParadigm-Zeta">\[\begin{equation*} 
\zeta = \Phi^{-1}\left ( Sp \right )
\tag{4.2}
\end{equation*}\]</span></p>
<p><span class="math display" id="eq:ratingsParadigm-Mu">\[\begin{equation*} 
\mu = \zeta + \Phi^{-1}\left ( Se \right )
\tag{4.3}
\end{equation*}\]</span></p>
<p>These are coded below:</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="ratingsParadigm.html#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qnorm</span>(<span class="dv">1</span><span class="fl">-0.5</span>)</span>
<span id="cb21-2"><a href="ratingsParadigm.html#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0</span></span>
<span id="cb21-3"><a href="ratingsParadigm.html#cb21-3" aria-hidden="true" tabindex="-1"></a>mu<span class="sc">-</span><span class="fu">qnorm</span>(<span class="fl">0.9</span>)</span>
<span id="cb21-4"><a href="ratingsParadigm.html#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.888</span></span></code></pre></div>
<p>Either way, one gets the same result: <span class="math inline">\(\zeta\)</span> = 0. It should be clear that this makes sense: FPF = 0.5 is consistent with half of the (symmetrical) unit-normal non-diseased distribution being above <span class="math inline">\(\zeta\)</span> = 0. The transformed value <span class="math inline">\(\zeta\)</span> (zero in this example) is a genuine numerical value. <em>To reiterate, ratings cannot be treated as genuine numerical values, but thresholds, estimated from an appropriate model, can be treated as genuine numerical values.</em></p>
<p>Exercise: calculate <span class="math inline">\(\zeta\)</span> for each of the remaining operating points. <em>Notice that <span class="math inline">\(\zeta\)</span> increases as one moves down the curve.</em></p>
<ul>
<li><p>In Fig. <a href="ratingsParadigm.html#fig:ratingsParadigmEqVarFitA">4.1</a> (A), the ROC curve, as determined by the uppermost operating point, passes exactly through this point but misses the others. If a different operating point were used to estimate <span class="math inline">\(\mu\)</span> and <span class="math inline">\(A_{z;\sigma = 1}\)</span>, the estimated values would have been different and the new curve would pass exactly through the <em>new</em> selected point. No single-point based choice of <span class="math inline">\(\mu\)</span> would yield a satisfactory visual fit to all the observed operating points. <strong>This is the reason one needs a modified model, with an extra parameter, namely the unequal variance binormal model, to fit radiologist data</strong> (the extra parameter is the ratio of the standard deviations of the two distributions).</p></li>
<li><p>Fig. <a href="ratingsParadigm.html#fig:ratingsParadigmEqVarFitA">4.1</a> (B) shows the predicted ROC curve by the unequal variance binormal model, to be introduced in Chapter 06. The corresponding parameter values are <span class="math inline">\(\mu\)</span> = 2.17and <span class="math inline">\(\sigma\)</span> = 1.65.</p></li>
<li><p>Notice the improved visual quality of the fit. Each observed point is “not engraved in stone,” rather both FPF and TPF are subject to sampling variability. Estimation of confidence intervals for FPF and TPF was addressed, see <a href="binary-task.html#eq:binary-task-CI-FPF">(3.31)</a> and <a href="binary-task.html#eq:binary-task-CI-TPF">(3.33)</a>. [A detail: the estimated confidence interval in the preceding chapter was for a single operating point; since the multiple operating points are correlated – some of the counts used to calculate them are common to two or more operating points – the method tends to overestimate the confidence interval. A modeling approach to estimating confidence intervals accounts for these correlations and yields tighter confidence intervals.]</p></li>
</ul>
</div>
<div id="relation-between-ratings-paradigm-and-the-binary-paradigm" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Relation between ratings paradigm and the binary paradigm</h2>
<p>Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a> and Table <a href="ratingsParadigm.html#tab:ratingsParadigmTable2">4.2</a> correspond to <span class="math inline">\(R = 5\)</span>. In Chapter <a href="binary-task0.html#binary-task0">2</a> it was shown that the binary task requires a single fixed threshold parameter <span class="math inline">\(\zeta\)</span> and a decision or binning rule Eqn. <a href="ratingsParadigm.html#eq:ratingsParadigm-binningRule">(4.4)</a>: assign the case a diseased rating of 2 if <span class="math inline">\(Z &gt; \zeta\)</span> and a rating of 1 otherwise.</p>
<p><strong>The R-rating task can be viewed as <span class="math inline">\(R-1\)</span> simultaneously conducted binary tasks each with its own fixed threshold <span class="math inline">\(\zeta_r\)</span>, where r = 1, 2, …, R-1. It is efficient compared to <span class="math inline">\(R-1\)</span> sequentially conducted binary tasks; however, the onus is on the observer to maintain fixed-multiple thresholds through the duration of the study.</strong></p>
<p>The rating method is a more efficient way of collecting the data compared to running the study repeatedly with appropriate instructions to cause the observer to adopt different fixed thresholds specific to each replication. In the clinical context such repeated studies would be impractical because it would introduce memory effects, wherein the diagnosis of a case would depend on how many times the case had been seen, along with other cases, in previous sessions. A second reason is that it is difficult for a radiologist to change the operating threshold in response to instructions. To the author’s knowledge, repeated use of the binary paradigm has not been used in any clinical ROC study</p>
<p>In order to model the binning, one defines dummy thresholds <span class="math inline">\(\zeta_0 = - \infty\)</span> and <span class="math inline">\(\zeta_R = + \infty\)</span>, in which case the thresholds satisfy the ordering requirement <span class="math inline">\(\zeta_{r-1} \le \zeta_r\)</span> , r = 1, 2, …, R. The rating or binning rule is:</p>
<p><span class="math display" id="eq:ratingsParadigm-binningRule">\[\begin{equation}
\left.
\begin{aligned}  
if \left (\zeta_{r-1} \le z &lt; \zeta_r  \right )\Rightarrow \text rating = r\\
r = 1, 2, ..., R
\end{aligned}
\right \}
\tag{4.4}
\end{equation}\]</span></p>
<p>For Table <a href="ratingsParadigm.html#tab:ratingsParadigmTable2">4.2</a>, the <strong>empirical</strong> thresholds are as follows:</p>
<p><span class="math display" id="eq:ratingsParadigm-EmpZeta">\[\begin{equation} 
\left.
\begin{aligned}
\zeta_r &amp;= r + 1 \\
r &amp; = 1, 2, ..., R-1\\
\zeta_0 &amp;= -\infty\\
\zeta_R &amp;= \infty\\
\end{aligned}
\right \}
\tag{4.5}
\end{equation}\]</span></p>
<p>The empirical thresholds are integers, as distinct from the floating point values predicted by Eqn. <a href="ratingsParadigm.html#eq:ratingsParadigm-Zeta">(4.2)</a>. <strong>Either way one gets the same operating points.</strong> This is a subtle and important distinction, which is related to the next section: one has enormous flexibility in the choice of the scale adopted for the decision variable axis.</p>
<p>In Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a> the number of bins is <span class="math inline">\(R = 5\)</span>. The “simultaneously conducted binary tasks” nature of the rating task can be appreciated from the following examples. Suppose one selects the threshold for the first binary task to be <span class="math inline">\(\zeta_4 = 5\)</span>. By definition, <span class="math inline">\(\zeta_5 = \infty\)</span>; therefore a case rated 5 satisfies the binning rule <span class="math inline">\(\zeta_4 \leq 5 &lt; \zeta_5\)</span>, i.e., Eqn. <a href="ratingsParadigm.html#eq:ratingsParadigm-binningRule">(4.4)</a>. The operating point corresponding to <span class="math inline">\(\zeta_4 = 5\)</span>, obtained by cumulating all cases rated five, yields <span class="math inline">\((0.017, 0.440)\)</span>. In the second binary-task, one selects as threshold <span class="math inline">\(\zeta_3 = 4\)</span>. Therefore, a case rated four satisfies the binning rule <span class="math inline">\(\zeta_3 \leq 4 &lt; \zeta_4\)</span>. The operating point corresponding to <span class="math inline">\(\zeta_3 = 4\)</span>, obtained by cumulating all cases rated four or five, yields <span class="math inline">\((0.05, 0.680)\)</span>. Similarly, for <span class="math inline">\(\zeta_2 = 3\)</span>, <span class="math inline">\(\zeta_1 = 2\)</span> and <span class="math inline">\(\zeta_0 = -\infty\)</span>, which yield counts in bins 3, 2 and 1, respectively. The last is a trivial operating point. The non-trivial operating points are generated by thresholds <span class="math inline">\(\zeta_r\)</span>, where <span class="math inline">\(r\)</span> = 1, 2, 3 and 4. A five-rating study has four associated thresholds and a corresponding number of equivalent binary studies. In general, an <span class="math inline">\(R\)</span> rating study has <span class="math inline">\(R-1\)</span> associated thresholds.</p>
</div>
<div id="ratings-are-not-numerical-values" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Ratings are not numerical values</h2>
<p>The ratings are to be thought of as ordered labels, not as numeric values. Arithmetic operations that are allowed on numeric values, such as averaging, are not allowed on ratings. One could have relabeled the ratings in Table 4.2 as A, B, C, D and E, where A &lt; B etc. As long as the counts in the body of the table are unaltered, such relabeling would have no effect on the observed operating points and the fitted curve. Of course one cannot average the labels A, B, etc. of different cases. The issue with numeric labels is not fundamentally different. At the root is that the difference in thresholds corresponding to the different operating points are not in relation to the difference between their numeric values. There is a way to estimate the underlying thresholds, if one assumes a specific model, for example the unequal-variance binormal model to be described in Chapter 06. The thresholds so obtained are genuine numeric values and can be averaged. [Not to hold the reader in suspense, the four thresholds corresponding to the data in Table 4.1 are 0.007676989, 0.8962713, 1.515645 and 2.396711; see §6.4.1; these values would be unchanged if, for example, the labels were doubled, with allowed values 2, 4, 6, 8 and 10, or any of an infinite number of rearrangements that preserves their ordering.]</p>
<p>The temptation to regard confidence levels / ratings as numeric values can be particularly strong when one uses a large number of bins to collect the data. One could use of quasi-continuous ratings scale, implemented for example, by having a slider-bar user interface for selecting the rating. The slider bar typically extends from 0 to 100, and the rating could be recorded as a floating-point number, e.g., 63.45. Here too one cannot assume that the difference between a zero-rated case and a 10 rated case is a tenth of the difference between a zero-rated case and a 100 rated case. So averaging the ratings is not allowed. Additionally, one cannot assume that different observers use the labels in the same way. One observer’s 4-rating is not equivalent to another observers 4-rating. Working directly with the ratings is a bad idea: valid analytical methods use the rankings of the ratings, not their actual values. The reason for the emphasis is that there are serious misconceptions about ratings. The author is aware of a publication stating, to the effect, that a modality resulted in an increase in average confidence level for diseased cases. Another publication used a specific numerical value of a rating to calculate the operating point for each observer – this assumes all observers use the rating scale in the same way.</p>
</div>
<div id="a-single-clinical-operating-point-from-ratings-data" class="section level2" number="4.7">
<h2><span class="header-section-number">4.7</span> A single “clinical” operating point from ratings data</h2>
<p>The reason for the quotes in the title to this section is that a single operating point on a laboratory ROC plot, no matter how obtained, has little relevance to how radiologists operate in the clinic. However, some consider it useful to quote an operating point from an ROC study. For a 5-rating ROC study, Table <a href="ratingsParadigm.html#tab:ratingsParadigmExampleTable">4.1</a>, it is not possible to unambiguously calculate the operating point of the observer in the binary task of discriminating between non-diseased and diseased cases. One possibility would be to use the “three and above” ratings to define the operating point, but one might jus have well have chosen “two and above.” A second possibility is to instruct the radiologist that a “four and above” rating, for example, implies the case would be reported “clinically” as diseased. However, the radiologist can only pretend so far that this study, which has no clinical consequences, is somehow a “clinical” study.</p>
<p>If a single laboratory study based operating point is desired <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2660" role="doc-biblioref">Nishikawa 2012</a>)</span>, the best strategy, in the author’s opinion, is to obtain the rating via two questions. This method is also illustrated in Table 3.1 of a book on detection theory <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1318" role="doc-biblioref">Macmillan and Creelman 1991</a>)</span>. The first question is “is the case diseased?” The binary (Yes/No) response to this question allows unambiguous calculation of the operating point, as in Chapter <a href="binary-task0.html#binary-task0">2</a>. The second question is: “what is your confidence in your previous decision?” and allow three responses, namely Low, Medium and High. The dual-question approach is equivalent to a 6-point rating scale, Fig. <a href="ratingsParadigm.html#fig:SixPointScale">4.2</a>. The answer to the first question, is the patient diseased, allows unambiguous construction of a single “clinical” operating point for disease presence. The answer to the second question, what is your confidence level in that decision, yields multiple operating points.</p>
<div class="figure"><span id="fig:SixPointScale"></span>
<img src="images/AcquiringData6PointScale.png" alt="A method for acquiring ROC data on an effectively 6-point scale that also yields an unambiguous single operating point for declaring patients diseased. Note the reversal of the final ratings in the last &quot;column&quot; in the lower half of the figure."  />
<p class="caption">
FIGURE 4.2: A method for acquiring ROC data on an effectively 6-point scale that also yields an unambiguous single operating point for declaring patients diseased. Note the reversal of the final ratings in the last “column” in the lower half of the figure.
</p>
</div>
<p>The ordering of the ratings can be understood as follows. The four, five and six ratings are as expected. If the radiologist states the patient is diseased and the confidence level is high that is clearly the highest end of the scale, i.e., six, and the lower confidence levels, five and four, follow, as shown. If, on the other hand, the radiologist states the patient is non-diseased, and the confidence level is high, then that must be the lowest end of the scale, i.e., “1.” The lower confidence levels in a negative decision must be higher than “1,” namely “2” and “3,” as shown. As expected, the low confidence ratings, namely “3” (non-diseased, low confidence) and “4” (diseased, low confidence) are adjacent to each other. With this method of data-collection, there is no confusion as to what rating defines the single desired operating point as this is determined by the binary response to the first question. The 6-point rating scale is also sufficiently fine to not smooth out the ability of the radiologist to maintain distinct different levels. In the author’s experience, using this scale one expects rating noise of about <span class="math inline">\(\pm\frac{1}{2}\)</span> a rating bin, i.e., the same difficult case, shown on different occasions to the same radiologist (with sufficient time lapse or other intervening cases to minimize memory effects) is expected to elicit a “3” or “4,” with roughly equal probability.</p>
</div>
<div id="the-forced-choice-paradigm" class="section level2" number="4.8">
<h2><span class="header-section-number">4.8</span> The forced choice paradigm</h2>
<p>In each of the four paradigms (ROC, FROC, LROC and ROI) described in TBA Chapter 01, patient images are displayed one patient at a time. A fifth paradigm involves presentation of multiple images to the observer, where one image (or set of images from one patient, i.e., a case) is from a diseased patient, and the rest are from non-diseased patients. The observer’s task is to pick the image, or the case, that is most likely to be from the diseased patient. If the observer is correct, the event is scored as a “one” and otherwise it is scored as a “zero.” The process is repeated with other sets of independent patient images, each time satisfying the condition that one patient is diseased and the rest are non-diseased. The sum of the scores divided by the total number of scores is the probability of a correct choice, denoted <span class="math inline">\(P(C)\)</span>. If the total number of cases presented at the same time is denoted <span class="math inline">\(n\)</span>, then the task is termed n-alternative forced choice or nAFC <span class="citation">(<a href="SplitPlotChapter.html#ref-RN298" role="doc-biblioref">Green and Swets 1966</a>)</span>. If only two cases are presented, one diseased and the other non-diseased, then n = 2 and the task is 2AFC. In Fig. <a href="ratingsParadigm.html#fig:2AFC">4.3</a>, in the left image a Gaussian nodule is superposed on a square region extracted from a non-diseased mammogram. The right image is a region extracted from a different non-diseased mammogram (one should not use the same background in the two images – the analysis assumes that different, i.e., independent images, are shown). If the observer clicks on the left image, a correct choice is recorded. [In some 2AFC-studies, the backgrounds are simulated non-diseased images. They resemble mammograms; the resemblance depends on the expertise of the observer: expert radiologists can tell that they are not true mammograms. They are actually created by filtering the random white noise with a 1/f3 spatial filter <span class="citation">(<a href="SplitPlotChapter.html#ref-burgess2011visual" role="doc-biblioref">Burgess 2011</a>)</span>.]</p>
<p>The 2AFC paradigm is popular, because its analysis is straightforward, and there exists a theorem4 that <span class="math inline">\(P(C)\)</span>, the probability of a correct choice in the 2AFC task, equals, to within sampling variability, the <em>true</em> area under the true (not fitted, not empirical) ROC curve. Another reason for its popularity is possibly the speed at which data can be collected, sometimes only limited by the speed at which disk stored images can be displayed on the monitor. While useful for studies into human visual perception on relatively simple images, and the model observer community has performed many studies using this paradigm <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1067" role="doc-biblioref">Bochud, Abbey, and Eckstein 1999</a>)</span>, the author cannot recommend it for clinical studies because <em>it does not resemble any clinical task</em>. In the clinic, radiologists never have to choose the diseased patient out of a pair consisting of one diseased and one non-diseased. Additionally, the forced-choice paradigm is wasteful of known-truth images, often a difficult/expensive resource to come by, because better statistics21 (tighter confidence intervals) are obtained by the ratings ROC method or by utilizing location specific extensions of the ROC paradigm. [The author is not aware of the 2AFC method being actually used to assess imaging systems using radiologists to perform real clinical tasks on real images.]</p>
<div class="figure"><span id="fig:2AFC"></span>
<img src="images/2AFC.png" alt="Example of image presentation in a 2AFC study."  />
<p class="caption">
FIGURE 4.3: Example of image presentation in a 2AFC study.
</p>
</div>
<p>Fig. <a href="ratingsParadigm.html#fig:2AFC">4.3</a>: Example of image presentation in a 2AFC study. The left image contains, at its center, a positive contrast Gaussian shape disk superposed on a non-diseased mammogram. The right image does not contain a lesion at its center and the background is from a different non-diseased patient. If the observer clicks on the left image it is recorded as a correct choice, otherwise it is recorded as an incorrect choice. The number of correct choices divided by the number of paired presentations is an estimate of the probability of a correct choice, which can be shown to be identical, apart from sampling variability, to the true area under the ROC curve. This is an example of a signal known exactly location known exactly (SKE-LKE) task widely used by the model observer community.</p>
</div>
<div id="observer-performance-studies-as-laboratory-simulations-of-clinical-tasks" class="section level2" number="4.9">
<h2><span class="header-section-number">4.9</span> Observer performance studies as laboratory simulations of clinical tasks</h2>
<ul>
<li><p>Observer performance paradigms (ROC, FROC, LROC and ROI) should be regarded as experiments conducted in a laboratory (i.e., controlled) setting that are intended to be representative of the actual clinical task. They should not to be confused with performance in a real “live” clinical setting: there is a known “laboratory effect” <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2026" role="doc-biblioref">Gur et al. 2008</a>)</span>. For example, in the just cited study radiologists performed better during live clinical interpretations than they did later, on the same cases, in a laboratory ROC study. This is to be expected because there is more at stake during live interpretations: e.g., the patient’s health and the radiologist’s reputation, than during laboratory ROC studies. The claimed “laboratory effect” has caused some minor controversy. A paper <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2373" role="doc-biblioref">Soh et al. 2013</a>)</span> titled “Screening mammography: test set data can reasonably describe actual clinical reporting” argues against the laboratory effect.</p></li>
<li><p>Real clinical interpretations happen every day in radiology departments all over the world. On the other hand, in the laboratory, the radiologist is asked to interpret the images “as if in a clinical setting” and render a “diagnosis.” The laboratory decisions have no clinical consequences, e.g., the radiologist will not be sued for mistakes and their laboratory study decisions will have no impact on the clinical management of the patients. [Usually laboratory ROC studies are conducted on retrospectively acquired images. Patients, whose images were used in an ROC study, have already been imaged in the clinic and decisions have already been made on how to manage them.]</p></li>
<li><p>There is no guarantee that results of the laboratory study are directly applicable to clinical practice. Indeed there is an assumption that the laboratory study correlates with clinical performance. Strict equality is not required, simply that the performance in the laboratory is related monotonically to actual clinical performance. Monotonicity assures preservation of performance orderings, e.g., a radiologist has greater performance than another does or one modality is superior to another, regardless of how they are measured, in the laboratory or in the clinic. The correlation is taken to be an axiomatic truth by researchers, when in fact it is an assumption. To the extent that the participating radiologist brings his/her full clinical expertise to bear on each laboratory image interpretation, i.e., takes the laboratory study seriously, this assumption is likely to be valid.</p></li>
<li><p>This title of this section provoked a strong response from a collaborator. To paraphrase him, "… <em>I think it is a pity in this book chapter you argue that these studies are simulations. I mean, the reason people perform these studies is because they believe in the results"</em>.</p></li>
<li><p>The author also believes in observer performance studies. Distrust of the word “simulation” seems to be peculiar to this field. Simulations are widely used in “hard” sciences, e.g., they are used in astrophysics to determine conditions dating to <span class="math inline">\(10^{-31}\)</span> seconds after the big bang. Simulations are not to be taken lightly. Conducting clinical studies is very difficult as there are many factors not under the researcher’s control. Observer performance studies of the type described in this book are the closest that one can come to the “real thing” as they include key elements of the actual clinical task: the entire imaging system, radiologists (assuming the radiologist take these studies seriously in the sense of bringing their full expertise to bear on each image interpretation) and real clinical images. As such are expected to correlate with real “live” interpretations.</p></li>
</ul>
</div>
<div id="discrete-vs.-continuous-ratings-the-miller-study" class="section level2" number="4.10">
<h2><span class="header-section-number">4.10</span> Discrete vs. continuous ratings: the Miller study</h2>
<ul>
<li><p>There is controversy about the merits of discrete vs. continuous ratings <span class="citation">(<a href="SplitPlotChapter.html#ref-RN99" role="doc-biblioref">Rockette, Gur, and Metz 1992</a>; <a href="SplitPlotChapter.html#ref-RN2179" role="doc-biblioref">Wagner, Beiden, and Metz 2001</a>)</span>. Since the late Prof. Charles E. Metz and the late Dr. Robert F. Wagner have both backed the latter (i.e., continuous or quasi-continuous ratings) new ROC study designs sometimes tend to follow their advice. The author’s recommendation is to follow the 6-point rating scale as outlined in Fig. <a href="ratingsParadigm.html#fig:SixPointScale">4.2</a>. This section provides the background for the recommendation.</p></li>
<li><p>A widely cited (22,909 citations at the time of writing) 1954 paper by Miller <span class="citation">(<a href="SplitPlotChapter.html#ref-RN930" role="doc-biblioref">G. A. Miller 1956</a>)</span> titled “The Magical Number Seven, Plus or Minus Two: Some Limits on Our Capacity for Processing Information” is relevant. It is a readable paper, freely downloadable in several languages (www.musanim.com/miller1956/). In the author’s judgment, this paper has not received the attention it should have in the ROC community, and for this reason portions from it are reproduced below. [George Armitage Miller, February 3, 1920 – July 22, 2012, was one of the founders of the field of cognitive psychology.]</p></li>
<li><p>Miller’s first objective was to comment on absolute judgments of unidimensional stimuli. Since all (univariate, i.e., single decision per case) ROC models assume a unidimensional decision variable, Miller’s work is highly relevant. He comments on two papers by Pollack <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2476" role="doc-biblioref">Pollack 1952</a>, <a href="SplitPlotChapter.html#ref-RN2474" role="doc-biblioref">1953</a>)</span>. Pollack asked listeners to identify tones by assigning numerals to them, analogous to a rating task described above. The tones differed in frequency, covering the range 100 to 8000 Hz in equal logarithmic steps. A tone was sounded and the listener responded by giving a numeral (i.e., a rating, with higher values corresponding to higher frequencies). After the listener had made his response, he was told the correct identification of the tone. When only two or three tones were used, the listeners never confused them. With four different tones, confusions were quite rare, but with five or more tones, confusions were frequent. With fourteen different tones, the listeners made many mistakes. Since it is so succinct, the entire content of the first (1952) paper by Pollack is reproduced below:</p></li>
<li><p>“In contrast to the extremely acute sensitivity of a human listener to discriminate small differences in the frequency or intensity between two sounds is his relative inability to identify (and name) sounds presented individually. When the frequency of a single tone is varied in equal‐logarithmic steps in the range between 100 cps and 8000 cps (and when the level of the tone is randomly adjusted to reduce loudness cues), the amount of information transferred is about 2.3 bits per stimulus presentation. This is equivalent to perfect identification among only 5 tones. The information transferred, under the conditions of measurement employed, is reasonably invariant under wide variations in stimulus conditions.”</p></li>
<li><p>By “information” is meant (essentially) the number of levels, measured in bits (binary digits), thereby making it independent of the unit of measurement: 1 bit corresponds to a binary rating scale, 2 bits to a four-point rating scale and 2.3 bits to <span class="math inline">\(2^{2.3}\)</span> = 4.9, i.e., about 5 ratings bins. Based on Pollack’s’ original unpublished data, Miller put an upper limit of 2.5 bits (corresponding to about 6 ratings bins) on the amount of information that is transmitted by listeners who make absolute judgments of auditory pitch. The second paper <span class="citation">(@ <a href="SplitPlotChapter.html#ref-RN2474" role="doc-biblioref">Pollack 1953</a>)</span> by Pollack was related to: (1) the frequency range of tones; (2) the utilization of objective reference tones presented with the unknown tone; and (3) the “dimensionality”—the number of independently varying stimulus aspects. Little additional gain in information transmission was associated with the first factor; a moderate gain was associated with the second; and a relatively substantial gain was associated with the third (we return to the dimensionality issue below).</p></li>
<li><p>As an interesting side-note, Miller states:</p></li>
</ul>
<blockquote>
<p>“Most people are surprised that the number is as small as six. Of course, there is evidence that a musically sophisticated person with absolute pitch can identify accurately any one of 50 or 60 different pitches. Fortunately, I do not have time to discuss these remarkable exceptions. I say it is fortunate because I do not know how to explain their superior performance. So I shall stick to the more pedestrian fact that most of us can identify about one out of only five or six pitches before we begin to get confused.</p>
</blockquote>
<p>It is interesting to consider that psychologists have been using seven-point rating scales for a long time, on the intuitive basis that trying to rate into finer categories does not really add much to the usefulness of the ratings. Pollack’s results indicate that, at least for pitches, this intuition is fairly sound.</p>
<blockquote>
<p>Next you can ask how reproducible this result is. Does it depend on the spacing of the tones or the various conditions of judgment? Pollack varied these conditions in a number of ways. The range of frequencies can be changed by a factor of about 20 without changing the amount of information transmitted more than a small percentage. Different groupings of the pitches decreased the transmission, but the loss was small. For example, if you can discriminate five high-pitched tones in one series and five low-pitched tones in another series, it is reasonable to expect that you could combine all ten into a single series and still tell them all apart without error. When you try it, however, it does not work. The channel capacity for pitch seems to be about six and that is the best you can do.”</p>
</blockquote>
<ul>
<li><p>In contrast to the careful experiments conducted in the psychophysical context to elucidate this issue, the author was unable to find a single study, in the medical imaging field, of the number of discrete rating levels that an observer can support. Instead, a recommendation has been made to acquire data on a quasi-continuous scale <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2179" role="doc-biblioref">Wagner, Beiden, and Metz 2001</a>)</span>.</p></li>
<li><p>There is no question that for multidimensional data, as observed in the second study by Pollack <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2474" role="doc-biblioref">Pollack 1953</a>)</span>, the observer can support more than 7 ratings bins. To quote Miller:</p></li>
</ul>
<blockquote>
<p>“You may have noticed that I have been careful to say that this magical number seven applies to one- dimensional judgments. Everyday experience teaches us that we can identify accurately any one of several hundred faces, any one of several thousand words, any one of several thousand objects, etc. The story certainly would not be complete if we stopped at this point. We must have some understanding of why the one-dimensional variables we judge in the laboratory give results so far out of line with what we do constantly in our behavior outside the laboratory. A possible explanation lies in the number of independently variable attributes of the stimuli that are being judged. Objects, faces, words, and the like differ from one another in many ways, whereas the simple stimuli we have considered thus far differ from one another in only one respect.”</p>
</blockquote>
<ul>
<li><p>In the medical imaging context, a trivial way to increase the number of ratings would be to color-code the images: red, green and blue; now one can assign a red image rated 3, a green image rated 2, etc., which would be meaningless unless the color encoded relevant diagnostic information. Another ability, quoted in the publication <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2179" role="doc-biblioref">Wagner, Beiden, and Metz 2001</a>)</span> advocating continuous ratings is the ability to recognize faces, again a multidimensional categorization task, as noted by Miller. Also quoted as an argument for continuous ratings is the ability of computer aided detection schemes that calculate many features for each perceived lesion and combine them into a single probability of malignancy, which is on a highly precise floating point 0 to 1 scale, which can be countered by the fact that radiologists are not computers. Other arguments for greater number of bins: it cannot hurt and one should acquire the rating data at greater precision than the noise, especially if the radiologist is able to maintain the finer distinctions. The author worries that radiologists who are willing to go along with greater precision are over-anxious to co-operate with the experimentalist. Expert radiologists will not modify their reading style and one should be suspicious when overzealous radiologists accede to an investigators request to interpret images in a style that does not resemble the clinic. Radiologists, especially experts, do not like more than about four ratings. The author once worked closely with a famous chest radiologist (the late Dr. Robert Fraser) who refused to use more than four ratings.</p></li>
<li><p>Another reason given for using continuous ratings is it reduces instances of data degeneracy. Data is sometimes said to be degenerate if the curve-fitting algorithm, the binormal model and the proper binormal model, cannot fit it (in simple terms, the program crashes). This occurs, for example, if there are no interior points on the ROC plot. Modifying radiologist behavior to accommodate the limitations of analytical methods seems to be inherently dubious. One could simply randomly add or subtract half an integer from the observed ratings, thereby making the rating scale more granular and reduce instances of degeneracy (this is actually done in some ROC software to overcome degeneracy issues). Another possibility is to use the empirical (trapezoidal) area under the ROC curve, which can always be calculated; there are no degeneracy problems with it. Actually, fitting methods now exist that are robust to data degeneracy, such as discussed in TBA Chapter 18 and Chapter 20, so this reason for acquiring continuous data no longer applies.</p></li>
<li><p>The rating task involves a unidimensional scale and the author sees no way of getting around the basic channel-limitation noted by Miller and for this reason the author recommends a 6 point scale, as in Fig. <a href="ratingsParadigm.html#fig:SixPointScale">4.2</a>.</p></li>
<li><p>On the other side of the controversy <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2145" role="doc-biblioref">Berbaum et al. 2002</a>)</span>, a position that the author agrees with, it has been argued that given a large number of allowed ratings levels the cooperating observer essentially bins the data into a much smaller number of bins (e.g., 0, 20, 40, 60, 80, 100) and then adds a zero-mean noise term to appear to be “spreading out the ratings.” This ensures that the binormal model does not crash. However, if the intent is to get the observer to spread the ratings, so that the binormal model does not crash, a better approach is to use alternate models that do not crash and are, in fact, very robust with respect to degneracy of the data. More on this later (see Chapters TBA CBM and RSM).</p></li>
</ul>
</div>
<div id="the-bi-rads-ratings-scale-and-roc-studies" class="section level2" number="4.11">
<h2><span class="header-section-number">4.11</span> The BI-RADS ratings scale and ROC studies</h2>
<p>It is desirable that the rating scale be relevant to the radiologists’ daily practice. This assures greater consistency – the fitting algorithms assume that the thresholds are held constant for the duration of the ROC study. Depending on the clinical task, a natural rating scale may already exist. For example, in 1992 the American College of Radiology developed the Breast Imaging Reporting and Data System (BI-RADS) to standardize mammography reporting36. There are six assessment categories: category 0 indicates need for additional imaging; category 1 is a negative (clearly non-diseased) interpretation; category 2 is a benign finding; category 3 is probably benign, with short-interval follow-up suggested; category 4 is a suspicious abnormality for which biopsy should be considered; category 5 is highly suggestive of malignancy and appropriate action should be taken. The 4th edition of the BI-RADS manual37 divides category 4 into three subcategories 4A, 4B and 4C and adds category 6 for a proven malignancy. The 3-category may be further subdivided into “probably benign with a recommendation for normal or short-term follow-up” and a 3+ category, “probably benign with a recommendation for immediate follow-up.” Apart from categories 0 and 2, the categories form an ordered set with higher categories representing greater confidence in presence of cancer. How to handle the 0s and the 2s is the subject of some controversy, described next.</p>
</div>
<div id="the-controversy" class="section level2" number="4.12">
<h2><span class="header-section-number">4.12</span> The controversy</h2>
<p>Two large clinical studies have been reported in which BI-RADS category data were acquired for &gt; 400,00 screening mammograms interpreted by many (124 in the 1st study) radiologists <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2168" role="doc-biblioref">Barlow et al. 2004</a>; <a href="SplitPlotChapter.html#ref-RN1902" role="doc-biblioref">Joshua J. Fenton et al. 2007</a>)</span>. The purpose of the first study was to relate radiologist characteristics to actual performance (e.g., does performance depend on reading volume – the number of cases interpreted per year), so it could be regarded as a more elaborate version of <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1087" role="doc-biblioref">Beam, Layde, and Sullivan 1996</a>)</span>, described in Chapter <a href="binary-task.html#binary-task">3</a>. The purpose of the second study was to determine the effectiveness of computer-aided detection (CAD) in screening mammography.</p>
<p>The reported ROC analyses used the BIRADS assessments labels ordered as follows: <span class="math inline">\(1 &lt; 2 &lt; 3 &lt; 3+ &lt; 0 &lt; 4 &lt; 5\)</span>. The last column of Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> shows that with this ordering the numbers of cancer per 1000 patients increases monotonically. The CAD study is discussed later, for now the focus is on the adopted BIRADS scale ordering that is common to both studies and which has raised controversy (the controversy appears to be limited to observer performance study analysts).</p>
<table class="table" style="margin-left: auto; margin-right: auto;">
<caption>
<span id="tab:BIRADS-study">TABLE 4.3: </span>The Barlow et al study: the ordering of the BI-RADS ratings in the first column correlates with cancer-rate in the last column.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:left;">
Total number
of mammograms
</th>
<th style="text-align:left;">
Mammograms without
breast cancer (percent)
</th>
<th style="text-align:left;">
Mammograms with
breast cancer (percent)
</th>
<th style="text-align:left;">
Cancers per 1000
screening mammograms
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 11em; ">
1: Normal
</td>
<td style="text-align:left;width: 8em; ">
356,030
</td>
<td style="text-align:left;width: 8em; ">
355,734 (76.2)
</td>
<td style="text-align:left;width: 8em; ">
296 (12.3)
</td>
<td style="text-align:left;width: 8em; ">
0.83
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
2: Benign finding
</td>
<td style="text-align:left;width: 8em; ">
56,614
</td>
<td style="text-align:left;width: 8em; ">
56,533 (12.1)
</td>
<td style="text-align:left;width: 8em; ">
81 (3.4)
</td>
<td style="text-align:left;width: 8em; ">
1.43
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
3: Probably benign,
recommend normal or short term follow up
</td>
<td style="text-align:left;width: 8em; ">
8,692
</td>
<td style="text-align:left;width: 8em; ">
8,627 (1.8)
</td>
<td style="text-align:left;width: 8em; ">
65 (2.7)
</td>
<td style="text-align:left;width: 8em; ">
7.48
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
3+: Probably benign,
recommend immediate follow up
</td>
<td style="text-align:left;width: 8em; ">
3,094
</td>
<td style="text-align:left;width: 8em; ">
3,049 (0.7)
</td>
<td style="text-align:left;width: 8em; ">
45 (1.9)
</td>
<td style="text-align:left;width: 8em; ">
14.54
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
0: Need additional
imaging evaluation
</td>
<td style="text-align:left;width: 8em; ">
42,823
</td>
<td style="text-align:left;width: 8em; ">
41,442 (8.9)
</td>
<td style="text-align:left;width: 8em; ">
1,381 (57.5)
</td>
<td style="text-align:left;width: 8em; ">
32.25
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
4: Suspicious finding,
biopsy should be considered
</td>
<td style="text-align:left;width: 8em; ">
2,022
</td>
<td style="text-align:left;width: 8em; ">
1,687 (0.4)
</td>
<td style="text-align:left;width: 8em; ">
335 (13.9)
</td>
<td style="text-align:left;width: 8em; ">
165.68
</td>
</tr>
<tr>
<td style="text-align:left;width: 11em; ">
5: Highly suggestive
of malignancy
</td>
<td style="text-align:left;width: 8em; ">
237
</td>
<td style="text-align:left;width: 8em; ">
38 (0.0)
</td>
<td style="text-align:left;width: 8em; ">
199 (8.3)
</td>
<td style="text-align:left;width: 8em; ">
839.66
</td>
</tr>
</tbody>
</table>
<p>The use of the BI-RADS ratings shown in Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> has been criticized <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2166" role="doc-biblioref">Jiang and Metz 2010</a>)</span> in an editorial titled:</p>
<blockquote>
<p>BI-RADS Data Should Not Be Used to Estimate ROC Curves</p>
</blockquote>
<p>Since BI-RADS is a clinical rating scheme widely used in mammography, the editorial, if correct, implies that ROC analysis of clinical mammography data is not possible. Since the BI-RADS scale was arrived at after considerable deliberation, inability to perform ROC analysis with it would strike at the root of clinical utility of the ROC method. The purpose of this section is to express the reasons why the author has a different take on this controversy.</p>
<p>It is claimed in the editorial that the Barlow et al. study confuses cancer yield with confidence level and that BI-RADS categories 1 and 2 should not be separate entries of the confidence scale, because both indicate no suspicion for cancer.</p>
<p>The author agrees with the Barlow et al. suggested ordering of the “2s” as more likely to have cancer than the “1s.” A category-2 means the radiologist found something to report, and the location of the finding is part of the clinical report. Even if the radiologist believes the finding is definitely benign, there is a finite probability that a category-2 finding is cancer, as evident in the last column of Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> (<span class="math inline">\(1.43 &gt; 0.83\)</span>). In contrast, there are no findings associated with a category-1 report. A paper <span class="citation">(<a href="SplitPlotChapter.html#ref-hartmann2005benign" role="doc-biblioref">Hartmann et al. 2005</a>)</span> titled:</p>
<blockquote>
<p>Benign breast disease and the risk of breast cancer</p>
</blockquote>
<p>should convince any doubters that benign lesions do have a finite chance of cancer.</p>
<p>The problem with “where to put the 0s” arises only when one tries to analyze clinical BI-RADS data. In a laboratory study, the radiologist would not be given the category-0 option. In analyzing a clinical study it is incumbent on the study designer to justify the choice of the rating scale adopted. Showing that the proposed ordering agrees with the probability of cancer is justification – and in the author’s opinion, given the very large sample size this was accomplished convincingly in the Barlow et al. study.</p>
<p><strong>Moreover, the last column of Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> suggests that any other ordering would violate an important principle, namely, optimal ordering is achieved when each case is rated according to it’s likelihood ratio (defined as the probability of the case being diseased divided by the probability of the case being non-diseased). The likelihood ratio is the “betting odds” of the case being diseased, which is expected to be monotonic with the empirical probability of the case being diseased, i.e., the last column of Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a>. Therefore, the ordering adopted in Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> is equivalent to adopting a likelihood ratio scale and any other ordering would not be monotonic with likelihood ratio.</strong></p>
<p>The likelihood ratio is described in more detail in the TBA Chapter 20, which describes ROC fitting methods that yield “proper” ROC curves, i.e., ones that have monotonically decreasing slope as the operating point moves up the curve from (0,0) to (1,1) and therefore do not (inappropriately) cross the chance diagonal. Key to these fitting methods is adoption of a likelihood ratio scale to rank-order cases, instead of the ratings assumed by the unequal variance binormal model. The proper ROC fitting algorithm implemented in PROPROC software reorders confidence levels assumed by the binormal model, TBA Chapter 20, paragraph following Fig. 20.4. This is analogous to the reordering of the clinical ratings based on cancer rates assumed in Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a>. It is illogical to allow reordering of ratings in “blind” software but question the same when done in a principled way by a researcher. As expected, the modeled ROC curves in the Barlow publication, their Fig. 4, show no evidence of improper behavior. This is in contrast to a clinical study (about fifty thousands patients spread over 33 hospitals with each mammogram interpreted by two radiologists) using a non-BIRADS 7-point rating scale which yielded markedly improper ROC curves <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1784" role="doc-biblioref">Pisano et al. 2005</a>)</span> for the film modality when using ROC ratings (not BIRADS). This suggests that use of a non-clinical ratings scale for clinical studies, without independent confirmation of the ordering implied by the scale, is problematical.</p>
<p>The reader might be interested as to reason for the 0-ratings being more predictive of cancer than a 3+ rating, Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a>. In the clinic the zero rating implies, in effect, “defer decision, incomplete information, additional imaging necessary.” A zero rating could be due to technical problems with the images: e.g., improper positioning (e.g., missing breast tissue close to the chest wall) or incorrect imaging technique (improper selection of kilovoltage and/or tube charge), making it impossible to properly interpret the images. Since the images are part of the permanent patient record, there are both healthcare and legal reasons why the images need to be optimal. Incorrect technical factors are expected to occur randomly and therefore not predictive of cancer. However, if there is a suspicious finding and the image quality is sub-optimal, the radiologist may be unable to commit to a decision, they may seek additional imaging, perhaps better compression or a slightly different view angle to resolve the ambiguity. Such zero ratings are expected with suspicious findings, and therefore are expected to be predictive of cancer.</p>
<p>As an aside, the second paper <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1902" role="doc-biblioref">Joshua J. Fenton et al. 2007</a>)</span> using the ordering shown in Table <a href="ratingsParadigm.html#tab:BIRADS-study">4.3</a> questioned the utility of CAD for breast cancer screening (this was ca. 2007). This paper was met with flurry of correspondence disputing the methodology (summarized above). The finding regarding utility of CAD has been validated by more recent studies, again with very large case and reader samples, showing that usage of CAD can actually be detrimental to patient outcome <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2321" role="doc-biblioref">Philpotts 2009</a>)</span> and a call <span class="citation">(<a href="SplitPlotChapter.html#ref-RN2404" role="doc-biblioref">J. J. Fenton 2015</a>)</span> for ending insurance reimbursement for CAD.</p>
</div>
<div id="ratingsParadigm-discussion" class="section level2" number="4.13">
<h2><span class="header-section-number">4.13</span> Discussion</h2>
<p>In this chapter the widely used ratings paradigm was described and illustrated with a sample dataset. The calculation of ROC operating points from this table was detailed. A formal notation was introduced to describe the counts in this table and the construction of operating points and an R example was given. The author does not wish to leave the impression that the ratings paradigm is used only in medical imaging. In fact the historical reference <span class="citation">(<a href="SplitPlotChapter.html#ref-RN1318" role="doc-biblioref">Macmillan and Creelman 1991</a>)</span> to the two-question six-point scale in Fig. <a href="ratingsParadigm.html#fig:SixPointScale">4.2</a>, namely Table 3.1 in the book by MacMillan and Creelman, was for a rating study on performance in recognizing odors. The early users of the ROC ratings paradigm were mostly experimental psychologists and psychophysicists interested in studying perception of signals, some in the auditory domain, and some in other sensory domains.</p>
<p>While it is possible to use the equal variance binormal model to obtain a measure of performance, the results depend upon the choice of operating point, and evidence was presented for the generally observed fact that most ROC ratings datasets are inconsistent with the equal variance binormal model. This indicates the need for an extended model, to be discussed in TBA Chapter 06.</p>
<p>The rating paradigm is a more efficient way of collecting the data compared to repeating the binary paradigm with instructions to cause the observer to adopt different fixed thresholds specific to each repetition. The rating paradigm is also more efficient than the 2AFC paradigm; more importantly, it is more clinically realistic.</p>
<p>Two controversial but important issues were addressed: the reason for the author’s recommendation for adopting a discrete 6-point rating scale, and correct usage of clinical BIRADS ratings in ROC studies. When a clinical scale exists, the empirical disease occurrence rate associated with each rating should be used to order the ratings. Ignoring an existing clinical scale would be a disservice to the radiology community.</p>
<p>The next step is to describe a model for ratings data. Before doing that, it is necessary to introduce an empirical performance measure, namely the area under the empirical or trapezoidal ROC, which does not require any modeling.</p>
</div>
<div id="ratingsParadigm-references" class="section level2" number="4.14">
<h2><span class="header-section-number">4.14</span> References</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="binary-task.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="empirical-auc.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["RJafrocBook.pdf", "RJafrocBook.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
