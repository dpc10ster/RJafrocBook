---
output:
  pdf_document: default
  html_document: default
---
# Applications using the Obuchowski Rockette method {#ORApplications} 

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
library(kableExtra)
library(ggplot2)
library(RJafroc)
library(here)
```

## Introduction {#ORApplications-introduction}
* Four examples are given. The first three use OR analysis, while the last one uses the pseudovalue-based DBM analysis.
* The first example uses a two-treatment five-reader **ROC** dataset, a well-know and widely used dataset in the literature [@RN1993]. 
* The second example uses a five-treatment four-reader **ROC** dataset, showing the effect of multiple treatment pairings. 
* The third example uses a five-treatment four-reader **FROC** dataset, showing the key difference involved in FROC analysis, namely the choice of figure of merit. 
* The fourth example uses a five-treatment four-reader **FROC** dataset, showing the key difference involved in DBM vs. OR analysis. 
* Each analysis involves the following steps: 
+ Calculate the figure of merit, 
+ Calculate the variance-covariance matrix and the mean-squares, and 
+ Calculate the NH statistic, p-value and confidence interval(s).

## Hand calculation using dataset02 {#ORApplications-dataset02-hand}
* `dataset02` has two modalities and five readers. 

```{r}
I <- length(dataset02$ratings$NL[,1,1,1])
J <- length(dataset02$ratings$NL[1,,1,1])
cat("I = ", I, ", J = ", J, "\n")
```

### Random-Reader Random-Case (RRRC) analysis {#ORApplications-RRRC-dataset02-hand}
* The first step is to calculate the figures of merit. 
* The following code uses `UtilFigureOfMerit()` to this end. Note that `FOM` has to be explicitly specified as "Wilcoxon".

```{r}
foms <- UtilFigureOfMerit(dataset02, FOM = "Wilcoxon")
print(foms)
```

* For example, for the first treatment, `trt0`, the second reader's figure of merit is `r foms["trt0", "rdr1"]`.
* The next step is to calculate the variance-covariance matrix and the mean-squares.
* The function `UtilORVarComponentsFactorial()` returns these quantities. The `Factorial` in the function name is due to the fact that this code applies to the factorial design. A different function is used for a split-plot design.
* For compactness only the first two members of the returned object are displayed. The remaining members are used in single-treatment and single-reader analyses.

```{r}
ret <- UtilORVarComponentsFactorial(dataset02, FOM = "Wilcoxon", covEstMethod = "jackknife")
print(ret$TRanova)
print(ret$VarCom)
```

* The next step is the calculate the NH testing statistic. 
* The relevant equation is Eqn. \@ref(eq:F-ORH-RRRC). 
* `ret` contains the values needed in this equation, as follows:
+ MS(T) is in `ret$TRanova["T", "MS"]`, whose value is `r ret$TRanova["T", "MS"]`. 
+ MS(TR) is in `ret$TRanova["TR", "MS"]`, whose value is `r ret$TRanova["TR", "MS"]`. 
+ `J`, the number of readers, is the length of the second dimension of `dataset02$ratings$NL`, i.e., 5. 
+ `Cov2` is in `ret$VarCom["Cov2", "Estimates"]`, whose value is `r ret$VarCom["Cov2", "Estimates"]`. 
+ `Cov3` is in `ret$VarCom["Cov3", "Estimates"]`, whose value is `r ret$VarCom["Cov3", "Estimates"]`. 

Applying Eqn. \@ref(eq:F-ORH-RRRC) one gets (`den` is the denominator on the right hand side of the referenced equation):

```{r}
den <- ret$TRanova["TR", "MS"] + J* max(ret$VarCom["Cov2", "Estimates"] - ret$VarCom["Cov3", "Estimates"],0)
F_ORH_RRRC <- ret$TRanova["T", "MS"]/den
print(F_ORH_RRRC)
```

* The next step is calculation of the denominator degrees of freedom.
* From the previous chapter, `ddf` is calculated using Eqn. \@ref(eq:ddfH-RRRC)). The numerator of `ddf` is seen to be identical to `den^2`, where `den` was calculated in the preceding code block. The implementation follows:

```{r}
ddf <- den^2*(I-1)*(J-1)/(ret$TRanova["TR", "MS"])^2
print(ddf)
```

* The next step is calculation of the p-value for rejecting the NH
* The relevant equation is Eqn. \@ref(eq:pValueOR-RRRC) whose implementation follows: 

```{r}
p <- 1 - pf(F_ORH_RRRC, I - 1, ddf)
print(p)
```

* The difference is not significant at $\alpha$ = 0.05. 
* The next step is calculation of confidence intervals.
* Since `I` = 2, their is only one paired difference in reader-averaged FOMs, namely, the first treatment minus the second:

```{r}
trtMeans <- rowMeans(foms)
trtMeanDiffs <- trtMeans[1] - trtMeans[2]
print(trtMeanDiffs)
```

* From the previous chapter, the $(1-\alpha)$ confidence interval for $\theta_{1 \bullet} - \theta_{2 \bullet}$ is given by Eqn. \@ref(eq:CI-RRRC).
* The expression inside the square-root symbol is `2/J*den`. The implementation follows:

```{r}
alpha <- 0.05
stdErr <- sqrt(2 * den/J)
t_crit <- abs(qt(alpha/2, ddf))
CI_RRRC <- c(trtMeanDiffs - t_crit*stdErr, trtMeanDiffs + t_crit*stdErr)
names(CI_RRRC) <- c("Lower", "Upper")
print(CI_RRRC)
```

The confidence interval includes zero, which confirms that the reader-averaged FOM difference between treatments is not significant. 

### Fixed-Reader Random-Case (FRRC) analysis {#ORApplications-FRRC-dataset02-hand}
TBA

### Random-Reader Fixed-Case (RRFC) analysis {#ORApplications-RRFC-dataset02-hand}
TBA

## Using RJafroc: dataset02 {#ORApplications-dataset02-RJafroc}
### Random-Reader Random-Case (RRRC) analysis {#ORApplications-RRRC-dataset02-RJafroc}
* This is accomplished using the significance testing function `StSignificanceTesting()`. 
* Since `analysisOption` is not explicitly specified in the following code, the function `StSignificanceTesting` performs all three analyses: `RRRC`, `FRRC` and `RRFC`.
* The significance level of the test, also an argument, `alpha`, defaults to 0.05. 
* The code below applies this function and saves the returned object to `st1`. 
* The first member of this object, a  `list` object named `FOMs`, is then displayed. 
* `FOMs` contains three data frames: 
+ `FOMS$foms`, the figures of merit for each treatment and reader, 
+ `FOMS$trtMeans`, the figures of merit for each treatment averaged over readers, and 
+ `FOMS$trtMeanDiffs`, the inter-treatment difference figures of merit averaged over readers. The difference is always the first treatment minus the second, etc., in this example, `trt0` minus `trt1`.

```{r}
st1 <- StSignificanceTesting(dataset02, FOM = "Wilcoxon", method = "OR")
print(st1$FOMs)
```

* Displayed next are the variance components and mean-squares. 
* These are contained in the `ANOVA` `list` object. 
* `ANOVA$TRanova` contains the treatment-reader ANOVA table, i.e. the sum of squares, the degrees of freedom and the mean-squares, listed for the treatment, reader and treatment-reader factors, i.e., `T`, `R` and `TR`.
* `ANOVA$VarCom` contains the OR variance components and the correlations.
* `ANOVA$IndividualTrt` contains the quantities necessary for individual treatment analyses.
* `ANOVA$IndividualRdr` contains the quantities necessary for individual reader analyses.

```{r}
print(st1$ANOVA)
```

* Displayed next are the results of RRRC analysis, contained in the `RRRC` `list` object.
* `RRRC$FTests` contains the results of the F-tests.
* `RRRC$ciDiffTrt` contains the results of the confidence intervals for the inter-treatment difference FOMs, averaged over readers.
* `RRRC$ciAvgRdrEachTrt` contains the results of the confidence intervals for the treatments, averaged over readers.

```{r}
print(st1$RRRC$FTests)
```

* TBA

```{r}
print(st1$RRRC$ciDiffTrt[,-c(2:5)])
```

* TBA

```{r}
print(st1$RRRC$ciAvgRdrEachTrt[,-c(2,3,6)])
```

* TBA

### Fixed-Reader Random-Case (FRRC) analysis {#ORApplications-FRRC-dataset02-RJafroc}

* TBA

```{r}
print(st1$FRRC$FTests)
```

* TBA

```{r}
print(st1$FRRC$ciDiffTrt[,-c(2:4)])
```

* TBA

```{r}
print(st1$FRRC$ciAvgRdrEachTrt[,-c(2,3,5)])
```

### Random-Reader Fixed-Case (RRFC) analysis {#ORApplications-RRFC-dataset02-RJafroc}

```{r}
print(st1$RRFC$FTests)
```

* TBA

```{r}
print(st1$RRFC$ciDiffTrt[,-c(2,3,4,5)])
```

## Using RJafroc: dataset04 {#ORApplications-dataset04-RJafroc}
* The second example uses the Federica Zanca dataset [@RN1882], i.e., `dataset04`, which has five modalities and four readers. 
* This illustrates the situation when multiple treatment pairings are involved. In contrast, the previous example had only one treatment pairing.
* Since this is an FROC dataset, in order to keep this comparable with the previous example, one converts it to an inferred-ROC dataset.
* The function `DfFroc2Roc(dataset04)` converts, using the highest-rating, the FROC dataset to an inferred-ROC dataset.
* The results are contained in the returned `list` object `st2`.

```{r}
ds <- DfFroc2Roc(dataset04) # convert to ROC
I <- length(ds$ratings$NL[,1,1,1])
J <- length(ds$ratings$NL[1,,1,1])
cat("I = ", I, ", J = ", J, "\n")
st2 <- StSignificanceTesting(ds, FOM = "Wilcoxon", method = "OR")
print(st2$FOMs)
print(st2$ANOVA$TRanova)
print(st2$ANOVA$VarCom)
```

### Random-Reader Random-Case (RRRC) analysis {#ORApplications-RRRC-dataset04}

```{r}
print(st2$RRRC$FTests)
```

* TBA

```{r}
print(st2$RRRC$ciDiffTrt[,-c(2:5)])
```

* TBA

```{r}
print(st2$RRRC$ciAvgRdrEachTrt[,-c(2,3,6)])
```

* TBA

### Fixed-Reader Random-Case (FRRC) analysis {#ORApplications-FRRC-dataset04}

```{r}
print(st2$FRRC$FTests)
```

* TBA

```{r}
print(st2$FRRC$ciDiffTrt[,-c(2:4)])
```

* TBA

```{r}
print(st2$FRRC$ciAvgRdrEachTrt[,-c(2,3,5)])
```

* TBA

```{r}
print(st2$FRRC$FTests)
```

* TBA

### Random-Reader Fixed-Case (RRFC) analysis {#ORApplications-RRFC-dataset04}

```{r}
print(st2$RRFC$FTests)
```

* TBA

```{r}
print(st2$RRFC$ciDiffTrt[,-c(2,3,4,5)])
```



## Using RJafroc: dataset04, FROC analysis {#ORApplications-dataset04-FROC-RJafroc}
* The third example uses `dataset04`, but this time we use the FROC data, i.e, we do not convert it to inferred-ROC. 
* Since this is an FROC dataset, one needs to use an FROC figure of merit. 
* In this example the weighted AFROC figure of merit `FOM = "wAFROC"` is specified. This is the recommended figure of merit when both normal and abnormal cases are present in the dataset.
* If the dataset does not contain normal cases, then the weighted AFROC1 figure of merit `FOM = "wAFROC1"` should be specified. 

```{r}
ds1 <- dataset04 # do NOT convert to ROC
# comment/uncomment following code to disable/enable unequal weights
# K2 <- length(ds1$ratings$LL[1,1,,1])
# weights <- array(dim = c(K2, max(ds1$lesions$perCase)))
# perCase <- ds1$lesions$perCase
# for (k2 in 1:K2) {
#   sum <- 0
#   for (el in 1:perCase[k2]) {
#     weights[k2,el] <- 1/el
#     sum <- sum + 1/el
#   }
#   weights[k2,1:perCase[k2]] <- weights[k2,1:perCase[k2]] / sum
# }
# ds1$lesions$weights <- weights
ds <- ds1
FOM <- "wAFROC" # also try wAFROC1, MaxLLF and MaxNLF
st3 <- StSignificanceTesting(ds, FOM = FOM, method = "OR")
print(st3$FOMs)
print(st3$ANOVA$TRanova)
print(st3$ANOVA$VarCom)
```

### Random-Reader Random-Case (RRRC) analysis {#ORApplications-RRRC-dataset04-FROC}

```{r}
print(st3$RRRC$FTests)
```

* TBA

```{r}
print(st3$RRRC$ciDiffTrt[,-c(2:5)])
```

* TBA

```{r}
print(st3$RRRC$ciAvgRdrEachTrt[,-c(2,3,6)])
```

* TBA

### Fixed-Reader Random-Case (FRRC) analysis {#ORApplications-FRRC-dataset04-FROC}

```{r}
print(st3$FRRC$FTests)
```

* TBA

```{r}
print(st3$FRRC$ciDiffTrt[,-c(2:4)])
```

* TBA

```{r}
print(st3$FRRC$ciAvgRdrEachTrt[,-c(2,3,5)])
```

* TBA

```{r}
print(st3$FRRC$FTests)
```

* TBA

### Random-Reader Fixed-Case (RRFC) analysis {#ORApplications-RRFC-dataset04-FROC}

```{r}
print(st3$RRFC$FTests)
```

* TBA

```{r}
print(st3$RRFC$ciDiffTrt[,-c(2,3,4,5)])
```


## Using RJafroc for dataset04, FROC analysis, DBM method {#ORApplications-dataset04-FROC-DBM-RJafroc}
* The fourth example again uses `dataset04`, i.e., FROC data, *but this time we use DBM analysis*.
* The key difference below is in the call to `StSignificanceTesting()` function, where we set `method = "DBM"`.
* Since DBM analysis is pseudovalue based, and the figure of merit is not the empirical AUC under the ROC, one expects to see differences from the previously presented OR analysis, contained in `st3`.

```{r}
st4 <- StSignificanceTesting(ds, FOM = FOM, method = "DBM") # Note: using DBM analysis
print(st4$FOMs)
print(st4$ANOVA$TRCanova)
print(st4$ANOVA$VarCom)
```

### Random-Reader Random-Case (RRRC) analysis {#ORApplications-RRRC-dataset04-FROC-DBM}

```{r}
print(st4$RRRC$FTests)
```

* TBA

```{r}
print(st4$RRRC$ciDiffTrt[,-c(2:5)])
```

* TBA

```{r}
print(st4$RRRC$ciAvgRdrEachTrt[,-c(2,3,6)])
```

* TBA

### Fixed-Reader Random-Case (FRRC) analysis {#ORApplications-FRRC-dataset04-FROC-DBM}

```{r}
print(st4$FRRC$FTests)
```

* TBA

```{r}
print(st4$FRRC$ciDiffTrt[,-c(2:4)])
```

* TBA

```{r}
print(st4$FRRC$ciAvgRdrEachTrt[,-c(2,3,5)])
```

* TBA

### Random-Reader Fixed-Case (RRFC) analysis {#ORApplications-RRFC-dataset04-FROC-DBM}

```{r}
print(st4$RRFC$FTests)
```

* TBA

```{r}
print(st4$RRFC$ciDiffTrt[,-c(2,3,4,5)])
```



## Discussion/Summary/5

## Tentative, need to think over {#ToMullOver1-tentative}
A comparison was run between results of OR and DBM for the FROC dataset. Except for `FRRC`, where differences are expected (because `ddf` in the former is $\infty$, while that in the later is $(I-1)\times(J-1))$, the results for the p-values were identical. This was true for the following FOMs: `wAFROC`, with equal and unequal weights, and `MaxLLF`. The confidence intervals (again, excluding `FRRC`) were identical for `FOM` = `wAFROC`. Slight differences were observed for `FOM` = `MaxLLF`.  

## References {#ORApplications-references}

